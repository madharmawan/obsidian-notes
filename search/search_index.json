{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 You can use the sidebar to navigate to any page at any time, but I tried to link everything together, so clicking the hyperlinks should get you everywhere in the book pretty nicely. Go to mastertoc","title":"Welcome"},{"location":"#welcome","text":"You can use the sidebar to navigate to any page at any time, but I tried to link everything together, so clicking the hyperlinks should get you everywhere in the book pretty nicely. Go to mastertoc","title":"Welcome"},{"location":"mastertoc/","text":"Table of Contents \u00b6 This note is the master toc. It splits into the toc of subjects: EECS, MSE, Physics, Math toc EECS [[toc MSE]] toc Physics [[toc Math]] Brief Blurb on These Notes \u00b6 I have decided to compile all my notes here, aimed towards possibly helping future students who are taking the class in understanding the material. However, it is mainly a place for me to try and explain concepts in my own words, so the tone and style will be very conversational. Maybe that is a good thing. Some of the notes results directly from taking the class. Other notes come from combined knowledge of subjects, and trying to put it somewhere (mostly the math and physics subjects will be that). Some notes are a result of being a part of course staff or mentoring for the course (such as CS 61A, CS 61C). Other notes are notes I take for the class (such as the physics classes). Obviously, the notes meant for teaching will be done in a more student focused way and comprehensive, and the notes for learning can be a bit broken and segmented, so take these ideas into consideration. Notes I'm Planning on making into teaching notes in order of when I am planning on doing them. CS 61A (Work in Progress) CS 61C (Work in Progress) EECS 16A/Math 54 (Planned) CS 61B (Planned)","title":"Table of Contents"},{"location":"mastertoc/#table-of-contents","text":"This note is the master toc. It splits into the toc of subjects: EECS, MSE, Physics, Math toc EECS [[toc MSE]] toc Physics [[toc Math]]","title":"Table of Contents"},{"location":"mastertoc/#brief-blurb-on-these-notes","text":"I have decided to compile all my notes here, aimed towards possibly helping future students who are taking the class in understanding the material. However, it is mainly a place for me to try and explain concepts in my own words, so the tone and style will be very conversational. Maybe that is a good thing. Some of the notes results directly from taking the class. Other notes come from combined knowledge of subjects, and trying to put it somewhere (mostly the math and physics subjects will be that). Some notes are a result of being a part of course staff or mentoring for the course (such as CS 61A, CS 61C). Other notes are notes I take for the class (such as the physics classes). Obviously, the notes meant for teaching will be done in a more student focused way and comprehensive, and the notes for learning can be a bit broken and segmented, so take these ideas into consideration. Notes I'm Planning on making into teaching notes in order of when I am planning on doing them. CS 61A (Work in Progress) CS 61C (Work in Progress) EECS 16A/Math 54 (Planned) CS 61B (Planned)","title":"Brief Blurb on These Notes"},{"location":"EECS/toc%20EECS/","text":"Table of Contents \u00b6 This note serves as the EECS toc. Get back to mastertoc Navigate to the toc of a specific class: - toc CS61A The Structure and Interpretation of Computer Programs (WIP) - toc CS61B Data Structures (Not started) - toc CS61C Great Ideas in Computer Architecture (WIP) - toc CS161 Computer Security (Class in Progress) - toc CS168 Introduction to the Internet: Architecture and Protocols (Class in Progress) - toc EECS 16A Designing Information Devices and Systems (Not Started) - toc EECS 151 Introduction to Digital Design and Integrated Circuits (Class in Progress) Here are all the information in each toc: CS 61A: The Structure and Interpretation of Computer Programs CS 61B: Data Structures CS 61C: Great Ideas in Computer Architecture 0. Introduction to CS 61C 1. Number Representation - 1.1 Decmial, Binary, and Hexadecimal Number Systems - 1.2 Signed Representations - 1.3 Floating Point Representation","title":"Table of Contents"},{"location":"EECS/toc%20EECS/#table-of-contents","text":"This note serves as the EECS toc. Get back to mastertoc Navigate to the toc of a specific class: - toc CS61A The Structure and Interpretation of Computer Programs (WIP) - toc CS61B Data Structures (Not started) - toc CS61C Great Ideas in Computer Architecture (WIP) - toc CS161 Computer Security (Class in Progress) - toc CS168 Introduction to the Internet: Architecture and Protocols (Class in Progress) - toc EECS 16A Designing Information Devices and Systems (Not Started) - toc EECS 151 Introduction to Digital Design and Integrated Circuits (Class in Progress) Here are all the information in each toc: CS 61A: The Structure and Interpretation of Computer Programs CS 61B: Data Structures CS 61C: Great Ideas in Computer Architecture 0. Introduction to CS 61C 1. Number Representation - 1.1 Decmial, Binary, and Hexadecimal Number Systems - 1.2 Signed Representations - 1.3 Floating Point Representation","title":"Table of Contents"},{"location":"EECS/CS%20161/toc%20CS161/","text":"Table of Contents CS 161 \u00b6 This note is the table of contents for CS 161 Contents [[Security Principles]] 1. Security Principles [[Memory Safety]] 2. x86 Assembly and Call Stack 3. Memory Safety Vulnerabilities 4. Mitigating Memory-Safety Vulnerabilities [[Cryptography]] 5. Introduction to Cryptography [[6. Symmetric-Key Cryptography]] [[Cryptographic Hashes]] [[8. Message Authentication Codes (MACs)]] [[9. Pseudorandom Number Generators]]","title":"Table of Contents CS 161"},{"location":"EECS/CS%20161/toc%20CS161/#table-of-contents-cs-161","text":"This note is the table of contents for CS 161 Contents [[Security Principles]] 1. Security Principles [[Memory Safety]] 2. x86 Assembly and Call Stack 3. Memory Safety Vulnerabilities 4. Mitigating Memory-Safety Vulnerabilities [[Cryptography]] 5. Introduction to Cryptography [[6. Symmetric-Key Cryptography]] [[Cryptographic Hashes]] [[8. Message Authentication Codes (MACs)]] [[9. Pseudorandom Number Generators]]","title":"Table of Contents CS 161"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/","text":"5. Introduction to Cryptography \u00b6 This not talks about the idea of cryptography, starting with a brief history, and then talking about some terms that will be used in future notes. Brief History of Cryptography \u00b6 Cryptography comes from Latin roots crypt, and graphia, meaning secret writing. Schemes for sending secret messages go back to antiquity. Caesar created the \"Caesar cypher,\" which consists of permuting the alphabet by some fixed amount. The second phase of cryptography, the \"mechanical era,\" found cryptographers using mechanical devices to encode and decode messages. The German project \"Enigma\" found a way to encrypt a message that seemed unbreakable. However, the British did find a way to break the Enigma code, which probably shorted the war by about a year. Modern cryptography is distringuished by its reliance on mathematics and electronic computers. Its early roots are found in the work of Claude Shannon following WW2. 1970s saw the introduction of a standardized cryptosystem, DES, by the National Insitute for Standards in Technology (NIST). DES answered the growing need for digital encryption standards in banking and other businesses. After the 1970s, we saw an explosion of work on a computational theory of cryptography. Definitions \u00b6 Alice, Bob, Eve, and Mallory \u00b6 Alice and Bob wish to communicate securely as though they were in the same room or were provided with a dedicated, untappable line. However, they are subject to tapping by an eavesdropping adversary, Eve. Sometimes, Eve might be replaced with Mallory, who can tamper with communications in addition to eavesdropping on them. Our goal will be designing a scheme to scramble messages between Alice and Bob such that Eve has no clue about the contents of their exchange, and Mallory is unable to tamper with the contnts of their exchange without being detected. Keys \u00b6 A key is the most basic building block of any cryptographic system. The key is a secret value that helps us secure messages. There are two main key models in modern cryptogrpahy 1. Symmetric key model: Alice and Bob both know the value of a secret key, and must secure their communications using this shared secret value 2. Asymmetric key model: each person has a secret key and a corresponding public key. Confidentiality, Integrity, Authenticity \u00b6 Confidentiality is the property that prevents adversaries from reading our private data. If a message is confidential, then an attacker does not know its contents. Many cryptographic algorithms that guarantee confidentiality work as follows: Alice uses a key to encrypt a message by changing it into a scrambled form that the attacker cannot read. She then sends this encrypted message over the insecure channel to Bob When Bob receives the encrypted message, he uses the key to decrpt the message by changing it back to its original form Call the message \"plaintext\" when it is unencrypted and \"ciphertext\" when it is encrypted. Even if the atttacker can see the encrypted ciphertext, they should not be able to decrypt it back into the corresponding plaintext Integrity is the property that prevents adversaries from tampering with our private data. If a message has integrity, then an attacker cannot chang its contents without being detected. Authenticity is the property that lets us determine who created a given message. If a message has authenticity, then we can be sure that the message was written by the person who claims to have written it. Most cryptographic algorithms that guarantee integrity and authenticity work as follows: Alice generates a tag or signature on a message. She then sends it to Bob When Bob receives the message and the tag, he verifies that the tag is valid for th e message that was sent. If the message was modified by an attacker, the tag should no longer be valid, and Bob's verification will fail. This lets Bob detect altered messages. The attacker should not be able to generate valid tags for their malicious messages Another property is deniability. If Alice and Bob want to communicate securely, Alice might want to publish a message from Bob and show it to a judge, claiming that it came from Bob. If the cryptosystem has deniability, there is no cryptographic proof available to guarantee that Alice's published message came from Bob. For example, consider a case where Alice and Bob use the same key to generate a signature on a message, and Alice publishes a message with a valid signature. Then the judge cannot be sure that the message came from Bob\u2013the signature could have plausibly been created by Alice. Overview of Schemes \u00b6 Let's look at cryptographic primitives that provide confidentiality, integrity, and authentication in both the symmetric-key and asymmetric-key settings. Symmetric-key encryption: Alice uses her secret key to encrypt a message, Bob uses the same secret key to decrypt the message Public-key encryption: Bob generates a matching public key and private key, and shares the public key with Alice (but does not share the private key with anyone). Alice can encrypt her message under Bob's public key, and then Bob will be able to decrypt using his private key. In syymmetric key setting, message authentication codes (MACs) provide integrity and authenticity. Alice uses the shared secret key to generate a MAC on her message, and Bob uses the same secret key to verify the MAC. In asymmetric-key setting, public-key signatures (known as digital signatures) provide integrity and authenticity. Alice generates a matching public and private key, and shares the public key with Bob. Alice computes a digital signature of her message using her private key, and appends the signature to her message. When Bob receives the mssage and its signature, he will be able to use Alice's public key to verify that no one has tampered with or modified the message. Here are some other primitives. They don't guarantee confidentiality, integrity, or authenticity by themselves, but they have desirable properties that will help s build secure cryptosystems: 3. Cryptographic hashes: provide a one way digest. They enable someone to condense a long message into a short sequence of what appear to be random bits. They are irreversible, so you can't go from the resulting hash back to the original message but you can quickly verify that a message has a given hash 4. Pseudorandom number generator: process which takes a small amount of true randomness and stretches it into a long sequence that should be indistinguishable from actual random data 5. Key exchange schemes: (e.g Diffie-Hellman key exchange) will allow Allice and Bob to use an insecure communication channel to agree on a shared random secret key that is subsequently used for symmetric-key encryption. Kerckhoff's Principle \u00b6 Cryptosystems should remain secure even when the attacker knows all internal details of the system. The key should be the only thing that must be kept secret, and the system should be designed to make it easy to change keys that are leaked (or suspected to be leaked). If your secrets are leaked, it is usually a lot easier to change the key than to replace every instance of the running software. (This principle is closely related to Shannon\u2019s Maxim: Don\u2019t rely on security through obscurity.) 1. Security Principles . We will assume that the attacker knows the encryption and decryption algorithms. The only information the attacker is missing is the secret key(s). Threat Models \u00b6 Here are several possibilites about how much access an eavesdropping attacker Eve has to the insecure channel: 1. Eve has managed to intercept a single encrypted message and wishes to recover the plaintext. This is known as ciphertext-only attack 2. Eve has intercepted an encrypted message and also already has some partial info about the plaintext, which helps with deducing the nature of the encryption. This is known as known plaintext attack 3. Even can capture an encrypted message from Alice and Bob and re-send the encrypted message to Bob again. This is known as a replay attack. \u201cHey Bob\u2019s Automatic Payment System: pay Eve $100\u201d and sends it repeatedly to Bob so Eve gets paid multiple times. Eve might not know the decryption of the message, but she can still send the encryption repeatedly to carry out the attack. 4. Eve can trick Alice to encrypt arbitrary messages of Eve's choice, for which Even can then observe the resulting ciphertexts. At some other point in time, Alice encrypts a message that is unknown to Eve; Eve intercepts the encryption of Alice's message and aims to recover the message given what Eve has observed about previous encryptions. This is known as chosen-plaintext attack 5. Even can trick Bob into decrypting some ciphertexts. Eve would like to use this to learn the decryption of some othe rciphertext. This is known as chosen-ciphertext attack 6. Even can do a combination of the previous two cases, tricking Alice into encrypting some messages of Eve's choosing, and trick Bob into decrypting ciphertexts of Eve's choosing. This case is known as chosen-plaintext/ciphetext attack, and is the most serious threat model. Today, we usually insist that our encryption algorithms provide security against chosen-plaintext/ciphertext attacks, both because those attacks are practical in some settings, and because it is in fact feasible to provide good security even against this very powerful attack model. However, for simplicity, this class will focus primarily on security against chosen-plaintext attacks.","title":"5. Introduction to Cryptography"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/#5-introduction-to-cryptography","text":"This not talks about the idea of cryptography, starting with a brief history, and then talking about some terms that will be used in future notes.","title":"5. Introduction to Cryptography"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/#brief-history-of-cryptography","text":"Cryptography comes from Latin roots crypt, and graphia, meaning secret writing. Schemes for sending secret messages go back to antiquity. Caesar created the \"Caesar cypher,\" which consists of permuting the alphabet by some fixed amount. The second phase of cryptography, the \"mechanical era,\" found cryptographers using mechanical devices to encode and decode messages. The German project \"Enigma\" found a way to encrypt a message that seemed unbreakable. However, the British did find a way to break the Enigma code, which probably shorted the war by about a year. Modern cryptography is distringuished by its reliance on mathematics and electronic computers. Its early roots are found in the work of Claude Shannon following WW2. 1970s saw the introduction of a standardized cryptosystem, DES, by the National Insitute for Standards in Technology (NIST). DES answered the growing need for digital encryption standards in banking and other businesses. After the 1970s, we saw an explosion of work on a computational theory of cryptography.","title":"Brief History of Cryptography"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/#definitions","text":"","title":"Definitions"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/#alice-bob-eve-and-mallory","text":"Alice and Bob wish to communicate securely as though they were in the same room or were provided with a dedicated, untappable line. However, they are subject to tapping by an eavesdropping adversary, Eve. Sometimes, Eve might be replaced with Mallory, who can tamper with communications in addition to eavesdropping on them. Our goal will be designing a scheme to scramble messages between Alice and Bob such that Eve has no clue about the contents of their exchange, and Mallory is unable to tamper with the contnts of their exchange without being detected.","title":"Alice, Bob, Eve, and Mallory"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/#keys","text":"A key is the most basic building block of any cryptographic system. The key is a secret value that helps us secure messages. There are two main key models in modern cryptogrpahy 1. Symmetric key model: Alice and Bob both know the value of a secret key, and must secure their communications using this shared secret value 2. Asymmetric key model: each person has a secret key and a corresponding public key.","title":"Keys"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/#confidentiality-integrity-authenticity","text":"Confidentiality is the property that prevents adversaries from reading our private data. If a message is confidential, then an attacker does not know its contents. Many cryptographic algorithms that guarantee confidentiality work as follows: Alice uses a key to encrypt a message by changing it into a scrambled form that the attacker cannot read. She then sends this encrypted message over the insecure channel to Bob When Bob receives the encrypted message, he uses the key to decrpt the message by changing it back to its original form Call the message \"plaintext\" when it is unencrypted and \"ciphertext\" when it is encrypted. Even if the atttacker can see the encrypted ciphertext, they should not be able to decrypt it back into the corresponding plaintext Integrity is the property that prevents adversaries from tampering with our private data. If a message has integrity, then an attacker cannot chang its contents without being detected. Authenticity is the property that lets us determine who created a given message. If a message has authenticity, then we can be sure that the message was written by the person who claims to have written it. Most cryptographic algorithms that guarantee integrity and authenticity work as follows: Alice generates a tag or signature on a message. She then sends it to Bob When Bob receives the message and the tag, he verifies that the tag is valid for th e message that was sent. If the message was modified by an attacker, the tag should no longer be valid, and Bob's verification will fail. This lets Bob detect altered messages. The attacker should not be able to generate valid tags for their malicious messages Another property is deniability. If Alice and Bob want to communicate securely, Alice might want to publish a message from Bob and show it to a judge, claiming that it came from Bob. If the cryptosystem has deniability, there is no cryptographic proof available to guarantee that Alice's published message came from Bob. For example, consider a case where Alice and Bob use the same key to generate a signature on a message, and Alice publishes a message with a valid signature. Then the judge cannot be sure that the message came from Bob\u2013the signature could have plausibly been created by Alice.","title":"Confidentiality, Integrity, Authenticity"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/#overview-of-schemes","text":"Let's look at cryptographic primitives that provide confidentiality, integrity, and authentication in both the symmetric-key and asymmetric-key settings. Symmetric-key encryption: Alice uses her secret key to encrypt a message, Bob uses the same secret key to decrypt the message Public-key encryption: Bob generates a matching public key and private key, and shares the public key with Alice (but does not share the private key with anyone). Alice can encrypt her message under Bob's public key, and then Bob will be able to decrypt using his private key. In syymmetric key setting, message authentication codes (MACs) provide integrity and authenticity. Alice uses the shared secret key to generate a MAC on her message, and Bob uses the same secret key to verify the MAC. In asymmetric-key setting, public-key signatures (known as digital signatures) provide integrity and authenticity. Alice generates a matching public and private key, and shares the public key with Bob. Alice computes a digital signature of her message using her private key, and appends the signature to her message. When Bob receives the mssage and its signature, he will be able to use Alice's public key to verify that no one has tampered with or modified the message. Here are some other primitives. They don't guarantee confidentiality, integrity, or authenticity by themselves, but they have desirable properties that will help s build secure cryptosystems: 3. Cryptographic hashes: provide a one way digest. They enable someone to condense a long message into a short sequence of what appear to be random bits. They are irreversible, so you can't go from the resulting hash back to the original message but you can quickly verify that a message has a given hash 4. Pseudorandom number generator: process which takes a small amount of true randomness and stretches it into a long sequence that should be indistinguishable from actual random data 5. Key exchange schemes: (e.g Diffie-Hellman key exchange) will allow Allice and Bob to use an insecure communication channel to agree on a shared random secret key that is subsequently used for symmetric-key encryption.","title":"Overview of Schemes"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/#kerckhoffs-principle","text":"Cryptosystems should remain secure even when the attacker knows all internal details of the system. The key should be the only thing that must be kept secret, and the system should be designed to make it easy to change keys that are leaked (or suspected to be leaked). If your secrets are leaked, it is usually a lot easier to change the key than to replace every instance of the running software. (This principle is closely related to Shannon\u2019s Maxim: Don\u2019t rely on security through obscurity.) 1. Security Principles . We will assume that the attacker knows the encryption and decryption algorithms. The only information the attacker is missing is the secret key(s).","title":"Kerckhoff's Principle"},{"location":"EECS/CS%20161/Cryptography/5.%20Introduction%20to%20Cryptography/#threat-models","text":"Here are several possibilites about how much access an eavesdropping attacker Eve has to the insecure channel: 1. Eve has managed to intercept a single encrypted message and wishes to recover the plaintext. This is known as ciphertext-only attack 2. Eve has intercepted an encrypted message and also already has some partial info about the plaintext, which helps with deducing the nature of the encryption. This is known as known plaintext attack 3. Even can capture an encrypted message from Alice and Bob and re-send the encrypted message to Bob again. This is known as a replay attack. \u201cHey Bob\u2019s Automatic Payment System: pay Eve $100\u201d and sends it repeatedly to Bob so Eve gets paid multiple times. Eve might not know the decryption of the message, but she can still send the encryption repeatedly to carry out the attack. 4. Eve can trick Alice to encrypt arbitrary messages of Eve's choice, for which Even can then observe the resulting ciphertexts. At some other point in time, Alice encrypts a message that is unknown to Eve; Eve intercepts the encryption of Alice's message and aims to recover the message given what Eve has observed about previous encryptions. This is known as chosen-plaintext attack 5. Even can trick Bob into decrypting some ciphertexts. Eve would like to use this to learn the decryption of some othe rciphertext. This is known as chosen-ciphertext attack 6. Even can do a combination of the previous two cases, tricking Alice into encrypting some messages of Eve's choosing, and trick Bob into decrypting ciphertexts of Eve's choosing. This case is known as chosen-plaintext/ciphetext attack, and is the most serious threat model. Today, we usually insist that our encryption algorithms provide security against chosen-plaintext/ciphertext attacks, both because those attacks are practical in some settings, and because it is in fact feasible to provide good security even against this very powerful attack model. However, for simplicity, this class will focus primarily on security against chosen-plaintext attacks.","title":"Threat Models"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/","text":"6. Symmetric-Key Encryption \u00b6 IND-CPA Security \u00b6 Recall confidentiality means that an attacker cannot read our messages. However, let's make it more precise and rigorious: The cipher text $C$ should give the attacker no additional information about the message $M$. In other words, the attacker should not learn any new information about $M$ beyond what they already knew before seeing $C$. Further formalize via experiment. Alice has encrypted and sent one of two messages, either \\(M_0\\) or \\(M_1\\) , and Eve has no idea which was sent. Eve tries to guess which was sent by looking at the cipher text. If the encryption scheme is confidential, then Eve's probability of guessing which message was sent should be 1/2, which is the same probability if she had not intercepted the ciphertext at all, and was instead guessing at random. Our definition says that even if Eve can trick Alice into encrypting some messages, she still cannot distinguish whether Alice sent \\(M_0\\) or \\(M_1\\) in the experiment. This definition is known as indistinguishability under chosen plaintext attack, or IND-CPA. It works as follows: 1. Eve chooses two different messages \\(M_0\\) , and \\(M_1\\) , and sends both messages to Alice 2. Alice flips a fair coin. If the coin is heads, she encrypts \\(M_0\\) . If the coin is tails, she encrypts \\(M_1\\) . More formally, Alice will choose a bit \\(b \\in\\{0, 1\\}\\) uniformly at random, and then encrypts \\(M_b\\) . Alice sends the encrypted message \\(Enc(K, M_b)\\) back to Eve 3. Eve is now allowed to ask Alice for encryptions of messages of Eve's choosing. Eve can send a plaintext message with the secret key. Eve is allowed to repeat this as many times as she wants. Intuitively, this steps is allowing Eve to perform a chosen-plaintext attack in an attempt to learn something about which message was sent 4. After Eve is finished asking for encryptions, she must guess whether the encrypted message from step 2 is the encryption of \\(M_0\\) or \\(M_1\\) . If Eve can guess which message was sent with probability > 1/2, she wins, and the scheme is not IND-CPA secure. Some restrictions: \\(M_0\\) and \\(M_1\\) must be the same length. Eve is limited to a practical number of encryption requests. Eve only wins if she has a non-negligible advantage. XOR Review \u00b6 Symmetric-key encryption often relies on the bitwise XOR operation. Some properties of the XOR operations: \\[ \\begin{align*} x\\oplus 0 &= x\\\\ x\\oplus x &= 0\\\\ x\\oplus y &= y\\oplus x\\\\ (x\\oplus y) \\oplus z &= x\\oplus (y\\oplus z)\\\\ x\\oplus y\\oplus x &= y \\end{align*} \\] The last one is important to note. Given \\(x\\oplus y\\) , you can retrieve \\(y\\) by XOR'ing with \\(x\\) , cancelling out the \\(x\\) . This allows us to perform algebra with XOR: \\[ \\begin{align*} y\\oplus 1 &= 0\\\\ y\\oplus 1\\oplus 1 &= 0\\oplus 1\\\\ y &= 1 \\end{align*} \\] One Time Pad \u00b6 One Time Pad is a symmetric encryption scheme. Alice and Bob share an \\(n\\) -bit secret key \\(K= k_1\\cdots k_n\\) . The bits are picked uniformly at random. To send an \\(n\\) -bit message \\(M=m_1\\cdots m_n\\) , we want the desired properties: 1. It should scramble up the message, i.e., map it to a ciphertext \\(C = c_1\\cdots c_n\\) . 2. Given knowledge of the secret key \\(K\\) , it should be easy to recover \\(M\\) from \\(C\\) . 3. Eve, who does not know \\(K\\) , should get no information about \\(M\\) . How to do it: for encryption \\[ c_j = m_j \\oplus k_j \\] for decryption \\[ \\begin{align*} c_j &= m_j \\oplus k_j\\\\ c_j\\oplus k_j &= m_j\\oplus k_j\\oplus k_j\\\\ c_j\\oplus k_j &= m_j \\end{align*} \\] Maybe more summarizable: Alice and Bob pick a shared random key \\(K\\) . Encryption: \\(C = M\\oplus K\\) Decryption: \\(M = C\\oplus K\\) Proof that One-Time Pad is IND-CPA Secure \u00b6 For a fixed choice of plaintext \\(M\\) , every possible value of ciphertext \\(C\\) can be achieved by an appropriate and unique choice of the shared key \\(K\\) , namely \\(K = M\\oplus C\\) . Since each such key value is equally likely, it follows that \\(C\\) is also equally likely to be any n-bit string. Eve thus sees a uniformly random \\(n\\) bit string no matter what the plaintext message was, and thus gets no information about which of the two messages was encrypted. Suppose Eve observes a ciphertext \\(C\\) , and knows the message \\(M\\) is either \\(M_0\\) or \\(M_1\\) . The probability space here is \\(2^{n+1}\\) since there are \\(2^n\\) choices for the n-bit key \\(K\\) , as well as the challenger's choice of whether to send \\(M_0\\) or \\(M_1\\) . All choices are equally likely. Assume key \\(K\\) is generated uniformly at random; then the challenger randomly chooses a bit \\(b\\in\\{0, 1\\}\\) , and Alice sends the encryption of \\(M_b\\) . So, if Eve observes that the cipher text has some specific value \\(C\\) , what is the conditional probability that \\(b = 0\\) given her observation? \\[ \\begin{align*} P(b=0|\\text{ciphertext} = C) &= \\frac{P(b = 0 \\land \\text{ciphertext = C})}{P(\\text{ciphertext} = C)}\\\\ &=\\frac{P(b=0\\land K = M_0\\oplus C)}{P(\\text{ciphertext} = C)}\\\\ & = \\frac{(1/2)(1/2^n)}{1/2^n}\\\\ & = \\frac{1}{2} \\end{align*} \\] Drawback of one time pad: Shared key cannot be reused to transmit another message \\(M'\\) . If \\(K\\) is reused to encrypt two messages \\(M\\) and \\(M'\\) , then Eve can XOR the two ciphertexts \\(C = M\\oplus K\\) and \\(C' = M'\\oplus K\\) to obtain \\(C\\oplus C' = M\\oplus M'\\) . If Eve happens to learn \\(M\\) , then she can easily deduce the other message \\(M'\\) . But she can also just reconstruct the key \\(K\\) too. Even if Eve does not know \\(M\\) or \\(M'\\) , there is often enough redundancy in messages that merely knowing \\(M\\oplus M'\\) is enough to recover most of the messages. In general, one-time pad is not secure if the key is used to encrypt more than one message. Block Ciphers \u00b6 Block cipher transforms a fixed-length \\(n\\) -bit input into a fixed-length \\(n\\) -bit output. The block cipher has \\(2^k\\) different settings for scrambling, so it also takes in a \\(k\\) -bit key as input, where each key corresponds to a different scrambling setting. Given a fixed key, the block cipher encryption must map each of the \\(2^n\\) possible plaintext inputs to a different ciphertext output. The block cipher encryption must map uniquely, so that there is some inverse operation that decrypts it. This means block cipher is deterministic. Mathematically: There is an encryption function \\(E : \\{0, 1\\}^k \\times \\{0, 1\\} \\rightarrow \\{0, 1\\}^n\\) . Once we fix a key \\(K\\) , the function maps \\(E_K: \\{0, 1\\}^n\\rightarrow \\{0, 1\\}^n\\) , defined by \\(E_K(M) = E(K, M)\\) . We require \\(E_K\\) to be a permutation on the n-bit strings, so it is invertible (bijective). The inverse mapping of this permutation is the decryption algorithm \\(D_K\\) . In other words, \\(D_K(E_K(M)) = M\\) . Block Cipher Security \u00b6 Block ciphers are not IND-CPA secure on their own because they are deterministic. In other words, encrypting the same message twice with the same key produces the same output twice. Eve sends \\(M_0\\) and \\(M_1\\) to be encrypted, then queries the challenger for the encryption of \\(M_0\\) and receives the same encryption. If the two encryptions she receives from the challenger are the same, then Eve knows the challenger encrypted \\(M_0\\) and sent \\(E(K, M_0\\) ) otherwise they encrypted \\(M_1\\) . Altough they are not IND-CPA secure, they have a desirable security property that helps us build IND-CPA secure symmetric encryption schemes: a block cipher is computationally indistinguishable from a random permutation. A random permutation is a function that maps each \\(n\\) -bit input to exactly one \\(n\\) -bit random output. AES is not truly indistinguishable from random, but is believed to be computationally indistinguishable from random. Intuitively, this means that given a practical amount of computation power, Eve cannot guess which type of permutation she received. This gives a strong security guarantee. given a single ciphertext \\(C = E_K(M)\\) , an attacker without the key cannot learn anything about the original message \\(M\\) . If the attacker could learn something about \\(M\\) , then AES would no longer be computationally indistinguishable. There is no proof that AES is computationally indistinguishable from random, but it is believed to be computationally indistinguishable. Block Cipher Modes of Operation \u00b6 Why AES cannot be a practical IND-CPA secure encryption scheme: 1. We would like to encrypt arbitrarily long messages, but the block cipher only takes fixed-length inputs 2. If the same message is sent twice, the ciphertext in the two transmissions is the same with AES. To fix these problems, the encryption algorithm can be randomized or stateful. Several standard ways of building an encryption algorithm, using a block cipher Electronic Code Book (ECB) Mode \u00b6 The plaintext \\(M\\) is simply broken into \\(n\\) -bit blocks \\(M_1\\cdots M_l\\) , and each block is encoded using the block cipher \\(C_i = E_K(M_i)\\) . The ciphertext is just a concatenation of these individual blocks: \\(C = C_1\\cdot C_2\\cdots C_l\\) . This scheme is flawed. Any redundancy in the blocks will show through and allow the eavesdropper to deduce information about the plaintext. If, for instance \\(M_i = M_j\\) , then \\(C_i = C_j\\) . ECB mode leaks information about the plaintext Encryption: C_i = E_K(M_i) Decryption: M_i = D_K(C_i) Cipher Block Chaining (CBC) Mode \u00b6 For each message, the sender picks a random \\(n\\) -bit string, called the initial vector (IV). Define \\(C_0 = IV\\) . The \\(i\\) th ciphertext block is given by \\(C_i = E_K(C_{i-1}\\oplus M_i)\\) . The ciphertext is the concatenation of the initial vector and these individual blocks \\(C = IV\\cdot C_1\\cdot C_2\\cdots C_l\\) . CBC mode has been proven to provide strong security guarantees on the privacy of the plaintext message Encryption: \\(C_0 = IV;\\;\\; C_i = E_K(P_i\\oplus C_{i-1})\\) Decryption: \\(P_i = D_K(C_i)\\oplus C_{i-1}\\) Ciphertext Feedback (CFB) Mode \u00b6 \\(C_0\\) is again the IV. The \\(i\\) th ciphertext block is now given by \\(C_i = E_K(C_{i-1})\\oplus M_i\\) . Encryption: \\(C_0 = IV;\\;\\;\\; C_i = E_K(C_{i-1})\\oplus P_i\\) Decryption: \\(P_i = E_K(C_{i-1})\\oplus C_i\\) Output Feedback (OFB) Mode \u00b6 The initial vector is repeatedly encrypted to obtain a set of values \\(Z_i\\) as follows: \\(Z_0 = IV\\) and \\(Z_i = E_K(Z_{i-1})\\) . These values \\(Z_i\\) are now used as though they were the key for a one-tie pad, so that \\(C_i = Z_i\\oplus M_i\\) . The ciphertext is the concatenation of the IV and these individual blocks: \\(C = IV\\cdot C_1\\cdot C_2\\cdots C_l\\) . In OFB, it is easy to tampe with ciphertexts. Suppose that the adversary happens to know that the \\(j\\) th block of the message \\(M_j\\) , specifies the amount of money being transferred to his account from the bank, and suppose he knows that \\(M_j = 100\\) . Since he knows both \\(M_j\\) and \\(C_j\\) , he can determine \\(Z_j\\) . He can then substitute any \\(n\\) -bit block in place of \\(M_j\\) and get a new ciphertext \\(C'_j\\) where 100 is replaced by any amount of his choice. Encryption: \\(Z*0 = IV;\\;\\;\\; Z_i = E_K(Z*i-1);\\;\\;\\; C_i = M_i\\oplus Z_i\\) Decyption: \\(P_i = C_i\\oplus Z_i\\) Counter (CTR) Mode \u00b6 A counter is initialized to IV and repeatedly incremented and encrypted to obtain a sequence that can now be used as though they were they keys for a one-time pad, namely \\(Z_i = E_K(IV + i)\\) and \\(C_i = Z_i\\oplus M_i\\) . In CTR, the IV is renamed the nonce. Encryption: \\(C_i = E_K(IV + i) \\oplus M_i\\) Decryption: \\(M_i = E_K(IV + i) \\oplus C_i\\) Parallelization \u00b6 Some modes require successive blocks to be encrypted or decrypted sequentially, but some of them can be parallelized: CBC encryption cannot be parallized since it depends on \\(C_{i-1}\\) . CBC decryption can be parallelized. Since we already have all the ciphertext blocks CTR encryption and decryption can both be parallelized. Padding \u00b6 Recall that block ciphers let us encrypt messages that are longer than one block long. What happens if we want to send a message that is not a multiple of the block size? It will depends on which mode is being used. Let's assume the block size is 128 bits (16 characters). CBC: if the plaintext isn't a multiple of 128 bits, then the last block of plaintext will be slightly shorter than 128 bits. The XOR would be undefined-bitwise XOR. The solution is to pad the plaintext until it is a multiple of 128 bits. But that means we have to remove the padding in decryption. PKCS#7 padding pads the message by the number of padding bytes used. This allows the decryption to understand how much bytes to remove. Not all modes need to be padded. CTR doesn't because the result of XOR never has to be passed into a block cipher again at the end, so the 100 bits left is fine. Reusing IVs is Insecure \u00b6 Recall ECB is not IND-CPA because it is deterministic. Encrypting the same plaintext twice produces the same output, and this causes information leakage. All other modes introduce a random initialization vector IV that is different on every encryption in order to ensure that encrypting the same plaintext twice with the same key results in different output. However, reusing IV in CTR is equivalent to reusing the one-time pad.","title":"6. Symmetric-Key Encryption"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#6-symmetric-key-encryption","text":"","title":"6. Symmetric-Key Encryption"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#ind-cpa-security","text":"Recall confidentiality means that an attacker cannot read our messages. However, let's make it more precise and rigorious: The cipher text $C$ should give the attacker no additional information about the message $M$. In other words, the attacker should not learn any new information about $M$ beyond what they already knew before seeing $C$. Further formalize via experiment. Alice has encrypted and sent one of two messages, either \\(M_0\\) or \\(M_1\\) , and Eve has no idea which was sent. Eve tries to guess which was sent by looking at the cipher text. If the encryption scheme is confidential, then Eve's probability of guessing which message was sent should be 1/2, which is the same probability if she had not intercepted the ciphertext at all, and was instead guessing at random. Our definition says that even if Eve can trick Alice into encrypting some messages, she still cannot distinguish whether Alice sent \\(M_0\\) or \\(M_1\\) in the experiment. This definition is known as indistinguishability under chosen plaintext attack, or IND-CPA. It works as follows: 1. Eve chooses two different messages \\(M_0\\) , and \\(M_1\\) , and sends both messages to Alice 2. Alice flips a fair coin. If the coin is heads, she encrypts \\(M_0\\) . If the coin is tails, she encrypts \\(M_1\\) . More formally, Alice will choose a bit \\(b \\in\\{0, 1\\}\\) uniformly at random, and then encrypts \\(M_b\\) . Alice sends the encrypted message \\(Enc(K, M_b)\\) back to Eve 3. Eve is now allowed to ask Alice for encryptions of messages of Eve's choosing. Eve can send a plaintext message with the secret key. Eve is allowed to repeat this as many times as she wants. Intuitively, this steps is allowing Eve to perform a chosen-plaintext attack in an attempt to learn something about which message was sent 4. After Eve is finished asking for encryptions, she must guess whether the encrypted message from step 2 is the encryption of \\(M_0\\) or \\(M_1\\) . If Eve can guess which message was sent with probability > 1/2, she wins, and the scheme is not IND-CPA secure. Some restrictions: \\(M_0\\) and \\(M_1\\) must be the same length. Eve is limited to a practical number of encryption requests. Eve only wins if she has a non-negligible advantage.","title":"IND-CPA Security"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#xor-review","text":"Symmetric-key encryption often relies on the bitwise XOR operation. Some properties of the XOR operations: \\[ \\begin{align*} x\\oplus 0 &= x\\\\ x\\oplus x &= 0\\\\ x\\oplus y &= y\\oplus x\\\\ (x\\oplus y) \\oplus z &= x\\oplus (y\\oplus z)\\\\ x\\oplus y\\oplus x &= y \\end{align*} \\] The last one is important to note. Given \\(x\\oplus y\\) , you can retrieve \\(y\\) by XOR'ing with \\(x\\) , cancelling out the \\(x\\) . This allows us to perform algebra with XOR: \\[ \\begin{align*} y\\oplus 1 &= 0\\\\ y\\oplus 1\\oplus 1 &= 0\\oplus 1\\\\ y &= 1 \\end{align*} \\]","title":"XOR Review"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#one-time-pad","text":"One Time Pad is a symmetric encryption scheme. Alice and Bob share an \\(n\\) -bit secret key \\(K= k_1\\cdots k_n\\) . The bits are picked uniformly at random. To send an \\(n\\) -bit message \\(M=m_1\\cdots m_n\\) , we want the desired properties: 1. It should scramble up the message, i.e., map it to a ciphertext \\(C = c_1\\cdots c_n\\) . 2. Given knowledge of the secret key \\(K\\) , it should be easy to recover \\(M\\) from \\(C\\) . 3. Eve, who does not know \\(K\\) , should get no information about \\(M\\) . How to do it: for encryption \\[ c_j = m_j \\oplus k_j \\] for decryption \\[ \\begin{align*} c_j &= m_j \\oplus k_j\\\\ c_j\\oplus k_j &= m_j\\oplus k_j\\oplus k_j\\\\ c_j\\oplus k_j &= m_j \\end{align*} \\] Maybe more summarizable: Alice and Bob pick a shared random key \\(K\\) . Encryption: \\(C = M\\oplus K\\) Decryption: \\(M = C\\oplus K\\)","title":"One Time Pad"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#proof-that-one-time-pad-is-ind-cpa-secure","text":"For a fixed choice of plaintext \\(M\\) , every possible value of ciphertext \\(C\\) can be achieved by an appropriate and unique choice of the shared key \\(K\\) , namely \\(K = M\\oplus C\\) . Since each such key value is equally likely, it follows that \\(C\\) is also equally likely to be any n-bit string. Eve thus sees a uniformly random \\(n\\) bit string no matter what the plaintext message was, and thus gets no information about which of the two messages was encrypted. Suppose Eve observes a ciphertext \\(C\\) , and knows the message \\(M\\) is either \\(M_0\\) or \\(M_1\\) . The probability space here is \\(2^{n+1}\\) since there are \\(2^n\\) choices for the n-bit key \\(K\\) , as well as the challenger's choice of whether to send \\(M_0\\) or \\(M_1\\) . All choices are equally likely. Assume key \\(K\\) is generated uniformly at random; then the challenger randomly chooses a bit \\(b\\in\\{0, 1\\}\\) , and Alice sends the encryption of \\(M_b\\) . So, if Eve observes that the cipher text has some specific value \\(C\\) , what is the conditional probability that \\(b = 0\\) given her observation? \\[ \\begin{align*} P(b=0|\\text{ciphertext} = C) &= \\frac{P(b = 0 \\land \\text{ciphertext = C})}{P(\\text{ciphertext} = C)}\\\\ &=\\frac{P(b=0\\land K = M_0\\oplus C)}{P(\\text{ciphertext} = C)}\\\\ & = \\frac{(1/2)(1/2^n)}{1/2^n}\\\\ & = \\frac{1}{2} \\end{align*} \\] Drawback of one time pad: Shared key cannot be reused to transmit another message \\(M'\\) . If \\(K\\) is reused to encrypt two messages \\(M\\) and \\(M'\\) , then Eve can XOR the two ciphertexts \\(C = M\\oplus K\\) and \\(C' = M'\\oplus K\\) to obtain \\(C\\oplus C' = M\\oplus M'\\) . If Eve happens to learn \\(M\\) , then she can easily deduce the other message \\(M'\\) . But she can also just reconstruct the key \\(K\\) too. Even if Eve does not know \\(M\\) or \\(M'\\) , there is often enough redundancy in messages that merely knowing \\(M\\oplus M'\\) is enough to recover most of the messages. In general, one-time pad is not secure if the key is used to encrypt more than one message.","title":"Proof that One-Time Pad is IND-CPA Secure"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#block-ciphers","text":"Block cipher transforms a fixed-length \\(n\\) -bit input into a fixed-length \\(n\\) -bit output. The block cipher has \\(2^k\\) different settings for scrambling, so it also takes in a \\(k\\) -bit key as input, where each key corresponds to a different scrambling setting. Given a fixed key, the block cipher encryption must map each of the \\(2^n\\) possible plaintext inputs to a different ciphertext output. The block cipher encryption must map uniquely, so that there is some inverse operation that decrypts it. This means block cipher is deterministic. Mathematically: There is an encryption function \\(E : \\{0, 1\\}^k \\times \\{0, 1\\} \\rightarrow \\{0, 1\\}^n\\) . Once we fix a key \\(K\\) , the function maps \\(E_K: \\{0, 1\\}^n\\rightarrow \\{0, 1\\}^n\\) , defined by \\(E_K(M) = E(K, M)\\) . We require \\(E_K\\) to be a permutation on the n-bit strings, so it is invertible (bijective). The inverse mapping of this permutation is the decryption algorithm \\(D_K\\) . In other words, \\(D_K(E_K(M)) = M\\) .","title":"Block Ciphers"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#block-cipher-security","text":"Block ciphers are not IND-CPA secure on their own because they are deterministic. In other words, encrypting the same message twice with the same key produces the same output twice. Eve sends \\(M_0\\) and \\(M_1\\) to be encrypted, then queries the challenger for the encryption of \\(M_0\\) and receives the same encryption. If the two encryptions she receives from the challenger are the same, then Eve knows the challenger encrypted \\(M_0\\) and sent \\(E(K, M_0\\) ) otherwise they encrypted \\(M_1\\) . Altough they are not IND-CPA secure, they have a desirable security property that helps us build IND-CPA secure symmetric encryption schemes: a block cipher is computationally indistinguishable from a random permutation. A random permutation is a function that maps each \\(n\\) -bit input to exactly one \\(n\\) -bit random output. AES is not truly indistinguishable from random, but is believed to be computationally indistinguishable from random. Intuitively, this means that given a practical amount of computation power, Eve cannot guess which type of permutation she received. This gives a strong security guarantee. given a single ciphertext \\(C = E_K(M)\\) , an attacker without the key cannot learn anything about the original message \\(M\\) . If the attacker could learn something about \\(M\\) , then AES would no longer be computationally indistinguishable. There is no proof that AES is computationally indistinguishable from random, but it is believed to be computationally indistinguishable.","title":"Block Cipher Security"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#block-cipher-modes-of-operation","text":"Why AES cannot be a practical IND-CPA secure encryption scheme: 1. We would like to encrypt arbitrarily long messages, but the block cipher only takes fixed-length inputs 2. If the same message is sent twice, the ciphertext in the two transmissions is the same with AES. To fix these problems, the encryption algorithm can be randomized or stateful. Several standard ways of building an encryption algorithm, using a block cipher","title":"Block Cipher Modes of Operation"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#electronic-code-book-ecb-mode","text":"The plaintext \\(M\\) is simply broken into \\(n\\) -bit blocks \\(M_1\\cdots M_l\\) , and each block is encoded using the block cipher \\(C_i = E_K(M_i)\\) . The ciphertext is just a concatenation of these individual blocks: \\(C = C_1\\cdot C_2\\cdots C_l\\) . This scheme is flawed. Any redundancy in the blocks will show through and allow the eavesdropper to deduce information about the plaintext. If, for instance \\(M_i = M_j\\) , then \\(C_i = C_j\\) . ECB mode leaks information about the plaintext Encryption: C_i = E_K(M_i) Decryption: M_i = D_K(C_i)","title":"Electronic Code Book (ECB) Mode"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#cipher-block-chaining-cbc-mode","text":"For each message, the sender picks a random \\(n\\) -bit string, called the initial vector (IV). Define \\(C_0 = IV\\) . The \\(i\\) th ciphertext block is given by \\(C_i = E_K(C_{i-1}\\oplus M_i)\\) . The ciphertext is the concatenation of the initial vector and these individual blocks \\(C = IV\\cdot C_1\\cdot C_2\\cdots C_l\\) . CBC mode has been proven to provide strong security guarantees on the privacy of the plaintext message Encryption: \\(C_0 = IV;\\;\\; C_i = E_K(P_i\\oplus C_{i-1})\\) Decryption: \\(P_i = D_K(C_i)\\oplus C_{i-1}\\)","title":"Cipher Block Chaining (CBC) Mode"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#ciphertext-feedback-cfb-mode","text":"\\(C_0\\) is again the IV. The \\(i\\) th ciphertext block is now given by \\(C_i = E_K(C_{i-1})\\oplus M_i\\) . Encryption: \\(C_0 = IV;\\;\\;\\; C_i = E_K(C_{i-1})\\oplus P_i\\) Decryption: \\(P_i = E_K(C_{i-1})\\oplus C_i\\)","title":"Ciphertext Feedback (CFB) Mode"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#output-feedback-ofb-mode","text":"The initial vector is repeatedly encrypted to obtain a set of values \\(Z_i\\) as follows: \\(Z_0 = IV\\) and \\(Z_i = E_K(Z_{i-1})\\) . These values \\(Z_i\\) are now used as though they were the key for a one-tie pad, so that \\(C_i = Z_i\\oplus M_i\\) . The ciphertext is the concatenation of the IV and these individual blocks: \\(C = IV\\cdot C_1\\cdot C_2\\cdots C_l\\) . In OFB, it is easy to tampe with ciphertexts. Suppose that the adversary happens to know that the \\(j\\) th block of the message \\(M_j\\) , specifies the amount of money being transferred to his account from the bank, and suppose he knows that \\(M_j = 100\\) . Since he knows both \\(M_j\\) and \\(C_j\\) , he can determine \\(Z_j\\) . He can then substitute any \\(n\\) -bit block in place of \\(M_j\\) and get a new ciphertext \\(C'_j\\) where 100 is replaced by any amount of his choice. Encryption: \\(Z*0 = IV;\\;\\;\\; Z_i = E_K(Z*i-1);\\;\\;\\; C_i = M_i\\oplus Z_i\\) Decyption: \\(P_i = C_i\\oplus Z_i\\)","title":"Output Feedback (OFB) Mode"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#counter-ctr-mode","text":"A counter is initialized to IV and repeatedly incremented and encrypted to obtain a sequence that can now be used as though they were they keys for a one-time pad, namely \\(Z_i = E_K(IV + i)\\) and \\(C_i = Z_i\\oplus M_i\\) . In CTR, the IV is renamed the nonce. Encryption: \\(C_i = E_K(IV + i) \\oplus M_i\\) Decryption: \\(M_i = E_K(IV + i) \\oplus C_i\\)","title":"Counter (CTR) Mode"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#parallelization","text":"Some modes require successive blocks to be encrypted or decrypted sequentially, but some of them can be parallelized: CBC encryption cannot be parallized since it depends on \\(C_{i-1}\\) . CBC decryption can be parallelized. Since we already have all the ciphertext blocks CTR encryption and decryption can both be parallelized.","title":"Parallelization"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#padding","text":"Recall that block ciphers let us encrypt messages that are longer than one block long. What happens if we want to send a message that is not a multiple of the block size? It will depends on which mode is being used. Let's assume the block size is 128 bits (16 characters). CBC: if the plaintext isn't a multiple of 128 bits, then the last block of plaintext will be slightly shorter than 128 bits. The XOR would be undefined-bitwise XOR. The solution is to pad the plaintext until it is a multiple of 128 bits. But that means we have to remove the padding in decryption. PKCS#7 padding pads the message by the number of padding bytes used. This allows the decryption to understand how much bytes to remove. Not all modes need to be padded. CTR doesn't because the result of XOR never has to be passed into a block cipher again at the end, so the 100 bits left is fine.","title":"Padding"},{"location":"EECS/CS%20161/Cryptography/6.%20Symmetric-Key%20Encryption/#reusing-ivs-is-insecure","text":"Recall ECB is not IND-CPA because it is deterministic. Encrypting the same plaintext twice produces the same output, and this causes information leakage. All other modes introduce a random initialization vector IV that is different on every encryption in order to ensure that encrypting the same plaintext twice with the same key results in different output. However, reusing IV in CTR is equivalent to reusing the one-time pad.","title":"Reusing IVs is Insecure"},{"location":"EECS/CS%20161/Cryptography/7.%20Cryptographic%20Hashes/","text":"7. Cryptographic Hashes \u00b6 Overview \u00b6 A cryptographic hash function is a function \\(H\\) that when applied on a message, \\(M\\) , can be used to generate a fixed-length \"fingerprint\" of the message. As such, any change to the message, no matter how small, will change many of the bits of the hash value with there being no detectable patters as to how the output changes based on specific input changes. \\(H\\) is deterministic, meaning if you compute \\(H(M)\\) twice with the same input \\(M\\) , you will always get the same output twice. The hash function is unkeyed, as it only takes in a message \\(M\\) and no secret key. Typically outputs of hash functions are fixed size: the SHA256 hash algorithm can be used to hash a message of any size, but always produces a 256-bit hash value. Properties of Hash Functions \u00b6 One-way: The hash function can be computed efficiently Given \\(x\\) , it is easy to compute \\(H(x)\\) . However, given an output \\(y\\) , it is infeasible to find any input \\(x\\) such that \\(H(x) = y\\) . This property is known as \"preimage resistant\" Second preimage resistant: Given input \\(x\\) , it is infeasible to find another input \\(x'\\) such that \\(x' \\neq x\\) but \\(H(x) = H(x')\\) . The difference between preimage resistance is that the adversary also knows a starting point \\(x\\) , and wishes to tweak it to \\(x'\\) in order to produce the same hash -- but cannot. Collision resistant: It is infeasible to find any pair of messages \\(x, x'\\) such that \\(x' \\neq x\\) but \\(H(x) = H(x')\\) . The difference between the others is that the adversary can freely choose their starting point \\(x\\) , potentially designing it specially to enable finding the associated \\(x'\\) -- but again cannot. Note the third property implies the second property. We keep them separate because given hash function's resistance towards the one might differ from resistance towards the other. Hash Algorithms \u00b6 One of the earliest hash function, MD5 (message digest 5) was broken years ago. SHA1 (secure hash algorithm) was broken in 2017. git version control used to use SHA1. This worked find until someone discovered how to produce SHA1 collisions. There are two primary \"families\" of hash algorithms in common use that are believed to be secure: SHA2 and SHA3. In each family, there are differing output lengths. SHA-256, SHA-384, SHA-512 are all instances of SHA2 family with outputs of 256, 384, 512 bits respectively. SHA3-256, SHA3-284, SHA3-512 are SHA3 family members. Lowest-Hash Scheme \u00b6 Cryptographic hashes have many practical applications outside of cryptography. Suppose you are a journalist, and a hacker contacts you claiming to have stolen 150 million records from a website. The hacker is keeping the records for ransom, so they don't want to present all 150 million files. You can tell if they are lying by getting the hash of them. If the hacker hashes all 150 million records, they are generating 150 million bitstrings. We might ask the hacker to hash them and then return the 10 lowest resulting hashes. Then check if those hashes are consistent with what we would expect the lowest 10 samples out of 150 million random bitstrings to be. The probability of getting those lowest 10 hashes from 150 million records is astronomically low and conclude that the hacker is lying about their claim. We can also require the attacker to send the 10 records corresponding to the lowest hashes, and they must know which of the 150 million fake records would result in the lowest hash.","title":"7. Cryptographic Hashes"},{"location":"EECS/CS%20161/Cryptography/7.%20Cryptographic%20Hashes/#7-cryptographic-hashes","text":"","title":"7. Cryptographic Hashes"},{"location":"EECS/CS%20161/Cryptography/7.%20Cryptographic%20Hashes/#overview","text":"A cryptographic hash function is a function \\(H\\) that when applied on a message, \\(M\\) , can be used to generate a fixed-length \"fingerprint\" of the message. As such, any change to the message, no matter how small, will change many of the bits of the hash value with there being no detectable patters as to how the output changes based on specific input changes. \\(H\\) is deterministic, meaning if you compute \\(H(M)\\) twice with the same input \\(M\\) , you will always get the same output twice. The hash function is unkeyed, as it only takes in a message \\(M\\) and no secret key. Typically outputs of hash functions are fixed size: the SHA256 hash algorithm can be used to hash a message of any size, but always produces a 256-bit hash value.","title":"Overview"},{"location":"EECS/CS%20161/Cryptography/7.%20Cryptographic%20Hashes/#properties-of-hash-functions","text":"One-way: The hash function can be computed efficiently Given \\(x\\) , it is easy to compute \\(H(x)\\) . However, given an output \\(y\\) , it is infeasible to find any input \\(x\\) such that \\(H(x) = y\\) . This property is known as \"preimage resistant\" Second preimage resistant: Given input \\(x\\) , it is infeasible to find another input \\(x'\\) such that \\(x' \\neq x\\) but \\(H(x) = H(x')\\) . The difference between preimage resistance is that the adversary also knows a starting point \\(x\\) , and wishes to tweak it to \\(x'\\) in order to produce the same hash -- but cannot. Collision resistant: It is infeasible to find any pair of messages \\(x, x'\\) such that \\(x' \\neq x\\) but \\(H(x) = H(x')\\) . The difference between the others is that the adversary can freely choose their starting point \\(x\\) , potentially designing it specially to enable finding the associated \\(x'\\) -- but again cannot. Note the third property implies the second property. We keep them separate because given hash function's resistance towards the one might differ from resistance towards the other.","title":"Properties of Hash Functions"},{"location":"EECS/CS%20161/Cryptography/7.%20Cryptographic%20Hashes/#hash-algorithms","text":"One of the earliest hash function, MD5 (message digest 5) was broken years ago. SHA1 (secure hash algorithm) was broken in 2017. git version control used to use SHA1. This worked find until someone discovered how to produce SHA1 collisions. There are two primary \"families\" of hash algorithms in common use that are believed to be secure: SHA2 and SHA3. In each family, there are differing output lengths. SHA-256, SHA-384, SHA-512 are all instances of SHA2 family with outputs of 256, 384, 512 bits respectively. SHA3-256, SHA3-284, SHA3-512 are SHA3 family members.","title":"Hash Algorithms"},{"location":"EECS/CS%20161/Cryptography/7.%20Cryptographic%20Hashes/#lowest-hash-scheme","text":"Cryptographic hashes have many practical applications outside of cryptography. Suppose you are a journalist, and a hacker contacts you claiming to have stolen 150 million records from a website. The hacker is keeping the records for ransom, so they don't want to present all 150 million files. You can tell if they are lying by getting the hash of them. If the hacker hashes all 150 million records, they are generating 150 million bitstrings. We might ask the hacker to hash them and then return the 10 lowest resulting hashes. Then check if those hashes are consistent with what we would expect the lowest 10 samples out of 150 million random bitstrings to be. The probability of getting those lowest 10 hashes from 150 million records is astronomically low and conclude that the hacker is lying about their claim. We can also require the attacker to send the 10 records corresponding to the lowest hashes, and they must know which of the 150 million fake records would result in the lowest hash.","title":"Lowest-Hash Scheme"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/","text":"2. x86 Assembly and Call Stack \u00b6 Number Representation \u00b6 A nibble is 4 bits, a byte is 8 bits, and a word is 32 bits (on 32b architectures). The word is the size of a pointer. Real-world 64-bit architectures include stronger defenses against memory safety exploits. Take a look at 1. Number Representation for information on how to represent numbers. Compiler, Assembler, Linker, Loader (CALL) \u00b6 There are 4 main steps to running a C program: 1. Compiler: translates C code into assembly instructions. We will use x86 Assembly, where 61C uses RISC-V ISA 2. Assembler: Translates assembly instructions into machine code (raw bits). 3. Linker: Resolves dependencies on external libraries. After the linker is finished linking external libraries, it outputs a binary executable of the program that you can run. 4. Loader: set up an address space in memory and runs the machine code instructions in the executable. Learn more about CALL in detail in 8. Compiler, Assembler, Linker, Loader (CALL) from 61C notes. C Memory Layout \u00b6 We can draw the memory layout as one long array with \\(2^{32}\\) elements, where each element is one byte. The leftmost element has address \\(0x00000000\\) andads the rightmost element is \\(0xFFFFFFFF\\) . We visually see this as a grid of bytes, where the bottom-left element is \\(0x00000000\\) and the top-right element has \\(0xFFFFFFFF\\) . We further separate the address space into four sections. From lowest to highest address, they are: - Code: Contains the executable instructions of the program (the code itself). Here, the assembler and linker output raw bytes that are stored in the code section. Static: Contains constants and static variables that never change during program execution, and are usually allocated when the program is started Heap: Stores dynamically allocated data. We do this with malloc and free in C. The heap starts at lower addresses and grows up to higher addresses as more memory is allocated. Stack: Stores local variables and other information associated with function calls. The stack starts at higher addresses and grows down as more functions are called. Little-Endian Words \u00b6 x86 is Little-Endian, meaning that when storing a word in memory, the least significant byte is stored at the lowest address, and the most significant byte is stored at the highest address. To store the word \\(0x44332211\\) , we stored them in bytes as You see that the least significant byte \\(0x11\\) is stored at the lowest address, and the most significant bytes \\(0x44\\) is stored at the highest address. Registers \u00b6 There are also registers, which store memory directly on the CPU. Each register can store one word. Registers do not have addresses, but we refer to registers using names. x86 has three special registers: eip: instruction pointer, which stores the address of the machine instruction currently being executed. RISC-V equivalent: PC (program counter) ebp: base pointer, which stores the address of the top of the current stack frame. RISC-V equivalent: FP (frame pointer) esp: stack pointer, stores the address of the bottom of the current stack frame. RISC-V equivalent: SP (stack pointer) The \"e\" in the register abbreviations stands for \"extended\" and indicates we are using a 32-bit system (extended from 16-bit system). Sometimes, the registers can point somewhere in memory. We can store the address of a pointer that goes to another part of memory. Stack: Pushing and Popping \u00b6 If we want to remember a value, we save it on the stack. We do the following 2-step procedure to add a value on a stack 1. Allocate additional space on the stack by decrementing the esp 2. Store the value in the newly allocated space The x86 push instruction does both of these steps to add a value to the stack. When we pop a value off the stack, the value is not wiped away from memory. Instead esp is incremented tso that the popped value is now below esp . Since esp points to the bottom of the stack, the popped value below esp is now in undefined memory. x86 Colling Convention \u00b6 Some syntactical differences between x86 syntax and RISC-V syntax: 1. destination register comes last in x86 2. references to registers are preceded with a percent sign. To reference eax , we would do %eax . 3. immediates are preceded with a dollar sign (such as $1 , $0x4 ). 4. Memory references use parenthesis and can have immediate offsets, such as 12(%esp) , which dereferences memory 12 bytes above the address contained in esp . If parentheses are used without an immediate offset, the offset can be through of as an implicit 0 . Here is an example. The assembly instruction xorl 4(%esi), $eax will be interpreted as the following. Here, the opcode is xorl , the source is 4(%esi) , and the destination is %eax . As such, the pseudocode might be written as EAX = EAX ^ *(ESI + 4) . We dereference the value 4 bytes above the address stored in esi . x86 Function Calls \u00b6 To call a function, the stack allocates extra space to store local variables and other information relevant to the function. Since the stack grows down, the extra space is at a lower address. Once the function returns, the space on the stack is freed up for future function calls. The caller calls the callee . Program execution starts in the caller, moves to the callee as a result of the function call, and then returns to the caller after the function call completes. In x86, we need to update the values in all three registers we've discussed: 1. eip , the instruction pointer needs to be changed to point to the instructions of the callee 2. ebp and esp need to be updated to point to the top and bottom of a new stack frame for the callee There are 11 steps to call an x86 function and returning. 1. Push arguments onto the stack. Since esp gets decremented as we push arguments onto the stack, we should push arguments in reverse order. 2. Push the old eip (rip) on the stack. rip is the (return instruction pointer). 3. Move eip to point to the instructions for the callee function 4. Push the old ebp (called sfp ) on the stack. This is the saved frame pointer. We do this since we are about to change the value in the ebp register. 5. Move ebp down. We can safely change ebp to point to the top of the new stack frame. The top of the new stack frame is where esp is currently pointing, since we are about to allocate new space below esp for the new stack frame. 6. Move esp down. We allocate new space for the new stack frame by decrementing esp . The compiler looks at the function to determine how far esp should be decremented. 7. Execute the function. Arguments will be located starting at the address stored in ebp plus 8 8. Move esp up. When the function is ready to return, increment esp to point to the top of the stack frame ( ebp ). This effectively erases the stack frame. 9. Restore the old ebp (called sfp ). 10. Restore the old eip (called rip ) 11. Remove arguments from the stack by incrementing the esp x86 Function Call in Assembly \u00b6 Let's play the role of the compiler: int main(void) { foo(1, 2) } void foo(int a, int b) { int bar[4]; } The compiler would turn the foo functioninto the following x86: main: # Step 1. Push arguments on the stack in reverse order push $2 push $1 # Steps 2-3. Save old eip (rip) on the stack and change eip call foo # Execution changes to foo now. After returning from foo: # Step 11: Remove arguments from stack add $8, %esp foo: # Step 4. Push old ebp (sfp) on the stack push %ebp # Step 5. Move ebp down to esp mov %esp, %ebp # Step 6. Move esp down sub $16, %esp # Step 7. Execute the function (omitted here) # Step 8. Move esp mov %ebp, %esp # Step 9. Restore old ebp (sfp) pop %ebp # Step 10. Restore old eip (rip) pop %eip Steps 1-3 happens in the caller function. Step 3 changes the eip to point to the callee. Once eip is changed, steps 4-10 happen in the calee function. Step 10 changes the eip to point back to the caller. And then now step 11 takes place. We use shorthand to write function returns. Step 8 and 9 are abbreviated as the leave instruction, and step 10 is abbreviated as the ret instruction. Maybe we can just write leave ret after each function We call steps 4-6 the function prologue, and steps 8-10 the function epilogue.","title":"2. x86 Assembly and Call Stack"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#2-x86-assembly-and-call-stack","text":"","title":"2. x86 Assembly and Call Stack"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#number-representation","text":"A nibble is 4 bits, a byte is 8 bits, and a word is 32 bits (on 32b architectures). The word is the size of a pointer. Real-world 64-bit architectures include stronger defenses against memory safety exploits. Take a look at 1. Number Representation for information on how to represent numbers.","title":"Number Representation"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#compiler-assembler-linker-loader-call","text":"There are 4 main steps to running a C program: 1. Compiler: translates C code into assembly instructions. We will use x86 Assembly, where 61C uses RISC-V ISA 2. Assembler: Translates assembly instructions into machine code (raw bits). 3. Linker: Resolves dependencies on external libraries. After the linker is finished linking external libraries, it outputs a binary executable of the program that you can run. 4. Loader: set up an address space in memory and runs the machine code instructions in the executable. Learn more about CALL in detail in 8. Compiler, Assembler, Linker, Loader (CALL) from 61C notes.","title":"Compiler, Assembler, Linker, Loader (CALL)"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#c-memory-layout","text":"We can draw the memory layout as one long array with \\(2^{32}\\) elements, where each element is one byte. The leftmost element has address \\(0x00000000\\) andads the rightmost element is \\(0xFFFFFFFF\\) . We visually see this as a grid of bytes, where the bottom-left element is \\(0x00000000\\) and the top-right element has \\(0xFFFFFFFF\\) . We further separate the address space into four sections. From lowest to highest address, they are: - Code: Contains the executable instructions of the program (the code itself). Here, the assembler and linker output raw bytes that are stored in the code section. Static: Contains constants and static variables that never change during program execution, and are usually allocated when the program is started Heap: Stores dynamically allocated data. We do this with malloc and free in C. The heap starts at lower addresses and grows up to higher addresses as more memory is allocated. Stack: Stores local variables and other information associated with function calls. The stack starts at higher addresses and grows down as more functions are called.","title":"C Memory Layout"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#little-endian-words","text":"x86 is Little-Endian, meaning that when storing a word in memory, the least significant byte is stored at the lowest address, and the most significant byte is stored at the highest address. To store the word \\(0x44332211\\) , we stored them in bytes as You see that the least significant byte \\(0x11\\) is stored at the lowest address, and the most significant bytes \\(0x44\\) is stored at the highest address.","title":"Little-Endian Words"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#registers","text":"There are also registers, which store memory directly on the CPU. Each register can store one word. Registers do not have addresses, but we refer to registers using names. x86 has three special registers: eip: instruction pointer, which stores the address of the machine instruction currently being executed. RISC-V equivalent: PC (program counter) ebp: base pointer, which stores the address of the top of the current stack frame. RISC-V equivalent: FP (frame pointer) esp: stack pointer, stores the address of the bottom of the current stack frame. RISC-V equivalent: SP (stack pointer) The \"e\" in the register abbreviations stands for \"extended\" and indicates we are using a 32-bit system (extended from 16-bit system). Sometimes, the registers can point somewhere in memory. We can store the address of a pointer that goes to another part of memory.","title":"Registers"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#stack-pushing-and-popping","text":"If we want to remember a value, we save it on the stack. We do the following 2-step procedure to add a value on a stack 1. Allocate additional space on the stack by decrementing the esp 2. Store the value in the newly allocated space The x86 push instruction does both of these steps to add a value to the stack. When we pop a value off the stack, the value is not wiped away from memory. Instead esp is incremented tso that the popped value is now below esp . Since esp points to the bottom of the stack, the popped value below esp is now in undefined memory.","title":"Stack: Pushing and Popping"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#x86-colling-convention","text":"Some syntactical differences between x86 syntax and RISC-V syntax: 1. destination register comes last in x86 2. references to registers are preceded with a percent sign. To reference eax , we would do %eax . 3. immediates are preceded with a dollar sign (such as $1 , $0x4 ). 4. Memory references use parenthesis and can have immediate offsets, such as 12(%esp) , which dereferences memory 12 bytes above the address contained in esp . If parentheses are used without an immediate offset, the offset can be through of as an implicit 0 . Here is an example. The assembly instruction xorl 4(%esi), $eax will be interpreted as the following. Here, the opcode is xorl , the source is 4(%esi) , and the destination is %eax . As such, the pseudocode might be written as EAX = EAX ^ *(ESI + 4) . We dereference the value 4 bytes above the address stored in esi .","title":"x86 Colling Convention"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#x86-function-calls","text":"To call a function, the stack allocates extra space to store local variables and other information relevant to the function. Since the stack grows down, the extra space is at a lower address. Once the function returns, the space on the stack is freed up for future function calls. The caller calls the callee . Program execution starts in the caller, moves to the callee as a result of the function call, and then returns to the caller after the function call completes. In x86, we need to update the values in all three registers we've discussed: 1. eip , the instruction pointer needs to be changed to point to the instructions of the callee 2. ebp and esp need to be updated to point to the top and bottom of a new stack frame for the callee There are 11 steps to call an x86 function and returning. 1. Push arguments onto the stack. Since esp gets decremented as we push arguments onto the stack, we should push arguments in reverse order. 2. Push the old eip (rip) on the stack. rip is the (return instruction pointer). 3. Move eip to point to the instructions for the callee function 4. Push the old ebp (called sfp ) on the stack. This is the saved frame pointer. We do this since we are about to change the value in the ebp register. 5. Move ebp down. We can safely change ebp to point to the top of the new stack frame. The top of the new stack frame is where esp is currently pointing, since we are about to allocate new space below esp for the new stack frame. 6. Move esp down. We allocate new space for the new stack frame by decrementing esp . The compiler looks at the function to determine how far esp should be decremented. 7. Execute the function. Arguments will be located starting at the address stored in ebp plus 8 8. Move esp up. When the function is ready to return, increment esp to point to the top of the stack frame ( ebp ). This effectively erases the stack frame. 9. Restore the old ebp (called sfp ). 10. Restore the old eip (called rip ) 11. Remove arguments from the stack by incrementing the esp","title":"x86 Function Calls"},{"location":"EECS/CS%20161/Memory%20Safety/2.%20x86%20Assembly%20and%20Call%20Stack/#x86-function-call-in-assembly","text":"Let's play the role of the compiler: int main(void) { foo(1, 2) } void foo(int a, int b) { int bar[4]; } The compiler would turn the foo functioninto the following x86: main: # Step 1. Push arguments on the stack in reverse order push $2 push $1 # Steps 2-3. Save old eip (rip) on the stack and change eip call foo # Execution changes to foo now. After returning from foo: # Step 11: Remove arguments from stack add $8, %esp foo: # Step 4. Push old ebp (sfp) on the stack push %ebp # Step 5. Move ebp down to esp mov %esp, %ebp # Step 6. Move esp down sub $16, %esp # Step 7. Execute the function (omitted here) # Step 8. Move esp mov %ebp, %esp # Step 9. Restore old ebp (sfp) pop %ebp # Step 10. Restore old eip (rip) pop %eip Steps 1-3 happens in the caller function. Step 3 changes the eip to point to the callee. Once eip is changed, steps 4-10 happen in the calee function. Step 10 changes the eip to point back to the caller. And then now step 11 takes place. We use shorthand to write function returns. Step 8 and 9 are abbreviated as the leave instruction, and step 10 is abbreviated as the ret instruction. Maybe we can just write leave ret after each function We call steps 4-6 the function prologue, and steps 8-10 the function epilogue.","title":"x86 Function Call in Assembly"},{"location":"EECS/CS%20161/Memory%20Safety/3.%20Memory%20Safety%20Vulnerabilities/","text":"3. Memory Safety Vulnerabilities \u00b6 This note describes some memory safety vulnerabilities, namely buffer overflow vulnerabilities, stack smashing, string/integer vulnerabilities, off-by-one vulnerabiliites. Buffer Overflow Vulnerabilities \u00b6 Buffer overflows are particularly a risk in C, and since C is a widely used systems programming lanugage, we must know how to protect against them. C++ and Objective-C also suffer from these vulnerabilities. If a programmer declares an array char buffer[4] , C will not automatically throw an error if the programmer tries to access buffer[5] . The programmer's responsibility is to check that every memory access is in bounds. Let's start with the example char buf[8]; void vulnerable() { gets(buf) } First, know the syntax: gets() reads as many bytes of input as the user supplies (through standard input), and stores them into buf[] . Even if the input contains more than 8 bytes of data, gets() will write past the end of buf , overwriting some other part of memory. A danger that can appear: char buf[8]; int authenticated = 0; void vulnerable() { gets(buf); } note where the variables are stored in our memory model. They are located in static. Static grows upwards, so authenticated is right above buf . Let's therefore write 9 bytes of data to buf such that the authenticated flag is set to true . Now an attacker can gain access. Modify the code to look like this instead char buf[8]; int (*fnptr)(); void vulnerable() { gets(buf); } Now that the static data is fnptr , note that this is a 4 byte value that stores the address of a function that weill dereference the pointer and start executing those instructions at the address. Therefore, let's gets(buf) with 12 bytes, where the ending 4 bytes point to an address of our choosing, redirecting program execution to some other memory location. Perhaps where malicious machine instructions are stored? This is a malicious code injection attack. Malicious code injection attacks allow an attacker to seize control of the program. At the conclusion of the attack, the program is still running, but now it is executing code chosen by the attacker, rather than the original code. For example, if a web server is running as root, once the attacker seizes control, the attacker can do anything that root can do; for example, leaving a backdoor that allows them to log in as root later. Now the system has been \"owned\" (also called pwned, 0wned, ownzored). Stack Smashing \u00b6 We can also exploit stack variables void vulnerable() { char buf[8]; gets(buf); } Two things to note: above buf in the stack lies the return address and other things, like rip and sfp . We could possible overwrite them with some carefully chosen inputs. Let's assume malicious code exists at 0xDEADBEEF . Then we just input AAAAAAAAAAAA\\xef\\xbe\\xad\\xde . And Boom! we have now just make the rip overwritten with 0xDEADBEEF , and the program will go there once the function returns. The program now will start running code at that address. Note that since x86 is little-endian, we had to input it as above. Now if the malicious code didn't already exist, what if we write some shellcode that allows us to perform arbitrary actions. If the shellcode was 8 bytes long. We might input something like [shellcode] + [4 bytes of garbage] + [address of buf] . Now notice that rip is sent to the shellcode. That is bad! Now suppose the shellcode is 100 bytes long. Obviously the shellcode won't fit, but let's do this [12 bytes of garbage] + [address of rip + 4] + [shellcode] Now the shellcode is above the rip in memory, so then we start running code at the shellcode. since the rip is sent just above it. Stack smashing dates back to the late 1980s, where the Morris Worm exploited a buffer overflow vulnerability to infect thousands of computers. There are tutorials on the web explaining how to deal with complications such as: Malicious code stored at an unknown location Buffer is stored on the heap instead of the stack Characters that can be written to the buffer are limited (like lowercase letters only) There is no way to introduce any malicious code into the program's address space. Bottom line: If your program has a buffer overflow bug, you should assume that the bug is exploitable and an attacker can take control of your program. Format String Vulnerabilities \u00b6 Let's look at this example void vulnerable() { char buf[8]; if (fgets(buf, sizeof buf, stdin) == NULL) { return; } printf(buf); } The stack diagram might look like Note the following: When printf() executes, it looks for a format string modifier denoted by a % in its first argument located 4 bytes above the RIP of printf . If it does find a modifier, it looks 8 bytes bove the RIP for the actual argument. We might have a print statement like printf(\"x has the value %d, y has the value %d, z has the value %d \\n\", x, y); . Note that the format string requires 3 arguments since we have three %d modifiers, but we only have 2 arguments. However, C will not catch this error So, here is what will happen with excess modifiers: it will look 4 bytes up for each modifier. Even if we don't pass in a third modifier value, it will still look 4 bytes upwards of the previous one. It will print out the value that is there. Here are other modifiers that might be useful: %s Treat argument as an address and print the string at that address up until the first null byte %n Treat argument as an address and write the number of characters that have been printed so far to that address %c Treat the argument as a value and print it out as a character %x Look at the stack and read the first variable after the format string %[b]u Print out [b] bytes starting from the argument Bottom line: if you program has a format string vulnerability, assume the attacker can learn any value stored in memory and can take control of your program. Integer Conversion Vulnerabilities \u00b6 Another example char buf[8]; void vulnerable() { int len = read_int_from_network(); char *p = read_string_from_network(); if (len > 8) { error(\"length too large: bad dog, no cookie for you!\"); return; } memcpy(buf, p, len); } Note two definitions for memcpy() and size_t : void *memcpy(void *dest, const void *src, size_t n); typedef unsigned int size_t; Therefore, if an attacker provides a negative value for len , the if statement won't notice anything wrong, and memcpy() will be executed with a negative third argument. Casting this to unsigned integer makes it be very large positive integer. Therefore, memcpy() will copy a huge amount of memory into buf , overflowing the buffer. Another example that tries to skirt around this problem: void vulnerable() { size_t len; char *buf; len = read_int_from_network(); buf = malloc(len+5); read(fd, buf, len); ... } It allocates 5 more bytes than necessary, so it seems to avoid overflow problems. However, len+5 can wrap around if len is too large. Let len = 0xFFFFFFFF , then the value of len + 5 is 4 . Therefore, the code allocates a 4-byte buffer and then writes a lot more than 4 bytes into it. Classic buffer overflow. Off-By-One Vulnerabilities \u00b6 Consider a buffer whose bounds checks are off by one. This means we can write n+1 bytes into a buffer of size n , overflowing the byte immediately after the buffer. We can overwrite a single byte and start executing instructions at an arbitrary address in memory. The idea here overwrite the extra byte we are allowed, which overwrites the LSB of the sfp . Make sfp point to somewhere inside buff . Then the function will return. The following will happen 1. mov %ebp, %esp : esp now points where ebp is pointing, which is the forged sfp 2. pop %ebp : Take the next value on the stack, the forged sfp, and place it in the ebp register. ebp is pointing insider the buffer 3. pop %eip : Take the next value on the stack, the rip, and place it in the eip register. Since we didn't maliciously change the rip, the old iep is correctly restored. Now ebp points insider the buffer, Let's put the shellcode in the buffer, so the execution will go there. Note two things: 1. We want to overwrite the place that the program eventually tries to interpret as the rip. 2. It is not enough the place the shellcode 4 bytes above where the forged sfp is pointing. You need to put the address of shellcode there, since the program will interpret that part of memory as the rip. Other Memory Safety Vulnerabilities \u00b6 Other examples of memory safety violations include Dangling pointer (pointer into a memory region that has been freed and is no longer valid) Double-Free (where a dynamically allocated object is explicitly freed multiple times) Use after free (where an object or structure in memory is deallocated but still used). These are particularly attractive targets for exploitation. Involves the attacker triggering the creation of two separate objects that actually share the same memory. The attacker can now use the second object to manipulate the interpretation of the first object. C++ vtable pointers. An example of heap overflow, where programmer declares objects on the heap. This requires storing a vtable pointer, a pointer to an array of pointers. If bounds are not checked correctly, an attacker can overflow one of the instance variables of object x . If there is another object above x in memory, then the attacker can overwrite that object's vtable pointer.","title":"3. Memory Safety Vulnerabilities"},{"location":"EECS/CS%20161/Memory%20Safety/3.%20Memory%20Safety%20Vulnerabilities/#3-memory-safety-vulnerabilities","text":"This note describes some memory safety vulnerabilities, namely buffer overflow vulnerabilities, stack smashing, string/integer vulnerabilities, off-by-one vulnerabiliites.","title":"3. Memory Safety Vulnerabilities"},{"location":"EECS/CS%20161/Memory%20Safety/3.%20Memory%20Safety%20Vulnerabilities/#buffer-overflow-vulnerabilities","text":"Buffer overflows are particularly a risk in C, and since C is a widely used systems programming lanugage, we must know how to protect against them. C++ and Objective-C also suffer from these vulnerabilities. If a programmer declares an array char buffer[4] , C will not automatically throw an error if the programmer tries to access buffer[5] . The programmer's responsibility is to check that every memory access is in bounds. Let's start with the example char buf[8]; void vulnerable() { gets(buf) } First, know the syntax: gets() reads as many bytes of input as the user supplies (through standard input), and stores them into buf[] . Even if the input contains more than 8 bytes of data, gets() will write past the end of buf , overwriting some other part of memory. A danger that can appear: char buf[8]; int authenticated = 0; void vulnerable() { gets(buf); } note where the variables are stored in our memory model. They are located in static. Static grows upwards, so authenticated is right above buf . Let's therefore write 9 bytes of data to buf such that the authenticated flag is set to true . Now an attacker can gain access. Modify the code to look like this instead char buf[8]; int (*fnptr)(); void vulnerable() { gets(buf); } Now that the static data is fnptr , note that this is a 4 byte value that stores the address of a function that weill dereference the pointer and start executing those instructions at the address. Therefore, let's gets(buf) with 12 bytes, where the ending 4 bytes point to an address of our choosing, redirecting program execution to some other memory location. Perhaps where malicious machine instructions are stored? This is a malicious code injection attack. Malicious code injection attacks allow an attacker to seize control of the program. At the conclusion of the attack, the program is still running, but now it is executing code chosen by the attacker, rather than the original code. For example, if a web server is running as root, once the attacker seizes control, the attacker can do anything that root can do; for example, leaving a backdoor that allows them to log in as root later. Now the system has been \"owned\" (also called pwned, 0wned, ownzored).","title":"Buffer Overflow Vulnerabilities"},{"location":"EECS/CS%20161/Memory%20Safety/3.%20Memory%20Safety%20Vulnerabilities/#stack-smashing","text":"We can also exploit stack variables void vulnerable() { char buf[8]; gets(buf); } Two things to note: above buf in the stack lies the return address and other things, like rip and sfp . We could possible overwrite them with some carefully chosen inputs. Let's assume malicious code exists at 0xDEADBEEF . Then we just input AAAAAAAAAAAA\\xef\\xbe\\xad\\xde . And Boom! we have now just make the rip overwritten with 0xDEADBEEF , and the program will go there once the function returns. The program now will start running code at that address. Note that since x86 is little-endian, we had to input it as above. Now if the malicious code didn't already exist, what if we write some shellcode that allows us to perform arbitrary actions. If the shellcode was 8 bytes long. We might input something like [shellcode] + [4 bytes of garbage] + [address of buf] . Now notice that rip is sent to the shellcode. That is bad! Now suppose the shellcode is 100 bytes long. Obviously the shellcode won't fit, but let's do this [12 bytes of garbage] + [address of rip + 4] + [shellcode] Now the shellcode is above the rip in memory, so then we start running code at the shellcode. since the rip is sent just above it. Stack smashing dates back to the late 1980s, where the Morris Worm exploited a buffer overflow vulnerability to infect thousands of computers. There are tutorials on the web explaining how to deal with complications such as: Malicious code stored at an unknown location Buffer is stored on the heap instead of the stack Characters that can be written to the buffer are limited (like lowercase letters only) There is no way to introduce any malicious code into the program's address space. Bottom line: If your program has a buffer overflow bug, you should assume that the bug is exploitable and an attacker can take control of your program.","title":"Stack Smashing"},{"location":"EECS/CS%20161/Memory%20Safety/3.%20Memory%20Safety%20Vulnerabilities/#format-string-vulnerabilities","text":"Let's look at this example void vulnerable() { char buf[8]; if (fgets(buf, sizeof buf, stdin) == NULL) { return; } printf(buf); } The stack diagram might look like Note the following: When printf() executes, it looks for a format string modifier denoted by a % in its first argument located 4 bytes above the RIP of printf . If it does find a modifier, it looks 8 bytes bove the RIP for the actual argument. We might have a print statement like printf(\"x has the value %d, y has the value %d, z has the value %d \\n\", x, y); . Note that the format string requires 3 arguments since we have three %d modifiers, but we only have 2 arguments. However, C will not catch this error So, here is what will happen with excess modifiers: it will look 4 bytes up for each modifier. Even if we don't pass in a third modifier value, it will still look 4 bytes upwards of the previous one. It will print out the value that is there. Here are other modifiers that might be useful: %s Treat argument as an address and print the string at that address up until the first null byte %n Treat argument as an address and write the number of characters that have been printed so far to that address %c Treat the argument as a value and print it out as a character %x Look at the stack and read the first variable after the format string %[b]u Print out [b] bytes starting from the argument Bottom line: if you program has a format string vulnerability, assume the attacker can learn any value stored in memory and can take control of your program.","title":"Format String Vulnerabilities"},{"location":"EECS/CS%20161/Memory%20Safety/3.%20Memory%20Safety%20Vulnerabilities/#integer-conversion-vulnerabilities","text":"Another example char buf[8]; void vulnerable() { int len = read_int_from_network(); char *p = read_string_from_network(); if (len > 8) { error(\"length too large: bad dog, no cookie for you!\"); return; } memcpy(buf, p, len); } Note two definitions for memcpy() and size_t : void *memcpy(void *dest, const void *src, size_t n); typedef unsigned int size_t; Therefore, if an attacker provides a negative value for len , the if statement won't notice anything wrong, and memcpy() will be executed with a negative third argument. Casting this to unsigned integer makes it be very large positive integer. Therefore, memcpy() will copy a huge amount of memory into buf , overflowing the buffer. Another example that tries to skirt around this problem: void vulnerable() { size_t len; char *buf; len = read_int_from_network(); buf = malloc(len+5); read(fd, buf, len); ... } It allocates 5 more bytes than necessary, so it seems to avoid overflow problems. However, len+5 can wrap around if len is too large. Let len = 0xFFFFFFFF , then the value of len + 5 is 4 . Therefore, the code allocates a 4-byte buffer and then writes a lot more than 4 bytes into it. Classic buffer overflow.","title":"Integer Conversion Vulnerabilities"},{"location":"EECS/CS%20161/Memory%20Safety/3.%20Memory%20Safety%20Vulnerabilities/#off-by-one-vulnerabilities","text":"Consider a buffer whose bounds checks are off by one. This means we can write n+1 bytes into a buffer of size n , overflowing the byte immediately after the buffer. We can overwrite a single byte and start executing instructions at an arbitrary address in memory. The idea here overwrite the extra byte we are allowed, which overwrites the LSB of the sfp . Make sfp point to somewhere inside buff . Then the function will return. The following will happen 1. mov %ebp, %esp : esp now points where ebp is pointing, which is the forged sfp 2. pop %ebp : Take the next value on the stack, the forged sfp, and place it in the ebp register. ebp is pointing insider the buffer 3. pop %eip : Take the next value on the stack, the rip, and place it in the eip register. Since we didn't maliciously change the rip, the old iep is correctly restored. Now ebp points insider the buffer, Let's put the shellcode in the buffer, so the execution will go there. Note two things: 1. We want to overwrite the place that the program eventually tries to interpret as the rip. 2. It is not enough the place the shellcode 4 bytes above where the forged sfp is pointing. You need to put the address of shellcode there, since the program will interpret that part of memory as the rip.","title":"Off-By-One Vulnerabilities"},{"location":"EECS/CS%20161/Memory%20Safety/3.%20Memory%20Safety%20Vulnerabilities/#other-memory-safety-vulnerabilities","text":"Other examples of memory safety violations include Dangling pointer (pointer into a memory region that has been freed and is no longer valid) Double-Free (where a dynamically allocated object is explicitly freed multiple times) Use after free (where an object or structure in memory is deallocated but still used). These are particularly attractive targets for exploitation. Involves the attacker triggering the creation of two separate objects that actually share the same memory. The attacker can now use the second object to manipulate the interpretation of the first object. C++ vtable pointers. An example of heap overflow, where programmer declares objects on the heap. This requires storing a vtable pointer, a pointer to an array of pointers. If bounds are not checked correctly, an attacker can overflow one of the instance variables of object x . If there is another object above x in memory, then the attacker can overwrite that object's vtable pointer.","title":"Other Memory Safety Vulnerabilities"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/","text":"4. Mitigating Memory-Safety Vulnerabilities \u00b6 Use a Memory-Safe Language \u00b6 Just use Java, Python, Go, Rust, Swift, etc. They do compile-time and runtime checks that prevent memory errors from occuring. Boom, done. Writing Memory-Safe Code \u00b6 In code, write your pre-conditions and post-conditions for every function you write and using invariants to prove that these conditions are satisfied. Defensive programming: always add checks in your code just in case something could go wrong. Always check that a pointer is not null before dereferencing it, even if you are sure that the pointer is always going to be valid Use safe libraries, which use functions that check bounds so you don't have to. fgets rather than gets strncpy rather than strcpy snprintf instead of sprintf Building Secure Software \u00b6 Use tools to analyze and patch insecure code. Run-time checks that do automatic bound-checking On check failure, direct it towards a controlled crash, ensuring the attacker does not succeed Hire someone to look over your code for memory safety errors Probe your own system for vulnerabilities Fuzz test (test with random inputs), corner cases, Valgrind Exploit Mitigations \u00b6 Code hardening defenses are mitigations: they try to make common exploits harder and cause exploits to crash instead of succeeding, but they are not foolproof. The only way to prevent all memory safety exploits is to use a memory-safe language. Mitigation: Non-Executable Pages \u00b6 A common buffer overflow involves the attacker to write some machine code into memory, and then redirect the program to execute the injected code. [shellcode] + [4 bytes of garbage] + [address of buf] To defend: make some portions of memory non-executable. This means that the computer should not interpret any data in these regions as CPU instructions. You can think of it as not allowing the eip to ever contain the address of a non-executable part of memory. Since modern systems separate memory into pages, make each page of memory either writable or executable, not both. It defends against stack smasking attacks Subverting Non-Executable Pages: Return Into libc \u00b6 Non-executable pages do not stop an attacker from executing existing code in memory. C programs have libraries of up to million of lines. All these instructions are marked as executable (and non-writable), since the programmer may want to call these functions legitimately. Attackers can just overwrite the rip with the address of a C library function. execv function lets the attacker start executing the instructions of some other executable. It takes the string of the filename of the program to execute. Put what you want to run on the stack. pwned. Subverting Non-Executable Pages: Return-Oriented Programming \u00b6 Return-oriented programming is a technique that overwrites a chain of return addresses starting at the rip in order to execute a series of \"ROP gadgets\" which are equivalent to the desired malicious code. We create a custom shellcode using pieces of code that already exist in memory. Instead of executing an existing function, like we did with \"return to libc\", with ROP you can execute your own code by simply executing different pieces of different code. If we wanted to add 4 to the value currently in the edx register as part of a larger program. In loaded memory, we have the following functions: foo: ... 0x4005a1 <foo+33> mov %edx, %eax 0x4005a3 <foo+35> leave 0x4005a4 <foo+36> ret ... bar: ... 0x400604 <bar+20> add $0x4, %eax 0x400608 <bar+24> pop %ebx 0x40060a <bar+26> leave 0x40060b <bar+27> ret To emulate the add $0x4, %edx instruction, move the value in edx to eax using the gadget in foo then add 4 to eax using gadget in bar. Therefore set the first return address to 0x004005a1 and the second return address to 0x00400604 to produce the desired result. Every time we jump to ROP gadget, we eventually execute the ret instruction and then pop the next return address off the stack, jumping to the next gadget. We just have to keep track that our desired value is now in a different register, and because we execute a pop %ebx instruction in bar before we return, we also have to remember that the value in ebx has been updated after executing these gadgets\u2014but these are all behaviors that we can account for using standard compiler techniques. In fact, so-called \u201cROP compilers\u201d exist to take an existing vulnerable program and a desired execution flow and generate a series of return addresses. General strategy: Write a chain of return addresses at the rip to achieve the behavior that we want. Each return address should point to a gadget, which is a small set of assembly instructions that already exist in memory and usually end in a ret instruction. The gadget then executes its instructions and ends with a ret instruction, which tells the code to jump to the next address on the stack, thus allowing us to jump to the next gadget! There are usually enough gadgets in memory for you to be able to run any shellcode you want. ROP compilers exist that will automatically generate a ROP chain for you based on a target binary and desired malicious code. Mitigation: Stack Canaries \u00b6 When we call a function, the compiler places a known dummy value, the stack canary, on the stack. This canary value is not used by the function at all, so it should stay unchanged throughout the duration of the function. The compiler will then check that the canary value has not been changed when the function returns. If canary changes, crash the program, since that is evidence something bad has happened. Stack canary uses the fact that many common stack smashing attacks involve overflowing a local variable to overwrite sfp and rip directly above. If an attacker starts writing at a buffer and wants to overwrite the rip , then they must overwrite everything in between the buffer and the rip . The stack canary is a random value generated at runtime. It is 1 word long. Stack canaries are usually guaranteed to contain a null byte (the first one usually). This lets the canary defend against string-based memory safety exploits, such as vulnerable calls to strcpy that read or write values from the stack until a null byte is encountered. The canary value changes each time the program is run. Subverting Stack Canaries \u00b6 Many exploits that the stack canary cannot detect: Stack canaries can't defend against attacks outside of the stack, such as vulnerable heap memory Stack canaries don't stop an attacker from overwriting other local variables. If there is an authenticated flag in the stack, we can still attack that Some exploits can write to non-consecutive parts of memory, such as format string vulnerabilities can let an attacker write directly to the rip without having to overwrite everything between a local variable and the rip , thus writing around the canary. Other techniques for defeating the stack canary: Guessing the canary. There are usually 24 bits of entropy (randomness) Let's say the attacker is lucky and runs it \\(2^{24}\\) times. In a 32-bit architecture, if every attempt took 1 second, it would take over 100 days to succeed (on 64-bit, it would take 2 million years if they did 1k attempts per second). Leak the canary: sometimes the program has a vulnerability that allows the attacker to read parts of memory, like format string vulnerabilities. If we leak the value, write it down, and then inject an exploit that overwrites the canary with its leaked value, all under a single run, we can pwned the system. Mitigation: Pointer Authentication \u00b6 Pointer authentication takes advantage of the fact that in a 64-bit architecture, many bits of the address are unused. A modern CPU might support a 4 TiB space, which needs 42 bits to address all of memory. There is then a lot of unused address space. Idea: consider using these unused bits to store a secret like the stack canary. Replace the 22 unused bits with some secret value, known as pointer authentication code (PAC) before pushing the value on the stack. If the rip of the function in a 64-bit system is 0x0000001234567899 . Address space is 40bits, and so the top 24 bits are always 0. Instead of pushing this address to the stack. Replace the unused bytes with PAC. However, this will make dereferencing the address invalid. Therefore, CPU will check the PAC is unchanged. If correct, CPU replaces the secret with the original unused bits to make the address valid again. Let's make it better and have the CPU use a different PAC for every pointer stored on the stack with some special math to determine them on the fly. Let's say we have \\(f(key, address)\\) , which outputs a PAC by performing some operation on these two inputs. The function will be deterministic. The function is also secure: an attacker who doesn't know the value of key cannot output secret values of their own. With PAC enabled, an attacker is never able to overwrite pointers on the stack without generating the corresponding secret for the attacker's malicious address. To subvert this, we might have to find a separate vulnerability in the program that allows the attacker to trick the program into creating a validated pointer. Or, they could try to discover the key. Mitigation: Address Space Layout Randomization \u00b6 ASLR is a mitigation that tries to make predicting addresses in memory more difficult. Each time the program is run, the beginning of each section of memory is randomly chosen. If the program imports libraries, randomize the starting addresses of each library's source code. ASLR causes absolute addresses of variables, save registers, and code instructions to be different each time the program is run. Therefore, the attacker must guess the address of their own malicious instructions. Attacker cannot place shellcode on the stack without knowing the address of the stack Attacker cannot place shellcode on the heap without knowing the address of the heap The attacker cannot construct an ROP chain or a return-to-libc attack without knowing the address of the code Some constraints of ASLR: Segments need to start at a page boundary. In other words, the starting address of each section of memory needs to be a multiple of page size (typically 4096 bytes in a 32-bit architecture) Subverting ASLR \u00b6 Two ways to subvert the ASLR Guess the address. Leak the address: sometimes the program has a vulnerability that allows the attacker to read parts of memory. For example, format string vulnerabilities. The stack often stores absolute addresses, such as pointers and saved registers. If the attacker can leak an absolute address, they may be able to determine the absolute address of other parts of memory relative to the absolute address they leaked. ASLR randomizes absolute addresses by changing the start of sections of memory, but it does not randomize the relative addresses of variables. Combining Mitigations \u00b6 Let's now just use multiple mitigations to force the attacker to find multiple vulnerabilities to exploit the program. This process is known as synergistic protection, where one mitigation helps strengthen another mitigation. Combining ASLR and non-executable pages results in an attacker not being able to write their own shellcode, because of non-executable pages, and not being able to use existing code in memory, because they don't know the addresses of that code. To defeat ASLR and non-executable pages, the attacker needs to find two vulnerabilities: find a way to leak memory and reveal the address location to defeat ASLR, and then find a way to write to memory and write an ROP chain.","title":"4. Mitigating Memory-Safety Vulnerabilities"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#4-mitigating-memory-safety-vulnerabilities","text":"","title":"4. Mitigating Memory-Safety Vulnerabilities"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#use-a-memory-safe-language","text":"Just use Java, Python, Go, Rust, Swift, etc. They do compile-time and runtime checks that prevent memory errors from occuring. Boom, done.","title":"Use a Memory-Safe Language"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#writing-memory-safe-code","text":"In code, write your pre-conditions and post-conditions for every function you write and using invariants to prove that these conditions are satisfied. Defensive programming: always add checks in your code just in case something could go wrong. Always check that a pointer is not null before dereferencing it, even if you are sure that the pointer is always going to be valid Use safe libraries, which use functions that check bounds so you don't have to. fgets rather than gets strncpy rather than strcpy snprintf instead of sprintf","title":"Writing Memory-Safe Code"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#building-secure-software","text":"Use tools to analyze and patch insecure code. Run-time checks that do automatic bound-checking On check failure, direct it towards a controlled crash, ensuring the attacker does not succeed Hire someone to look over your code for memory safety errors Probe your own system for vulnerabilities Fuzz test (test with random inputs), corner cases, Valgrind","title":"Building Secure Software"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#exploit-mitigations","text":"Code hardening defenses are mitigations: they try to make common exploits harder and cause exploits to crash instead of succeeding, but they are not foolproof. The only way to prevent all memory safety exploits is to use a memory-safe language.","title":"Exploit Mitigations"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#mitigation-non-executable-pages","text":"A common buffer overflow involves the attacker to write some machine code into memory, and then redirect the program to execute the injected code. [shellcode] + [4 bytes of garbage] + [address of buf] To defend: make some portions of memory non-executable. This means that the computer should not interpret any data in these regions as CPU instructions. You can think of it as not allowing the eip to ever contain the address of a non-executable part of memory. Since modern systems separate memory into pages, make each page of memory either writable or executable, not both. It defends against stack smasking attacks","title":"Mitigation: Non-Executable Pages"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#subverting-non-executable-pages-return-into-libc","text":"Non-executable pages do not stop an attacker from executing existing code in memory. C programs have libraries of up to million of lines. All these instructions are marked as executable (and non-writable), since the programmer may want to call these functions legitimately. Attackers can just overwrite the rip with the address of a C library function. execv function lets the attacker start executing the instructions of some other executable. It takes the string of the filename of the program to execute. Put what you want to run on the stack. pwned.","title":"Subverting Non-Executable Pages: Return Into libc"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#subverting-non-executable-pages-return-oriented-programming","text":"Return-oriented programming is a technique that overwrites a chain of return addresses starting at the rip in order to execute a series of \"ROP gadgets\" which are equivalent to the desired malicious code. We create a custom shellcode using pieces of code that already exist in memory. Instead of executing an existing function, like we did with \"return to libc\", with ROP you can execute your own code by simply executing different pieces of different code. If we wanted to add 4 to the value currently in the edx register as part of a larger program. In loaded memory, we have the following functions: foo: ... 0x4005a1 <foo+33> mov %edx, %eax 0x4005a3 <foo+35> leave 0x4005a4 <foo+36> ret ... bar: ... 0x400604 <bar+20> add $0x4, %eax 0x400608 <bar+24> pop %ebx 0x40060a <bar+26> leave 0x40060b <bar+27> ret To emulate the add $0x4, %edx instruction, move the value in edx to eax using the gadget in foo then add 4 to eax using gadget in bar. Therefore set the first return address to 0x004005a1 and the second return address to 0x00400604 to produce the desired result. Every time we jump to ROP gadget, we eventually execute the ret instruction and then pop the next return address off the stack, jumping to the next gadget. We just have to keep track that our desired value is now in a different register, and because we execute a pop %ebx instruction in bar before we return, we also have to remember that the value in ebx has been updated after executing these gadgets\u2014but these are all behaviors that we can account for using standard compiler techniques. In fact, so-called \u201cROP compilers\u201d exist to take an existing vulnerable program and a desired execution flow and generate a series of return addresses. General strategy: Write a chain of return addresses at the rip to achieve the behavior that we want. Each return address should point to a gadget, which is a small set of assembly instructions that already exist in memory and usually end in a ret instruction. The gadget then executes its instructions and ends with a ret instruction, which tells the code to jump to the next address on the stack, thus allowing us to jump to the next gadget! There are usually enough gadgets in memory for you to be able to run any shellcode you want. ROP compilers exist that will automatically generate a ROP chain for you based on a target binary and desired malicious code.","title":"Subverting Non-Executable Pages: Return-Oriented Programming"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#mitigation-stack-canaries","text":"When we call a function, the compiler places a known dummy value, the stack canary, on the stack. This canary value is not used by the function at all, so it should stay unchanged throughout the duration of the function. The compiler will then check that the canary value has not been changed when the function returns. If canary changes, crash the program, since that is evidence something bad has happened. Stack canary uses the fact that many common stack smashing attacks involve overflowing a local variable to overwrite sfp and rip directly above. If an attacker starts writing at a buffer and wants to overwrite the rip , then they must overwrite everything in between the buffer and the rip . The stack canary is a random value generated at runtime. It is 1 word long. Stack canaries are usually guaranteed to contain a null byte (the first one usually). This lets the canary defend against string-based memory safety exploits, such as vulnerable calls to strcpy that read or write values from the stack until a null byte is encountered. The canary value changes each time the program is run.","title":"Mitigation: Stack Canaries"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#subverting-stack-canaries","text":"Many exploits that the stack canary cannot detect: Stack canaries can't defend against attacks outside of the stack, such as vulnerable heap memory Stack canaries don't stop an attacker from overwriting other local variables. If there is an authenticated flag in the stack, we can still attack that Some exploits can write to non-consecutive parts of memory, such as format string vulnerabilities can let an attacker write directly to the rip without having to overwrite everything between a local variable and the rip , thus writing around the canary. Other techniques for defeating the stack canary: Guessing the canary. There are usually 24 bits of entropy (randomness) Let's say the attacker is lucky and runs it \\(2^{24}\\) times. In a 32-bit architecture, if every attempt took 1 second, it would take over 100 days to succeed (on 64-bit, it would take 2 million years if they did 1k attempts per second). Leak the canary: sometimes the program has a vulnerability that allows the attacker to read parts of memory, like format string vulnerabilities. If we leak the value, write it down, and then inject an exploit that overwrites the canary with its leaked value, all under a single run, we can pwned the system.","title":"Subverting Stack Canaries"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#mitigation-pointer-authentication","text":"Pointer authentication takes advantage of the fact that in a 64-bit architecture, many bits of the address are unused. A modern CPU might support a 4 TiB space, which needs 42 bits to address all of memory. There is then a lot of unused address space. Idea: consider using these unused bits to store a secret like the stack canary. Replace the 22 unused bits with some secret value, known as pointer authentication code (PAC) before pushing the value on the stack. If the rip of the function in a 64-bit system is 0x0000001234567899 . Address space is 40bits, and so the top 24 bits are always 0. Instead of pushing this address to the stack. Replace the unused bytes with PAC. However, this will make dereferencing the address invalid. Therefore, CPU will check the PAC is unchanged. If correct, CPU replaces the secret with the original unused bits to make the address valid again. Let's make it better and have the CPU use a different PAC for every pointer stored on the stack with some special math to determine them on the fly. Let's say we have \\(f(key, address)\\) , which outputs a PAC by performing some operation on these two inputs. The function will be deterministic. The function is also secure: an attacker who doesn't know the value of key cannot output secret values of their own. With PAC enabled, an attacker is never able to overwrite pointers on the stack without generating the corresponding secret for the attacker's malicious address. To subvert this, we might have to find a separate vulnerability in the program that allows the attacker to trick the program into creating a validated pointer. Or, they could try to discover the key.","title":"Mitigation: Pointer Authentication"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#mitigation-address-space-layout-randomization","text":"ASLR is a mitigation that tries to make predicting addresses in memory more difficult. Each time the program is run, the beginning of each section of memory is randomly chosen. If the program imports libraries, randomize the starting addresses of each library's source code. ASLR causes absolute addresses of variables, save registers, and code instructions to be different each time the program is run. Therefore, the attacker must guess the address of their own malicious instructions. Attacker cannot place shellcode on the stack without knowing the address of the stack Attacker cannot place shellcode on the heap without knowing the address of the heap The attacker cannot construct an ROP chain or a return-to-libc attack without knowing the address of the code Some constraints of ASLR: Segments need to start at a page boundary. In other words, the starting address of each section of memory needs to be a multiple of page size (typically 4096 bytes in a 32-bit architecture)","title":"Mitigation: Address Space Layout Randomization"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#subverting-aslr","text":"Two ways to subvert the ASLR Guess the address. Leak the address: sometimes the program has a vulnerability that allows the attacker to read parts of memory. For example, format string vulnerabilities. The stack often stores absolute addresses, such as pointers and saved registers. If the attacker can leak an absolute address, they may be able to determine the absolute address of other parts of memory relative to the absolute address they leaked. ASLR randomizes absolute addresses by changing the start of sections of memory, but it does not randomize the relative addresses of variables.","title":"Subverting ASLR"},{"location":"EECS/CS%20161/Memory%20Safety/4.%20Mitigating%20Memory-Safety%20Vulnerabilities/#combining-mitigations","text":"Let's now just use multiple mitigations to force the attacker to find multiple vulnerabilities to exploit the program. This process is known as synergistic protection, where one mitigation helps strengthen another mitigation. Combining ASLR and non-executable pages results in an attacker not being able to write their own shellcode, because of non-executable pages, and not being able to use existing code in memory, because they don't know the addresses of that code. To defeat ASLR and non-executable pages, the attacker needs to find two vulnerabilities: find a way to leak memory and reveal the address location to defeat ASLR, and then find a way to write to memory and write an ROP chain.","title":"Combining Mitigations"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/","text":"1. Security Principles \u00b6 This note describes the basic security principles one should consider when implementing anything computer security related. Know Your Threat Model \u00b6 Threat mode: model of who your attacker is and what resources they have. Here are some commone assumptions we take into account for attackers: Attacker can interact with your systems without anyone noticine, meaning you might not always be able to detect the attacker tampering with your system before they attack Attacker has general information about your system, such as the OS, any potential software vulnerabilities, etc. Attacker is persistent and lucky; for example any vulnerability left to chance should be assumed to work for the attacker Attacker has resources required to undertake the attack (such as computation power, money, etc.) Attacker can coordinate several complex attacks across various systems, so they can attack your entire network at the same time Every system is a potential target. For example, a casino was once hacked because a fish-tank thermometer was hacked within the network. Also consider old code where the threat model might have changed. The Internet was mostly populated by academics who trusted one another. Now there are billions of devices, some of them are malicious. Consider Human Factors \u00b6 There are also other non-coding related factors to consider Programmers themselves mighjt make mistakes and use tools that allow them to make mistakes Users like convenience, so if a security system is unusable and not user-friendly, no matter how secure it is, it will go unused Social engineering attacks are when one exploits other's trust and access for personal gain Security is Economics \u00b6 Sometimes more security means more costs, more money. But also sometimes one needs to consider the relation between the expected benefit of defense and the expected cost of the attack (such as putting a $100 lock on a $1 item). A corollary of this principle is that you should focus your energy on securing the weakest links. A system is only as secure as the weakest link. Attackers follow the path of least resistance, and they will attack the system at its weakest point. A related principle is conservative design, which states that systems should be evaluated according to the worst security failure that is at all plausible, under assumptions favorable to the attacker. Detect If You Can't Prevent \u00b6 Detection is simply learning tha the attack has taken place, and response would be doing something about the attack. When dealing with a response, you should always assume bad things will happen, and therefore prepare your systems for the worst case outcome. You should plan security in a way that lets you get back to some form of a working state a (like keeping offsite backups of computer systems). Defense In Depth \u00b6 Defense in depth is the idea that multiple types of defenses should be layered together so an attacker would have to breach all the defenses to successfully attack a system. Least Privilege \u00b6 This is the idea that one should give a program a set of access privileges that it legitmately needs to do its job but nothing more. This is a powerful approach -- although it doesn't reduce the probably of failure, it can reduce the expected cost of failures, such as in the case of buffer overflows. Separation of Responsibility \u00b6 Split up privilege, so that no one person has complete power. Require more than one party to approve before access is granted. Ensure Complete Mediation \u00b6 Make sure that you check every access to every object. On eway to accomplish this is through a reference monitor, which is a single point through which all access must occur. Shannon's Maxim \u00b6 States that the attacker knows the system that they are attacking. Security through obscurity: refers to systems that rely on the secrecy of their design, algorithms, or source code to be secure. However, it is extremely brittle and is ofted difficult to keep the design of a system secret from a sufficiently motivated attacker. This doesn't mean that open-source applications are necessarily more secure than closed-source applications. Never rely on obscurity as part of your security. Always assume that the attacker knows every detail about the system that you are working with. Kerckhoff's Principle: cryptographic systems should remain secure even when the attacker knows all internal details of the systems. The secret key should be the only thing that must be kept secret, and the system should be designed to make it easy to change keys that are leaked (or suspected to be leaked). Use Fail-Safe Defaults \u00b6 Choose default setting that \"fail safe\", balancing security with usability when a system goes down. Ensure that if the security mechanisms fail or crash, they will default to secure behavior, not insecure behavior. For example, firewalls explicitly decide to foward a given packet or else the packet is lost. If a firewall suffers a failure, no packets will be forwarded. Design Security in From the Start \u00b6 Retrofitting security to an existing application after it has already been spec'ed, designed, and implemented is usually very difficult. Look to the Internet as a whole as an example. The Trusted Computing Base (TCB) \u00b6 TCB is that portion of the system that must oerate correctly in order for the security goals of the system to be assured. We have to rely on every component in the TCB to work correctly. HOwever, anything that is outside the TCB isn't relied upon in any way; even if it misbehaves or operates maliciously, it cannot defeat the system's security goals. TCB is made to be small as possible since a smaller, simpler TCB is easier to write and audit. TCB Design Principles: 1. Unbypassable (or completeness): There must be no way to breach system securit by bypassing the TCB 2. Tamper-resistat (or security): The TCB should be protected from tampering by anyone else. 3. Verifiable (or correctness): It should be possible to verify the correctness of the TCB. This usually means the TCB should be as simple as possible. TCB simple and small: less code you have to write, the fewer changes you have to make a mistake or introduce some kind of implementation flaw. Industry error rates are 1-5 defects/1000 lines of code. Benefits of TCB: 1. Allows a primitive yet effective form of modularity 2. Lets us separate the system into two parts (the security-critical (TCB) and everything else Summary of good principles: 1. Know what is in the TCB. Design your system so that the TCB is clearly identifiable 2. Try to make the TCB unbypassable, tamper-resistant, and verifiable 3. Keep It Simple, Stupid (KISS) 4. Decompose for security. Choose an architecture that makes the TCB as simple and clear as possible TOCTTOU Vulnerabilities \u00b6 Common failure of ensuring complete mediation involves race conditions. TOCTTOUS (Time of check to time of use) vulnerability arises when enforcing access control policies such as when using a reference monitor: procedure withdraw(amount w) { // contact central server to get balance 1. let b := balance 2. if b < w, abort // contact central server to set the balance 3. set balance := b - w 4. give w dollars to the user } With this code, we see that multiple calls to withdraw concurrently can break it. It the attacker knew the execution procedure, they can withdraw infinite amounts of money. This is TOCTTOU, because between the check and the use of whatever state was checked, the state somehow changed. In the example, between the time that the balance was checked and the time the balance was set, the balance was somehow changed.","title":"1. Security Principles"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#1-security-principles","text":"This note describes the basic security principles one should consider when implementing anything computer security related.","title":"1. Security Principles"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#know-your-threat-model","text":"Threat mode: model of who your attacker is and what resources they have. Here are some commone assumptions we take into account for attackers: Attacker can interact with your systems without anyone noticine, meaning you might not always be able to detect the attacker tampering with your system before they attack Attacker has general information about your system, such as the OS, any potential software vulnerabilities, etc. Attacker is persistent and lucky; for example any vulnerability left to chance should be assumed to work for the attacker Attacker has resources required to undertake the attack (such as computation power, money, etc.) Attacker can coordinate several complex attacks across various systems, so they can attack your entire network at the same time Every system is a potential target. For example, a casino was once hacked because a fish-tank thermometer was hacked within the network. Also consider old code where the threat model might have changed. The Internet was mostly populated by academics who trusted one another. Now there are billions of devices, some of them are malicious.","title":"Know Your Threat Model"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#consider-human-factors","text":"There are also other non-coding related factors to consider Programmers themselves mighjt make mistakes and use tools that allow them to make mistakes Users like convenience, so if a security system is unusable and not user-friendly, no matter how secure it is, it will go unused Social engineering attacks are when one exploits other's trust and access for personal gain","title":"Consider Human Factors"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#security-is-economics","text":"Sometimes more security means more costs, more money. But also sometimes one needs to consider the relation between the expected benefit of defense and the expected cost of the attack (such as putting a $100 lock on a $1 item). A corollary of this principle is that you should focus your energy on securing the weakest links. A system is only as secure as the weakest link. Attackers follow the path of least resistance, and they will attack the system at its weakest point. A related principle is conservative design, which states that systems should be evaluated according to the worst security failure that is at all plausible, under assumptions favorable to the attacker.","title":"Security is Economics"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#detect-if-you-cant-prevent","text":"Detection is simply learning tha the attack has taken place, and response would be doing something about the attack. When dealing with a response, you should always assume bad things will happen, and therefore prepare your systems for the worst case outcome. You should plan security in a way that lets you get back to some form of a working state a (like keeping offsite backups of computer systems).","title":"Detect If You Can't Prevent"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#defense-in-depth","text":"Defense in depth is the idea that multiple types of defenses should be layered together so an attacker would have to breach all the defenses to successfully attack a system.","title":"Defense In Depth"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#least-privilege","text":"This is the idea that one should give a program a set of access privileges that it legitmately needs to do its job but nothing more. This is a powerful approach -- although it doesn't reduce the probably of failure, it can reduce the expected cost of failures, such as in the case of buffer overflows.","title":"Least Privilege"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#separation-of-responsibility","text":"Split up privilege, so that no one person has complete power. Require more than one party to approve before access is granted.","title":"Separation of Responsibility"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#ensure-complete-mediation","text":"Make sure that you check every access to every object. On eway to accomplish this is through a reference monitor, which is a single point through which all access must occur.","title":"Ensure Complete Mediation"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#shannons-maxim","text":"States that the attacker knows the system that they are attacking. Security through obscurity: refers to systems that rely on the secrecy of their design, algorithms, or source code to be secure. However, it is extremely brittle and is ofted difficult to keep the design of a system secret from a sufficiently motivated attacker. This doesn't mean that open-source applications are necessarily more secure than closed-source applications. Never rely on obscurity as part of your security. Always assume that the attacker knows every detail about the system that you are working with. Kerckhoff's Principle: cryptographic systems should remain secure even when the attacker knows all internal details of the systems. The secret key should be the only thing that must be kept secret, and the system should be designed to make it easy to change keys that are leaked (or suspected to be leaked).","title":"Shannon's Maxim"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#use-fail-safe-defaults","text":"Choose default setting that \"fail safe\", balancing security with usability when a system goes down. Ensure that if the security mechanisms fail or crash, they will default to secure behavior, not insecure behavior. For example, firewalls explicitly decide to foward a given packet or else the packet is lost. If a firewall suffers a failure, no packets will be forwarded.","title":"Use Fail-Safe Defaults"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#design-security-in-from-the-start","text":"Retrofitting security to an existing application after it has already been spec'ed, designed, and implemented is usually very difficult. Look to the Internet as a whole as an example.","title":"Design Security in From the Start"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#the-trusted-computing-base-tcb","text":"TCB is that portion of the system that must oerate correctly in order for the security goals of the system to be assured. We have to rely on every component in the TCB to work correctly. HOwever, anything that is outside the TCB isn't relied upon in any way; even if it misbehaves or operates maliciously, it cannot defeat the system's security goals. TCB is made to be small as possible since a smaller, simpler TCB is easier to write and audit. TCB Design Principles: 1. Unbypassable (or completeness): There must be no way to breach system securit by bypassing the TCB 2. Tamper-resistat (or security): The TCB should be protected from tampering by anyone else. 3. Verifiable (or correctness): It should be possible to verify the correctness of the TCB. This usually means the TCB should be as simple as possible. TCB simple and small: less code you have to write, the fewer changes you have to make a mistake or introduce some kind of implementation flaw. Industry error rates are 1-5 defects/1000 lines of code. Benefits of TCB: 1. Allows a primitive yet effective form of modularity 2. Lets us separate the system into two parts (the security-critical (TCB) and everything else Summary of good principles: 1. Know what is in the TCB. Design your system so that the TCB is clearly identifiable 2. Try to make the TCB unbypassable, tamper-resistant, and verifiable 3. Keep It Simple, Stupid (KISS) 4. Decompose for security. Choose an architecture that makes the TCB as simple and clear as possible","title":"The Trusted Computing Base (TCB)"},{"location":"EECS/CS%20161/Security%20Principles/1.%20Security%20Principles/#tocttou-vulnerabilities","text":"Common failure of ensuring complete mediation involves race conditions. TOCTTOUS (Time of check to time of use) vulnerability arises when enforcing access control policies such as when using a reference monitor: procedure withdraw(amount w) { // contact central server to get balance 1. let b := balance 2. if b < w, abort // contact central server to set the balance 3. set balance := b - w 4. give w dollars to the user } With this code, we see that multiple calls to withdraw concurrently can break it. It the attacker knew the execution procedure, they can withdraw infinite amounts of money. This is TOCTTOU, because between the check and the use of whatever state was checked, the state somehow changed. In the example, between the time that the balance was checked and the time the balance was set, the balance was somehow changed.","title":"TOCTTOU Vulnerabilities"},{"location":"EECS/CS%20168/toc%20CS168/","text":"Table of Contents CS 168 \u00b6 This note serves as the CS 168 toc. Get back to toc EECS CS 168 Introduction to the Internet: Architecture and Protocols \u00b6 Lectures: [[1. Introduction]] 2. How the Internet Works - A Bottom-Up View 3. Architectural Principles 4. Designing the Internet 5. Routing Fundamentals 6. Routing Approaches I 7. Routing Approaches II Notes: 0. Introduction to CS 168 1. Computer Networks and the Internet [[1.1 What is the Internet?]] 2. Application Layer 2.1 Principles of Network Applications 2.2 The Web and HTTP 2.3 Electronic Mail in the Internet 2.4 DNS - The Internet's Directory Service [[3. Transport Layer]] [[4. The Network Layer: Data Plane]] [[5. The Network Layer: Control Plane]] [[6. The Link Layer and LANs]] [[7. Wireless and Mobile Networks]] [[8. Security in Computer Networks]]","title":"Table of Contents CS 168"},{"location":"EECS/CS%20168/toc%20CS168/#table-of-contents-cs-168","text":"This note serves as the CS 168 toc. Get back to toc EECS","title":"Table of Contents CS 168"},{"location":"EECS/CS%20168/toc%20CS168/#cs-168-introduction-to-the-internet-architecture-and-protocols","text":"Lectures: [[1. Introduction]] 2. How the Internet Works - A Bottom-Up View 3. Architectural Principles 4. Designing the Internet 5. Routing Fundamentals 6. Routing Approaches I 7. Routing Approaches II Notes: 0. Introduction to CS 168 1. Computer Networks and the Internet [[1.1 What is the Internet?]] 2. Application Layer 2.1 Principles of Network Applications 2.2 The Web and HTTP 2.3 Electronic Mail in the Internet 2.4 DNS - The Internet's Directory Service [[3. Transport Layer]] [[4. The Network Layer: Data Plane]] [[5. The Network Layer: Control Plane]] [[6. The Link Layer and LANs]] [[7. Wireless and Mobile Networks]] [[8. Security in Computer Networks]]","title":"CS 168 Introduction to the Internet: Architecture and Protocols"},{"location":"EECS/CS%20168/0.%20Introduction%20to%20CS%20168/0.%20Introduction%20to%20CS%20168/","text":"0. Introduction \u00b6 The purpose of these notes is to go through the content of computer networking and architecture, based on the material from the textbook, Computer Networking: A Top-Down Approach by Kurose and Ross. I plan to make a set of comprehensive notes out of these notes, so I would like to think of this as a rough draft of it. I also will draw notes from the class CS 168 Introduction to the Internet: Architecture and Protocols, taken at UC Berkeley and taught by Professor Sylvia Ratnasamy. Primarily these notes will be meant for this class, and will possibly be made for future students taking this class. Personally, I have no experience in this subject, but through these notes, I hope I can get proficient in the jargon and concepts well enough. The plan is to follow with the concepts of lecture, drawing from the textbook for more detailed information. Next section: 1. Computer Networks and the Internet","title":"0. Introduction"},{"location":"EECS/CS%20168/0.%20Introduction%20to%20CS%20168/0.%20Introduction%20to%20CS%20168/#0-introduction","text":"The purpose of these notes is to go through the content of computer networking and architecture, based on the material from the textbook, Computer Networking: A Top-Down Approach by Kurose and Ross. I plan to make a set of comprehensive notes out of these notes, so I would like to think of this as a rough draft of it. I also will draw notes from the class CS 168 Introduction to the Internet: Architecture and Protocols, taken at UC Berkeley and taught by Professor Sylvia Ratnasamy. Primarily these notes will be meant for this class, and will possibly be made for future students taking this class. Personally, I have no experience in this subject, but through these notes, I hope I can get proficient in the jargon and concepts well enough. The plan is to follow with the concepts of lecture, drawing from the textbook for more detailed information. Next section: 1. Computer Networks and the Internet","title":"0. Introduction"},{"location":"EECS/CS%20168/1.%20Overview%20of%20Computer%20Networks%20and%20the%20Internet/1.%20Computer%20Networks%20and%20the%20Internet/","text":"1. Computer Networks and the Internet \u00b6 In this note, I summarize the chapter, which discusses the contents of the Internet at a super high level. Get back to toc CS168 This chapter looks at various pieces of hardware and software that make up the Internet and computer networks. We will be looking at the edge of the network first, loking at end systems and its applications, following the transport service provided to the applications running on the end systems. Then we will look at the technologies found in the access network, finally reaching into the network core, identifying packet switching and circuit switching as the two basic approaches for transporting data through a telecommunication network, analyzing the strengths and weaknesses of these approaches. The Internet\u2019s hierarchical structure consists of higher and lower ISPs, which allow it to scale to include thousands of networks. Then some introductory concepts of computer networking will be discussed. We will look at the causes of delay, throughput and packet loss in a packet-switched network, developing models for transmission, propagation, and queuing delays as well as for throughput. In addition, protocol layering and service models are key architectural principles in networking. Finally we will look at prevalent security attacks. Sections in this Chapter: [[1.1 What is the Internet?]] [[1.2 The Network Edge]] [[1.3 The Network Core]] [[1.4 Delay, Loss, and Throughput in Packet-Switched Networks]] [[1.5 Protocol Layers and Their Service Models]] [[1.6 Networks Under Attack]] [[1.7 History of Computer Networking and the Internet]]","title":"1. Computer Networks and the Internet"},{"location":"EECS/CS%20168/1.%20Overview%20of%20Computer%20Networks%20and%20the%20Internet/1.%20Computer%20Networks%20and%20the%20Internet/#1-computer-networks-and-the-internet","text":"In this note, I summarize the chapter, which discusses the contents of the Internet at a super high level. Get back to toc CS168 This chapter looks at various pieces of hardware and software that make up the Internet and computer networks. We will be looking at the edge of the network first, loking at end systems and its applications, following the transport service provided to the applications running on the end systems. Then we will look at the technologies found in the access network, finally reaching into the network core, identifying packet switching and circuit switching as the two basic approaches for transporting data through a telecommunication network, analyzing the strengths and weaknesses of these approaches. The Internet\u2019s hierarchical structure consists of higher and lower ISPs, which allow it to scale to include thousands of networks. Then some introductory concepts of computer networking will be discussed. We will look at the causes of delay, throughput and packet loss in a packet-switched network, developing models for transmission, propagation, and queuing delays as well as for throughput. In addition, protocol layering and service models are key architectural principles in networking. Finally we will look at prevalent security attacks. Sections in this Chapter: [[1.1 What is the Internet?]] [[1.2 The Network Edge]] [[1.3 The Network Core]] [[1.4 Delay, Loss, and Throughput in Packet-Switched Networks]] [[1.5 Protocol Layers and Their Service Models]] [[1.6 Networks Under Attack]] [[1.7 History of Computer Networking and the Internet]]","title":"1. Computer Networks and the Internet"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.%20Application%20Layer/","text":"2. Application Layer \u00b6 In this chapter, we will look at the conceptual and implementation aspects of network applications, which start with key application-layer concepts, including network services. Then we will look at several network applications in dettail. Application layer is a good place to start our study of protocols. Contents: 2.0 Key Terms 2.1 Principles of Network Applications 2.2 The Web and HTTP 2.3 Electronic Mail in the Internet 2.4 DNS - The Internet's Directory Service 2.5 Peer-to-Peer File Distribution [[2.6 Video Streaming and Content Distribution Networks]] [[2.7 Socket Programming: Creating Network Applications]] [[2.8 Summary]]","title":"2. Application Layer"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.%20Application%20Layer/#2-application-layer","text":"In this chapter, we will look at the conceptual and implementation aspects of network applications, which start with key application-layer concepts, including network services. Then we will look at several network applications in dettail. Application layer is a good place to start our study of protocols. Contents: 2.0 Key Terms 2.1 Principles of Network Applications 2.2 The Web and HTTP 2.3 Electronic Mail in the Internet 2.4 DNS - The Internet's Directory Service 2.5 Peer-to-Peer File Distribution [[2.6 Video Streaming and Content Distribution Networks]] [[2.7 Socket Programming: Creating Network Applications]] [[2.8 Summary]]","title":"2. Application Layer"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.0%20Key%20Terms/","text":"2.0 Key Terms \u00b6","title":"2.0 Key Terms"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.0%20Key%20Terms/#20-key-terms","text":"","title":"2.0 Key Terms"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/","text":"2.1 Principles of Network Appications \u00b6 At the core of network application develop is writing programs that run on different end systems and communicate with each other over the network. Thus, when developing your new application, you need to write software that will run on multiple end systems. This can be written in C, Java, Python, etc. Network Application Architectures \u00b6 The application architecture is designed by the application developer and dictates how the applicatio nis structured over the various end systems. This is opposed to network architecture (the 5-layer Internet architecture discussed in 1. Computer Networks and the Internet . Network architecture is fixed. Client-server architecture is the structuer where there is an always-on host, called the server, which services requests from many other hosts, called clients. Some notes: always-on Web server services requests from browsers running on client hosts. When a Web server receives a request for an objectfrom a client host, it responds by sending he requested object to the client host. Note that with client-server architecture, clients do not directly communicate with each other; two browsers do not communicate with each other, they instead communicate with a server. In client-server architecture, servers have a fixed, well-known address, called an IP address. A client can always contact the server by sending a packet to the server's IP address Data centers (housing a large number of hosts) is often used to create a powerful virtual server Peer-to-Peer architecture (P2P architecture), there is minimal reliance on deciated servers in data centers. Instead the application exploits direct communication between pairs of intermittenly connected hosts, called peers. Some notes: Peers are not owned by the service provider, but are instead desktops and laptops controlled by users, with most of the peers residing in homes, universities, offices, etc. There is no dedicated server it passes through. A compelling feature of P2P: self-scalability. In a P2P file sharing application, although each peer generates workload by requesting files, each peer also adds service capacity to the system by distributing files to other peers. Cost effective, since they normally don't require significant server infrastructure and server bandwidth Faces challenges of security, performance, and reliability due to their highly decentralized structure. An image showing the difference: Process Communicating \u00b6 You also need a basic understanding of how programs, running in multiple end systems, communicate with each other. In jargon of OS, it is not actually programs but processes that communicate. Process: program that is running within an end system. When processes are running on the same end system, they can communicate with each other with interprocess communication. We are interested in how processes running on different hosts (with potentially different OS) communicate. Processes communicate by exchanging messages across the computer network. A receiving process receives these messages and possibly responds by sending messages back. Client and Server Processes \u00b6 In the context of communication session between a pair of processes, the process that initiates the communication is labeled as the client. The process that waits to be contacted to begin the session is the server. Web application - browser is the client process, and the Web server is the server process P2P file-sharing system - peer that is downloading is the client, and the peer that is uploading is the server You see in P2P that a process can be both a client and a server. It just depends on the context. The Interface Between the Process and the Computer Network \u00b6 A process sends messages into, and receives messages from, the network through a sofware interface called a socket. If a process is a house, the socket is the door. When a process wants to send a message to another process on another host, it shoves the message out its door. Once the message arrives at the destination host, the message passes through the receiving process's door, and the receiving process then acts on the message. A socket is the interface between the application layer and the transprt layer within a host. It is also known as the Application Programming Interface (also known as API) between the application and the network. The only control that the application develop has on the transport-layer side is 1. The choice of transport protocol 2. Perhaps the ability to fix a few transport-layer parameters such as maximum buffer and maximum segment sizes Addressing Processes \u00b6 To identify the receiving process, two pieces of information need to be specified 1. The address ofthe host 2. An identifier that specifies the receiving process in the destination host The host is identified by its IP address. We also need to identify the receiving process, called the prot number. A Web server is identified by port number 80. Mail server process is identified by port number 25. Transport Services Available to Applications \u00b6 Many networks provide more than one transport-layer protocol. You must choose one of the available TL protocols. How do you know what to pick? We looko at 4 factors Reliable Data Transfer \u00b6 Packets can get lost within a computer network (overflow a buffer in a router, discarded by host or router after bit corruption). If a protocol provides such a guaranteed data delivery service, it is said to provide reliable data transfer. When a TL protcol doesn't provide reliable data transfer, some of the data sent by the sending process may never arrive at the receiving process. This may be acceptable for loss-tolerant applications, like multimedia applications that can tolerate some amount of data loss. Throughput \u00b6 Throughput is the rate at which the sending process can deliver bits to the receiving process. The available throughput fill fluctuate over time since there will be other sessions sharing the bandwidth, those coming and going. The application could provide guaranteed available throghput at some specified rate of \\(r \\;bits/sec\\) . Applications that have throughput requirements are said to be bandwidth-sensitive applications. Multimedia applications are bandwidth sensitive. Conversely elastic applications can make use of as much or as little throughput as happens to be available. Email, file transfer, and Web transfers are elastic applications. Timing \u00b6 TL protocol can also provide timing guarantees. An example guarantee might be that every bit that the sender pumps into the socket arrives at the receiver's socket no more than 100 msec later, which might be important in Internet telephony, virtual environments, teleconferencing, and multiplayer games. Lower delay is always preferable to higher delay. Security \u00b6 TL protocol can provide an application with one or more security services. The TL protocol can encrypt sending host data transmitted to the receiving host, which will be decrypted. Transport Services Provided by the Internet \u00b6 The Internet makes two transport protocols availabel to applications, TCP and UDP. One of the first decisions you have to make is whether to use TCP or UDP. TCP Services \u00b6 TCP service model includes a connection-oriented service and a reliable data transfer service. We get the following: Connection-oriented service: TCP has the client and server exchange TL control information with each other before the application-level messages begin to flow (a handshake procedure). Then a TCP connection is said to exist between the sockets of the two processes Reliable data transfer service: it will deliver all data sent without error and in proper order. Congestion control mechanism: throttles a sending process when the network is congested between sender and receiver UDP Services \u00b6 UDP is a no-frills, lightweight transport protocol, providing minimal services, UDP is connectionless, so there is no handshaking before the two processes start to communicate. We also have an unreliable data transfer service. UDP provides no guarantee that the message will ever reeach the receiving process. Furthermore, messages do not arrive at the same time, and might be out of order. There is also no congestin-control mechanism. Neither TCP nor UDP provide any encryption, the Internet communicty has developed an enhancement for TCP, called TLS (Transport Layer Security), that includes security. Services Not Provided by Internet Transport Protocols \u00b6 The dimension of timing is missing in TCP and UDP. Today's Internet, however, can often provide satisfactory service to time-sensitive applications, but it cannot provide any timing or throughput guarantees. Application-Layer Protocols \u00b6 An application-layer protocol defines how an application's processes, running on different end systems, pass messages to each other. If a TL protocol sends messages into sockets, the AL protocol will determine how the messages are structured. In particular, an application-layer protocol defines: The types of messages exchangs, for example, request messags and response messages the syntax of the various message types, such as the fields in the message and how the fields are delineated The semantics of the fields, that is, the meaning of the information in the fields Rules for determining when and how a process sends messages and responds to messages.","title":"2.1 Principles of Network Appications"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#21-principles-of-network-appications","text":"At the core of network application develop is writing programs that run on different end systems and communicate with each other over the network. Thus, when developing your new application, you need to write software that will run on multiple end systems. This can be written in C, Java, Python, etc.","title":"2.1 Principles of Network Appications"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#network-application-architectures","text":"The application architecture is designed by the application developer and dictates how the applicatio nis structured over the various end systems. This is opposed to network architecture (the 5-layer Internet architecture discussed in 1. Computer Networks and the Internet . Network architecture is fixed. Client-server architecture is the structuer where there is an always-on host, called the server, which services requests from many other hosts, called clients. Some notes: always-on Web server services requests from browsers running on client hosts. When a Web server receives a request for an objectfrom a client host, it responds by sending he requested object to the client host. Note that with client-server architecture, clients do not directly communicate with each other; two browsers do not communicate with each other, they instead communicate with a server. In client-server architecture, servers have a fixed, well-known address, called an IP address. A client can always contact the server by sending a packet to the server's IP address Data centers (housing a large number of hosts) is often used to create a powerful virtual server Peer-to-Peer architecture (P2P architecture), there is minimal reliance on deciated servers in data centers. Instead the application exploits direct communication between pairs of intermittenly connected hosts, called peers. Some notes: Peers are not owned by the service provider, but are instead desktops and laptops controlled by users, with most of the peers residing in homes, universities, offices, etc. There is no dedicated server it passes through. A compelling feature of P2P: self-scalability. In a P2P file sharing application, although each peer generates workload by requesting files, each peer also adds service capacity to the system by distributing files to other peers. Cost effective, since they normally don't require significant server infrastructure and server bandwidth Faces challenges of security, performance, and reliability due to their highly decentralized structure. An image showing the difference:","title":"Network Application Architectures"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#process-communicating","text":"You also need a basic understanding of how programs, running in multiple end systems, communicate with each other. In jargon of OS, it is not actually programs but processes that communicate. Process: program that is running within an end system. When processes are running on the same end system, they can communicate with each other with interprocess communication. We are interested in how processes running on different hosts (with potentially different OS) communicate. Processes communicate by exchanging messages across the computer network. A receiving process receives these messages and possibly responds by sending messages back.","title":"Process Communicating"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#client-and-server-processes","text":"In the context of communication session between a pair of processes, the process that initiates the communication is labeled as the client. The process that waits to be contacted to begin the session is the server. Web application - browser is the client process, and the Web server is the server process P2P file-sharing system - peer that is downloading is the client, and the peer that is uploading is the server You see in P2P that a process can be both a client and a server. It just depends on the context.","title":"Client and Server Processes"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#the-interface-between-the-process-and-the-computer-network","text":"A process sends messages into, and receives messages from, the network through a sofware interface called a socket. If a process is a house, the socket is the door. When a process wants to send a message to another process on another host, it shoves the message out its door. Once the message arrives at the destination host, the message passes through the receiving process's door, and the receiving process then acts on the message. A socket is the interface between the application layer and the transprt layer within a host. It is also known as the Application Programming Interface (also known as API) between the application and the network. The only control that the application develop has on the transport-layer side is 1. The choice of transport protocol 2. Perhaps the ability to fix a few transport-layer parameters such as maximum buffer and maximum segment sizes","title":"The Interface Between the Process and the Computer Network"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#addressing-processes","text":"To identify the receiving process, two pieces of information need to be specified 1. The address ofthe host 2. An identifier that specifies the receiving process in the destination host The host is identified by its IP address. We also need to identify the receiving process, called the prot number. A Web server is identified by port number 80. Mail server process is identified by port number 25.","title":"Addressing Processes"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#transport-services-available-to-applications","text":"Many networks provide more than one transport-layer protocol. You must choose one of the available TL protocols. How do you know what to pick? We looko at 4 factors","title":"Transport Services Available to Applications"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#reliable-data-transfer","text":"Packets can get lost within a computer network (overflow a buffer in a router, discarded by host or router after bit corruption). If a protocol provides such a guaranteed data delivery service, it is said to provide reliable data transfer. When a TL protcol doesn't provide reliable data transfer, some of the data sent by the sending process may never arrive at the receiving process. This may be acceptable for loss-tolerant applications, like multimedia applications that can tolerate some amount of data loss.","title":"Reliable Data Transfer"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#throughput","text":"Throughput is the rate at which the sending process can deliver bits to the receiving process. The available throughput fill fluctuate over time since there will be other sessions sharing the bandwidth, those coming and going. The application could provide guaranteed available throghput at some specified rate of \\(r \\;bits/sec\\) . Applications that have throughput requirements are said to be bandwidth-sensitive applications. Multimedia applications are bandwidth sensitive. Conversely elastic applications can make use of as much or as little throughput as happens to be available. Email, file transfer, and Web transfers are elastic applications.","title":"Throughput"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#timing","text":"TL protocol can also provide timing guarantees. An example guarantee might be that every bit that the sender pumps into the socket arrives at the receiver's socket no more than 100 msec later, which might be important in Internet telephony, virtual environments, teleconferencing, and multiplayer games. Lower delay is always preferable to higher delay.","title":"Timing"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#security","text":"TL protocol can provide an application with one or more security services. The TL protocol can encrypt sending host data transmitted to the receiving host, which will be decrypted.","title":"Security"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#transport-services-provided-by-the-internet","text":"The Internet makes two transport protocols availabel to applications, TCP and UDP. One of the first decisions you have to make is whether to use TCP or UDP.","title":"Transport Services Provided by the Internet"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#tcp-services","text":"TCP service model includes a connection-oriented service and a reliable data transfer service. We get the following: Connection-oriented service: TCP has the client and server exchange TL control information with each other before the application-level messages begin to flow (a handshake procedure). Then a TCP connection is said to exist between the sockets of the two processes Reliable data transfer service: it will deliver all data sent without error and in proper order. Congestion control mechanism: throttles a sending process when the network is congested between sender and receiver","title":"TCP Services"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#udp-services","text":"UDP is a no-frills, lightweight transport protocol, providing minimal services, UDP is connectionless, so there is no handshaking before the two processes start to communicate. We also have an unreliable data transfer service. UDP provides no guarantee that the message will ever reeach the receiving process. Furthermore, messages do not arrive at the same time, and might be out of order. There is also no congestin-control mechanism. Neither TCP nor UDP provide any encryption, the Internet communicty has developed an enhancement for TCP, called TLS (Transport Layer Security), that includes security.","title":"UDP Services"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#services-not-provided-by-internet-transport-protocols","text":"The dimension of timing is missing in TCP and UDP. Today's Internet, however, can often provide satisfactory service to time-sensitive applications, but it cannot provide any timing or throughput guarantees.","title":"Services Not Provided by Internet Transport Protocols"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.1%20Principles%20of%20Network%20Applications/#application-layer-protocols","text":"An application-layer protocol defines how an application's processes, running on different end systems, pass messages to each other. If a TL protocol sends messages into sockets, the AL protocol will determine how the messages are structured. In particular, an application-layer protocol defines: The types of messages exchangs, for example, request messags and response messages the syntax of the various message types, such as the fields in the message and how the fields are delineated The semantics of the fields, that is, the meaning of the information in the fields Rules for determining when and how a process sends messages and responds to messages.","title":"Application-Layer Protocols"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/","text":"2.2 The Web and HTTP \u00b6 This note explains how the Web and HTTP works The Web was the first Internet application that caught the general public's eye. It elevated the Internet from just one of many data networks to essentially the one and only data network. Overview of HTTP \u00b6 HyperText Transfer Protocol (HTTP), the Web's application-layer protocol, lies at the heart of the Web. It is implemented in two programs: a client program and a server program, executing on different end systems, which talk to each other by exchanging HTTP messages. HTTP defines the structure of these messages and how the client and server exchange the messages. First, some Web terminology: Web page: consists of objects object: a file, such as HTML file, JPEG image, Javascript fill, CCS style sheet, video clip, that is addressable by a single URL Base HTML File: The base of the Web pages that references the other objects in the page with the objects' URLs. URL: made of two components -- the hostname of the server that houses the object and the object's path name. http://www.someSchool.edu/someDepartment/picture.gif has www.someSchool.edu as the hostname, and /someDepartment/picture.gif for a path name. Web browsers: (Chrome, Internet Explorer) implement the client side of HTTP, in the context of the Web, we will use the words browser and client interchangeably Web servers: implement the server side of the HTTP, house Web objects, each addressable by a URL The general request-response behavior looks like this. HTTP request messages for the objects in the page to the server. The server recieves the requests and responds with HTTP response messages that contain the objects. HTTP uses TCP as its underlying transport protocol. The HTTP client first initiates a TCP connection with the server, then when the conection is established, the browser and server process access TCP through their socket interfaces. It is important to note that the server sends requested files to clients without storing any state information about the client. It completely forgets what it did. HTTP is said to be a stateless protocol since it maintains no information about the clients. Non-Persistent and Persistent Connections \u00b6 Non-persistent: when the client-server interaction is taking place over TCP each request/response pair is sent over a separate TCP connection Persistent: when the client-server interaction is taking place over TCP each request/response pair are all sent over the same TCP connection HTTP with Non-Persistent Connections \u00b6 Example: Let's have a page with base HTML file and 10 JPEG images, and that all 11 of these objects reside on the same surver. The URL for the base HTML file is http://www.someSchool.edu/someDepartment/home.index . This is what happens: HTTP client process initiates a TCP connection to the server www.someSchool.edu on port number 80 (default port number for HTTP). There will be a socket at the client and a socket at the server associated with the TCP connection. HTTP client sends HTTP request message to server via its socket. The request message includes the path name /someDepartment/home.index . HTTP server process receives request message via its socket, retrieves the object /someDepartment/home.index from its storage (RAM or disk), encapsulates the object in an HTTP response message, and sends the response message to the client via its socket HTTP server process tells TCP to close the TCP connection (it won't terminate until it knows for sure that the client has received the response message intact) HTTP client receives the response message, then the TCP connection terminates. The message indicates the encapsulated object is an HTML file. THe client extracts the file from the response message, examines the HTML file, and finds references to the 10 JPEG objects The first 4 steps are then repeated for each of the referenced JPEG objects. Not that here, each TCP connection is closed after the server sends the object. HTTP/1.0 employs non-persistent TCP connections. Therefore, 11 TCP connections are generated. Let's estimate amount of time that elapses. The round-trip time (RTT) is the time it takes for a small packet to travel from client to server and then back to the client. It includes packet-propagation delays, packet-queuing delays in intermediate routers and switches, and packet-processing delays. When a use clicks on a hyperlink, this causes the browser to initiate a TCP connection. There is a \"3-way handshake\" -- client sends small TCP segment to server, the server acknowledges and responds with a small TCP segment, and the client ackowledges back to the server. The first two parts of the handshake take one RTT, Then after the first two parts, the client sends the HTTP request into the TCP connection, and once this arrives at the server, the server sends the HTML file to TCP connection. This is another RTT, so it is 2 RTTs plus transmission time at the server of the HTML file. Shortcomings of Non-Persistent connections: Brand-new connections must be established and maintained for each requested object TCP buffers must be allocated and TCP variables must be kept in both the client and server, which places a significant burden on the Web surver Each object suffers a delivery delay of 2 RTTs -- one RTT to establish the TCP connection, and 1 RTT to request and receive the object. HTTP with Persistent Connections \u00b6 HTTP/1.1 uses persistent connections, the server leaves the TCP connection open after sending a response. So, the HTML file and the 10 images are sent over a single persistent TCP connection. HTTP Message Format \u00b6 Two types of HTTP messages: request, and response HTTP Request Message \u00b6 Typical HTTP request might look like GET /somedir/page.html HTTP/1.1 Host: www.someschool.edu Connection: close User-agent: Mozilla/5.0 Accept-language: fr The message is written in ordinary ASCII text, the message consists of 5 lines, each followed by a carriage return and a line feed. The last line is followed by an additional carriage return and line feed. A request message can have many more lines or as few as one line. First line is called request line, which has three parts Method field Can take on several different values: GET , POST , HEAD , PUT , DELETE . A great majority of HTTP request messages uses GET . GET gets used when browser requests an object, with the requested object identified in the URL field URL field HTTP version field Subsequent lines are the header lines. Host specifies the host on which the object resides Connection: close is the browser telling the server it does not want to bother with persistent connections. User-agent specifies the user agent is a Mozilla/5.0, a Firefox browser. You can send different versions of the same object to different types of user agents. Accept-language indicates that the user prefers to receive a French version of the object, if it exists, otherwise send the default version. Here is an image of the HTTP request message: The general format closely follows our example. The entity body is empty with GET method, but is used with POST method. POST is used when the user fills out a form, such as words to a search engine. The user still requests a Web page, but the specific contents depend on the input into the form. The entity body contains what the user entered into the form fields. HEAD is similar to GET . It reponds with an HTTP message but it leaves out the requested object. It is used for debugging PUT is used in conjunction with Web publishing tools. It allows a user to upload an object to a specific path on a specific Web server. DELETE allows a user to delete an object on the Web server. HTTP Response Message \u00b6 Here is an image of the response message: There are three sections: status line: three fields protocol version field status code corresponding status message header lines Very similar to the header lines in the request message entity body: the meat of the message. contains the requested object itself There are a few status codes you might have seen. These are the status codes and corresponding status messages: 200 OK: Request succeeded and information is returned in the response 301 Moved Permanently: Requested object has been permanently moved; the new URL is specified in a Location: header. The client software will automatically retrieve the new URL 400 Bad Request: Generic error code indicating that the request could not be understood by the server 404 Not Found: Requested document does not exist on the server 505 HTTP Version Not Supported: Requested HTTP protocol version is not supported by the server. User-Server Interaction: Cookies \u00b6 The HTTP server is stateless, which simplifies server design and permitted engineers to develop high-performance Web servers that can handle thousands of simultaneous TCP connections. Cookies however, allow sites to keep track of users. Cookie technology has 4 components: 1. Cookie header line in the HTTP response message 2. Cookie header lin in the HTTP request message 3. Cookie file kept on the user's end system and managed by the user's browser 4. Back-end database at the Web site When somone contacts Amazon.com for the first time, the server creates a unique identification number and creates an entry in its back-end database that is indexed by identification number. The Amazon Web server then responds to your browser, including in the HTTP reponse a Set-cookie: header, which contains the identification number. When your browser receives the HTTP response message, it sees the Set-cookie header, then it appends a line to the special cookie file that it manages. This line includes the hostname of the server and identification number. The cookie file may have entries from other websites. Now whenever you have activity on Amazon.com, although Amazon might not know who you are, they know exactly which pages user 1678 visited, in which order, and at what times. Thus, they can use cookies to provide its shopping cart service and other things, like recommend products. If you register an account with Amazon, then Amazon can include this information in its database, thereby associating a name to a cookie identification number. Web Caching \u00b6 A Web cache (or called proxy server) is a network entity that satisfies HTTP requests on behalf of an origin Web server. The Web cache has its own disk storage and keeps copies of recently requested objects in this storage. Suppose a browser requests http://www.someschool.edu/ campus.gif . Here is what happens: 1. Browser establishes TCP connection to Web cache and sends HTTP request for the object to the Web cache 2. Web cache checks to see if it has a copy of the object stored locally. If it does, the Web cache returns the object within an HTTP response message to the client browser 3. If the Web cache does not have the object, it opens a TCP connection to the origin server, www.someschool.edu . The Web cache then sends an HTTP request for the object into the cache-to-server TCP connection. After receiving the request the origin server sends the object within an HTTP response to the Web cache 4. When the Web cache receives the object, it stores a copy in its local storage and sends a copy, within an HTTP response message, to the client browser. It is super similar to caching in 16. Caches . Through use of Content Distribution Networks (CDNs), Web caches are increasingly playing an important role in the Internet. A CDN company installs many geographically distributed caches throughout the Internet, thereby localizing much of the traffic. The Conditional GET \u00b6 The conditional GET happens if (1) the request message uses the GET method and (2) the request message includes an If-Modified-Since header line. It allows a cache to verify that its objects are up to date. We might then send GET /fruit/kiwi.gif HTTP/1.1 Host: www.exotiquecuisine.com If-modified-since: Wed, 9 Sep 2015 09:23:24 Suppose the object has not been modified since that date, then the Web server sends a response message to the cache: HTTP/1.1 304 Not Modified Date: Sat, 10 Oct 2015 15:39:29 Server: Apache/1.3.0 (Unix) (empty entity body) So the conditional GET makes the Web server send a response message but does not include the requested object in the response message. If it has changed, then the server will send the object. HTTP/2 \u00b6 Standardized in 2015, HTTP/2 reduced perceived latency by enabling request and response multiplexing over a single TCP connection, provide request prioritization and server push, and provide efficient compression of HTTP header fields It does not change HTTP methods, status codes, URLs, header fields. It simply changes how the data is formatted and transported between client and server. The developers of Web browsers discovered that sending al lthe objects in a Web page over a single TCP connection has a Head of Line (HOL) blocking problem. If a large video clip is at the top of the Web page and bleow it are many small objects below it, the a single TCP connection will have the video clip take a long time to pass through the bottleneck link. HTTP/1.1 browsers typically work around this by opening multiple parallel TCP connections. HTTP/2 wants to get rid of parallel TCP connections, which reduces the number of sockets that need to be open and maintained at servers, but also allows TCP congestion control to operate as intended. TCP congestion controll provides browsers an unintended incentive to use multiple parallel TCP connections rather than a single persistent connection. HTTP/2 Framing \u00b6 The HTTP/2 solution for HOL blocking is to break each message into small frames, and interleave the request and response messages on the same TCP connection. We might break a large video clip into 8 smaller objects, so the server can receive 9 concurrent requests from any browser wanting to see the Web page, and for each request, the server needs to send 9 competing HTTP response messages to the browser. The ability to break down an HTTP message into independent frames, interleave them, and then reassemble them on the other end is the single most important enhancement of HTTP/2 Response Message Prioritization and Server Pushing \u00b6 Message prioritization allows developers to customize the relative priority of requests to better optimize applicaiton performance. We might assign a weight between 1 and 256 to each message, where higher number indicates higher priority. Another feature of HTTP/2: ability for server to send multiple responses for a single client request. The server can push additional objects to the client, without the client having to request each one. Instead of waiting for the HTTP requests for these objects, the server cna analyze the HTML page, identify the objects that are needed, and send them to the client before receiving explicit requests for these objects, which eliminates extra latency. HTTP/3 \u00b6 QUIC is a new transport protocol implemented in the applicaiton layer over the bare-bones UDP protocol. QUIC has several features desireable for HTTP, such as message multiplexing (interleaving), per-stream flow control, and low-latency connection establishment. HTTP/3 is yet a new HTTP protocol designed to operate over QUIC. As of 202, HTTP/2 is described in Internet drafts and has not yet been fully standardized. Many HTTP/2 features are subsumed by QUIC.","title":"2.2 The Web and HTTP"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#22-the-web-and-http","text":"This note explains how the Web and HTTP works The Web was the first Internet application that caught the general public's eye. It elevated the Internet from just one of many data networks to essentially the one and only data network.","title":"2.2 The Web and HTTP"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#overview-of-http","text":"HyperText Transfer Protocol (HTTP), the Web's application-layer protocol, lies at the heart of the Web. It is implemented in two programs: a client program and a server program, executing on different end systems, which talk to each other by exchanging HTTP messages. HTTP defines the structure of these messages and how the client and server exchange the messages. First, some Web terminology: Web page: consists of objects object: a file, such as HTML file, JPEG image, Javascript fill, CCS style sheet, video clip, that is addressable by a single URL Base HTML File: The base of the Web pages that references the other objects in the page with the objects' URLs. URL: made of two components -- the hostname of the server that houses the object and the object's path name. http://www.someSchool.edu/someDepartment/picture.gif has www.someSchool.edu as the hostname, and /someDepartment/picture.gif for a path name. Web browsers: (Chrome, Internet Explorer) implement the client side of HTTP, in the context of the Web, we will use the words browser and client interchangeably Web servers: implement the server side of the HTTP, house Web objects, each addressable by a URL The general request-response behavior looks like this. HTTP request messages for the objects in the page to the server. The server recieves the requests and responds with HTTP response messages that contain the objects. HTTP uses TCP as its underlying transport protocol. The HTTP client first initiates a TCP connection with the server, then when the conection is established, the browser and server process access TCP through their socket interfaces. It is important to note that the server sends requested files to clients without storing any state information about the client. It completely forgets what it did. HTTP is said to be a stateless protocol since it maintains no information about the clients.","title":"Overview of HTTP"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#non-persistent-and-persistent-connections","text":"Non-persistent: when the client-server interaction is taking place over TCP each request/response pair is sent over a separate TCP connection Persistent: when the client-server interaction is taking place over TCP each request/response pair are all sent over the same TCP connection","title":"Non-Persistent and Persistent Connections"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#http-with-non-persistent-connections","text":"Example: Let's have a page with base HTML file and 10 JPEG images, and that all 11 of these objects reside on the same surver. The URL for the base HTML file is http://www.someSchool.edu/someDepartment/home.index . This is what happens: HTTP client process initiates a TCP connection to the server www.someSchool.edu on port number 80 (default port number for HTTP). There will be a socket at the client and a socket at the server associated with the TCP connection. HTTP client sends HTTP request message to server via its socket. The request message includes the path name /someDepartment/home.index . HTTP server process receives request message via its socket, retrieves the object /someDepartment/home.index from its storage (RAM or disk), encapsulates the object in an HTTP response message, and sends the response message to the client via its socket HTTP server process tells TCP to close the TCP connection (it won't terminate until it knows for sure that the client has received the response message intact) HTTP client receives the response message, then the TCP connection terminates. The message indicates the encapsulated object is an HTML file. THe client extracts the file from the response message, examines the HTML file, and finds references to the 10 JPEG objects The first 4 steps are then repeated for each of the referenced JPEG objects. Not that here, each TCP connection is closed after the server sends the object. HTTP/1.0 employs non-persistent TCP connections. Therefore, 11 TCP connections are generated. Let's estimate amount of time that elapses. The round-trip time (RTT) is the time it takes for a small packet to travel from client to server and then back to the client. It includes packet-propagation delays, packet-queuing delays in intermediate routers and switches, and packet-processing delays. When a use clicks on a hyperlink, this causes the browser to initiate a TCP connection. There is a \"3-way handshake\" -- client sends small TCP segment to server, the server acknowledges and responds with a small TCP segment, and the client ackowledges back to the server. The first two parts of the handshake take one RTT, Then after the first two parts, the client sends the HTTP request into the TCP connection, and once this arrives at the server, the server sends the HTML file to TCP connection. This is another RTT, so it is 2 RTTs plus transmission time at the server of the HTML file. Shortcomings of Non-Persistent connections: Brand-new connections must be established and maintained for each requested object TCP buffers must be allocated and TCP variables must be kept in both the client and server, which places a significant burden on the Web surver Each object suffers a delivery delay of 2 RTTs -- one RTT to establish the TCP connection, and 1 RTT to request and receive the object.","title":"HTTP with Non-Persistent Connections"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#http-with-persistent-connections","text":"HTTP/1.1 uses persistent connections, the server leaves the TCP connection open after sending a response. So, the HTML file and the 10 images are sent over a single persistent TCP connection.","title":"HTTP with Persistent Connections"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#http-message-format","text":"Two types of HTTP messages: request, and response","title":"HTTP Message Format"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#http-request-message","text":"Typical HTTP request might look like GET /somedir/page.html HTTP/1.1 Host: www.someschool.edu Connection: close User-agent: Mozilla/5.0 Accept-language: fr The message is written in ordinary ASCII text, the message consists of 5 lines, each followed by a carriage return and a line feed. The last line is followed by an additional carriage return and line feed. A request message can have many more lines or as few as one line. First line is called request line, which has three parts Method field Can take on several different values: GET , POST , HEAD , PUT , DELETE . A great majority of HTTP request messages uses GET . GET gets used when browser requests an object, with the requested object identified in the URL field URL field HTTP version field Subsequent lines are the header lines. Host specifies the host on which the object resides Connection: close is the browser telling the server it does not want to bother with persistent connections. User-agent specifies the user agent is a Mozilla/5.0, a Firefox browser. You can send different versions of the same object to different types of user agents. Accept-language indicates that the user prefers to receive a French version of the object, if it exists, otherwise send the default version. Here is an image of the HTTP request message: The general format closely follows our example. The entity body is empty with GET method, but is used with POST method. POST is used when the user fills out a form, such as words to a search engine. The user still requests a Web page, but the specific contents depend on the input into the form. The entity body contains what the user entered into the form fields. HEAD is similar to GET . It reponds with an HTTP message but it leaves out the requested object. It is used for debugging PUT is used in conjunction with Web publishing tools. It allows a user to upload an object to a specific path on a specific Web server. DELETE allows a user to delete an object on the Web server.","title":"HTTP Request Message"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#http-response-message","text":"Here is an image of the response message: There are three sections: status line: three fields protocol version field status code corresponding status message header lines Very similar to the header lines in the request message entity body: the meat of the message. contains the requested object itself There are a few status codes you might have seen. These are the status codes and corresponding status messages: 200 OK: Request succeeded and information is returned in the response 301 Moved Permanently: Requested object has been permanently moved; the new URL is specified in a Location: header. The client software will automatically retrieve the new URL 400 Bad Request: Generic error code indicating that the request could not be understood by the server 404 Not Found: Requested document does not exist on the server 505 HTTP Version Not Supported: Requested HTTP protocol version is not supported by the server.","title":"HTTP Response Message"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#user-server-interaction-cookies","text":"The HTTP server is stateless, which simplifies server design and permitted engineers to develop high-performance Web servers that can handle thousands of simultaneous TCP connections. Cookies however, allow sites to keep track of users. Cookie technology has 4 components: 1. Cookie header line in the HTTP response message 2. Cookie header lin in the HTTP request message 3. Cookie file kept on the user's end system and managed by the user's browser 4. Back-end database at the Web site When somone contacts Amazon.com for the first time, the server creates a unique identification number and creates an entry in its back-end database that is indexed by identification number. The Amazon Web server then responds to your browser, including in the HTTP reponse a Set-cookie: header, which contains the identification number. When your browser receives the HTTP response message, it sees the Set-cookie header, then it appends a line to the special cookie file that it manages. This line includes the hostname of the server and identification number. The cookie file may have entries from other websites. Now whenever you have activity on Amazon.com, although Amazon might not know who you are, they know exactly which pages user 1678 visited, in which order, and at what times. Thus, they can use cookies to provide its shopping cart service and other things, like recommend products. If you register an account with Amazon, then Amazon can include this information in its database, thereby associating a name to a cookie identification number.","title":"User-Server Interaction: Cookies"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#web-caching","text":"A Web cache (or called proxy server) is a network entity that satisfies HTTP requests on behalf of an origin Web server. The Web cache has its own disk storage and keeps copies of recently requested objects in this storage. Suppose a browser requests http://www.someschool.edu/ campus.gif . Here is what happens: 1. Browser establishes TCP connection to Web cache and sends HTTP request for the object to the Web cache 2. Web cache checks to see if it has a copy of the object stored locally. If it does, the Web cache returns the object within an HTTP response message to the client browser 3. If the Web cache does not have the object, it opens a TCP connection to the origin server, www.someschool.edu . The Web cache then sends an HTTP request for the object into the cache-to-server TCP connection. After receiving the request the origin server sends the object within an HTTP response to the Web cache 4. When the Web cache receives the object, it stores a copy in its local storage and sends a copy, within an HTTP response message, to the client browser. It is super similar to caching in 16. Caches . Through use of Content Distribution Networks (CDNs), Web caches are increasingly playing an important role in the Internet. A CDN company installs many geographically distributed caches throughout the Internet, thereby localizing much of the traffic.","title":"Web Caching"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#the-conditional-get","text":"The conditional GET happens if (1) the request message uses the GET method and (2) the request message includes an If-Modified-Since header line. It allows a cache to verify that its objects are up to date. We might then send GET /fruit/kiwi.gif HTTP/1.1 Host: www.exotiquecuisine.com If-modified-since: Wed, 9 Sep 2015 09:23:24 Suppose the object has not been modified since that date, then the Web server sends a response message to the cache: HTTP/1.1 304 Not Modified Date: Sat, 10 Oct 2015 15:39:29 Server: Apache/1.3.0 (Unix) (empty entity body) So the conditional GET makes the Web server send a response message but does not include the requested object in the response message. If it has changed, then the server will send the object.","title":"The Conditional GET"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#http2","text":"Standardized in 2015, HTTP/2 reduced perceived latency by enabling request and response multiplexing over a single TCP connection, provide request prioritization and server push, and provide efficient compression of HTTP header fields It does not change HTTP methods, status codes, URLs, header fields. It simply changes how the data is formatted and transported between client and server. The developers of Web browsers discovered that sending al lthe objects in a Web page over a single TCP connection has a Head of Line (HOL) blocking problem. If a large video clip is at the top of the Web page and bleow it are many small objects below it, the a single TCP connection will have the video clip take a long time to pass through the bottleneck link. HTTP/1.1 browsers typically work around this by opening multiple parallel TCP connections. HTTP/2 wants to get rid of parallel TCP connections, which reduces the number of sockets that need to be open and maintained at servers, but also allows TCP congestion control to operate as intended. TCP congestion controll provides browsers an unintended incentive to use multiple parallel TCP connections rather than a single persistent connection.","title":"HTTP/2"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#http2-framing","text":"The HTTP/2 solution for HOL blocking is to break each message into small frames, and interleave the request and response messages on the same TCP connection. We might break a large video clip into 8 smaller objects, so the server can receive 9 concurrent requests from any browser wanting to see the Web page, and for each request, the server needs to send 9 competing HTTP response messages to the browser. The ability to break down an HTTP message into independent frames, interleave them, and then reassemble them on the other end is the single most important enhancement of HTTP/2","title":"HTTP/2 Framing"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#response-message-prioritization-and-server-pushing","text":"Message prioritization allows developers to customize the relative priority of requests to better optimize applicaiton performance. We might assign a weight between 1 and 256 to each message, where higher number indicates higher priority. Another feature of HTTP/2: ability for server to send multiple responses for a single client request. The server can push additional objects to the client, without the client having to request each one. Instead of waiting for the HTTP requests for these objects, the server cna analyze the HTML page, identify the objects that are needed, and send them to the client before receiving explicit requests for these objects, which eliminates extra latency.","title":"Response Message Prioritization and Server Pushing"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.2%20The%20Web%20and%20HTTP/#http3","text":"QUIC is a new transport protocol implemented in the applicaiton layer over the bare-bones UDP protocol. QUIC has several features desireable for HTTP, such as message multiplexing (interleaving), per-stream flow control, and low-latency connection establishment. HTTP/3 is yet a new HTTP protocol designed to operate over QUIC. As of 202, HTTP/2 is described in Internet drafts and has not yet been fully standardized. Many HTTP/2 features are subsumed by QUIC.","title":"HTTP/3"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.3%20Electronic%20Mail%20in%20the%20Internet/","text":"2.3 Electronic Mail in the Internet \u00b6 This note explains how email works. Email is an asynchronous communication medium. A high level-view contains three major components: User agents Mail servers Simple Mail Transfer Protocol (SMTP) Mail servers form the core of the email infrastructure. Each recipient has a mailbox located in one of the mail servers. A typical journey starts in the sender's user agent, then travels to the sender's mail server, and thentravels to the recipient's mail server, where it is deposited in the recipient's mailbox. If Alice's server cannot deliver to Bob's server, Alice's server holds the message in a message queue and attempts to transfer the message later, usually with reattempts every 30 minutes or so; if no success for a while, the server removes the message and notifies Alice. SMTP \u00b6 The principle application-layer protocol for Internet email. It uses a reliable data transfer service of TCP to transfer ail from the sender's mail server to the recipient's mail server. SMTP has two sides: client (executes on sender's mail server) and server side (executes on recipient's mail server) Suppose Alice wants to send Bob a simple ASCII message 1. Alice invokes her user agent for email, provides Bob's email address, composes a message, and instructs the user agent to send the message 2. Alice's user agent sends the message to her mail server, where it is placed in a message queue 3. Client side of SMTP, running on Alice's mail server, sees the message in the message queue. It opens a TCP conection to an SMTP server, running on Bob's mail server. 4. After SMTP handshking, the SMTP client sends Alice's message into the TCP connection 5. Bob's mail server uses the server side of SMTP and receives the message. Bob's mail server then places the message in Bob's mailbox 6. Bob invokes his user agent to read the message at his convenience. Now let's take a closer look: Client SMTP has TCP establish a connection to port 25 at the server SMTP. If server is down, the client tries again later. When connection is established, server and client perform some application-layer handshaking. They introduce themselves before transferring information from one to another. SMTP clients indicates email address of sender, and the email address of the recipient The client then sends the message. SMTP can count on reliable data transfer service of TCP to get the message to the server without errors. Client repeats this process over the same TCP connection if it has other messages to send to the server; otherwise, it instructs TCP to close the conection. Something like this happens with client (C) and server (S) S: 220 hamburger.edu C: HELO crepes.fr S: 250 Hello crepes.fr, pleased to meet you C: MAIL FROM: <alice@crepes.fr> S: 250 alice@crepes.fr ... Sender ok C: RCPT TO: <bob@hamburger.edu> S: 250 bob@hamburger.edu ... Recipient ok C: DATA S: 354 Enter mail, end with \u201d.\u201d on a line by itself C: Do you like ketchup? C: How about pickles? C: . S: 250 Message accepted for delivery C: QUIT S: 221 hamburger.edu closing connection As part of the dialogue, client issued five commands: HELO (Hello), MAIL FROM , RCPT TO , DATA , and QUIT There is also a single period, which indicates the end of the message to the server. Mail Message Formats \u00b6 There may be peripheral header information like Bob's address, Alice's return address, date, etc. In an real mail. In email, there is also a header containing peripheral information that precedes the body. A typical message headder looks like this: From: alice@crepes.fr To: bob@hamburger.edu Subject: Searching for the meaning of life. After the message header, there is a blank line, then the message body follows Mail Access Protocols \u00b6 There is a small problem with the approach discused. Recall that a mail server manages mailboxes and runs the client and server sides of SMTP. If Bob's mail server were to reside on his local host, then Bob's host would have to remain always on, and connected to the Internet to receive new mail, which arrives at any time. This is highly impractical. Instead a typical user runs a user agent on the local host but accesses its mailbox stored on an always-on shared mail server. This mail server is shared with other users. There are two common ways today for Bob to retrieve email from a mail server Using a Web-based email or smartphone app (like Gmail), user agent will use HTTP to retrieve Bob's email Internet Mail Access Protocol IMAP) is used with mail clients such as Microsoft Outlook.","title":"2.3 Electronic Mail in the Internet"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.3%20Electronic%20Mail%20in%20the%20Internet/#23-electronic-mail-in-the-internet","text":"This note explains how email works. Email is an asynchronous communication medium. A high level-view contains three major components: User agents Mail servers Simple Mail Transfer Protocol (SMTP) Mail servers form the core of the email infrastructure. Each recipient has a mailbox located in one of the mail servers. A typical journey starts in the sender's user agent, then travels to the sender's mail server, and thentravels to the recipient's mail server, where it is deposited in the recipient's mailbox. If Alice's server cannot deliver to Bob's server, Alice's server holds the message in a message queue and attempts to transfer the message later, usually with reattempts every 30 minutes or so; if no success for a while, the server removes the message and notifies Alice.","title":"2.3 Electronic Mail in the Internet"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.3%20Electronic%20Mail%20in%20the%20Internet/#smtp","text":"The principle application-layer protocol for Internet email. It uses a reliable data transfer service of TCP to transfer ail from the sender's mail server to the recipient's mail server. SMTP has two sides: client (executes on sender's mail server) and server side (executes on recipient's mail server) Suppose Alice wants to send Bob a simple ASCII message 1. Alice invokes her user agent for email, provides Bob's email address, composes a message, and instructs the user agent to send the message 2. Alice's user agent sends the message to her mail server, where it is placed in a message queue 3. Client side of SMTP, running on Alice's mail server, sees the message in the message queue. It opens a TCP conection to an SMTP server, running on Bob's mail server. 4. After SMTP handshking, the SMTP client sends Alice's message into the TCP connection 5. Bob's mail server uses the server side of SMTP and receives the message. Bob's mail server then places the message in Bob's mailbox 6. Bob invokes his user agent to read the message at his convenience. Now let's take a closer look: Client SMTP has TCP establish a connection to port 25 at the server SMTP. If server is down, the client tries again later. When connection is established, server and client perform some application-layer handshaking. They introduce themselves before transferring information from one to another. SMTP clients indicates email address of sender, and the email address of the recipient The client then sends the message. SMTP can count on reliable data transfer service of TCP to get the message to the server without errors. Client repeats this process over the same TCP connection if it has other messages to send to the server; otherwise, it instructs TCP to close the conection. Something like this happens with client (C) and server (S) S: 220 hamburger.edu C: HELO crepes.fr S: 250 Hello crepes.fr, pleased to meet you C: MAIL FROM: <alice@crepes.fr> S: 250 alice@crepes.fr ... Sender ok C: RCPT TO: <bob@hamburger.edu> S: 250 bob@hamburger.edu ... Recipient ok C: DATA S: 354 Enter mail, end with \u201d.\u201d on a line by itself C: Do you like ketchup? C: How about pickles? C: . S: 250 Message accepted for delivery C: QUIT S: 221 hamburger.edu closing connection As part of the dialogue, client issued five commands: HELO (Hello), MAIL FROM , RCPT TO , DATA , and QUIT There is also a single period, which indicates the end of the message to the server.","title":"SMTP"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.3%20Electronic%20Mail%20in%20the%20Internet/#mail-message-formats","text":"There may be peripheral header information like Bob's address, Alice's return address, date, etc. In an real mail. In email, there is also a header containing peripheral information that precedes the body. A typical message headder looks like this: From: alice@crepes.fr To: bob@hamburger.edu Subject: Searching for the meaning of life. After the message header, there is a blank line, then the message body follows","title":"Mail Message Formats"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.3%20Electronic%20Mail%20in%20the%20Internet/#mail-access-protocols","text":"There is a small problem with the approach discused. Recall that a mail server manages mailboxes and runs the client and server sides of SMTP. If Bob's mail server were to reside on his local host, then Bob's host would have to remain always on, and connected to the Internet to receive new mail, which arrives at any time. This is highly impractical. Instead a typical user runs a user agent on the local host but accesses its mailbox stored on an always-on shared mail server. This mail server is shared with other users. There are two common ways today for Bob to retrieve email from a mail server Using a Web-based email or smartphone app (like Gmail), user agent will use HTTP to retrieve Bob's email Internet Mail Access Protocol IMAP) is used with mail clients such as Microsoft Outlook.","title":"Mail Access Protocols"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.4%20DNS%20-%20The%20Internet%27s%20Directory%20Service/","text":"2.4 DNS - The Internet's Directory Service \u00b6 This note describes DNS: what services it provides, how it works, and how messages are structured. Internet hosts can be identified by its hostname. However, since hostnames are variable-length characters, a router would have a hard time identifying them. For this reason, hosts are also identified by IP addresses. An IP address consists of four bytes and has a rigid hierarchical structure. I might look like 121.7.106.83 , where each period separates one of the bytes expressed in decimal notation from \\(0\\) to \\(255\\) . We scan the address from left to right and as we go along, we get more specific information about where the host is located in the Internet. Services Provided by DNS \u00b6 The main task of the Internet's Domain name System (DNS) is to translate hostnames to IP addresses. The DNS is 1. A distributed database implemented in a hierarchy of DNS servers 2. An application-layer protocol that allows hosts to query the distributed database. DNS is commonly employed by other AL protocols, like HTTP and SMTP, to translate user-supplied hostnames to IP addresses. WHen a browser (HTTP client) requests a URL like www.someschool.edu/index.html, it will do the following: 1. The user machine runs the client side of the DNS application 2. The browser extracts the hostname, www.someschool.edu, from the URL and passes the hostname to the client side of the DNS application 3. The DNS client sends a query containing the hostname to a DNS server 4. The DNS client eventually receives a reply, which includes the IP address for the hostname 5. Once the browser receives the IP address from DNS, it can initiate a TCP connection to the HTTP server process located at port 80 at that IP address DNS provides a few other important services in addition to translating hostnames to IP addresses: 1. Host aliasing. For example, a hostname such as relay1.west-coast.enterprise.com could have two aliases such as enterprise.com and www.enterprise.com. The relay1.west-coast.enterprise.com is said to be a canonical hostname. 2. Mail server aliasing, just like host aliasing for mail 3. Load distribution: busy sites, like cnn.com are replicated over multiple servers, with each server running on a different end system and each having a different IP address. For replicated Web servers, a set of IP addresses is thus associated with one alias hostname. The DNS database contains this set of IP addresses. Overview of How DNS Works \u00b6 A simple design for DNS would have one DNS server that contains all the mappings. In the centralized design, clients simply direct all queries to the single DNS server, and the DNS server responds directly to the querying clients. Challenges of this approach include A single point of failure: if DNS server crashes, the entire Internet does too Traffic volume: There are millions and billions of requests from HTTP and email Distant centralized database: it cannot be \"close to\" all the querying clients Maintenance: would have to keep records for all Internet hosts To fix this, we want to organize it in a hierarchical fashion. There are three classes of DNS servers 1. Root DNS servers: copies of 13 different root servers, managed by 12 different organizations, and coordinated through the Internet Assigned Numbers Authority. Provides the IP addresses of the TLD servers 2. Top-level domain (TLD) DNS servers: top-level domains such as com, org, net, edu, gov, and country top-level domains like uk, fr, ca, jp. There is a TLD server for each of them. 3. Authoriatative DNS servers: Every organization with publicly accessible hosts on the Internet must provide publicly accessible DNS records that map the names of those hosts to IP addresses. Another important type of DNS server is the local DNS server. It does not strictly belong to the hierarchy, but are central to DNS architecture. Each ISP has a local DNS server. When a host connects to an ISP, the ISP provides the host with IP addresses of one or more of its local DNS servers. Basically, it acts as a proxy, forwarding the query into the hierarchy. This image makes the use of both recursive queries and iterative queries. The query sent from cse.nyu.edu to dns.nyu.edu is recursive since the query asks dns.nyu.edu to obtain the mapping on its behalf. However, the subsequent three queries are iterative since all the replies are directly returned to dns.nyu.edu . DNS Caching \u00b6 DNS caching can be exploited to improve the delay performance and to reduce the number of DNS messages ricocheting around the Internet. The idea is like any cache. In a query chain, when a DNS server receives a DNS reply, it can cache the mapping in its local memory. DNS Records and Messages \u00b6 DNS servers that together implement the DNS distributed database store resource records (RRs), including RRs that provide hostname-to-IP address mappings. Each DNS reply message carries one or more RRs. An RR is a four-tuple that contains the following fields: (Name, Value, Type, TTL) TTL is the time to live of the resource record; it determines when a resource should be removed from a cache. Name and Value depend on Type : If Type=A , then Name is a hostname, and Value is the IP address for the hostname If Type=NS , then Name is a domain, and Value is the hostname of an authoritative DNS server taht knows how to obtain the IP address for hosts in the domain. If Type=CNAME , then Value is a canonical hostname for the alias hostname Name . If Type=MX , then Value is the canonical name of a mail server that has an alias hostname Name . DNS Messages \u00b6 The semantics of the various fields in a DNS message are as follows: First 12 bytes is the header section, which has a number of fields. 16-bit number that identifies the query, copied into the reply message to a query, allowing the client to match received replies with sent queries 1-bit query/reply flag indicating whether the message is a query (0) or reply (1). 1-bit authoritative flag is set in a reply message when a DNS server is an authoritative server for a queries name A 1-bit recursion-desired flag is set when a client desires that the DNS server perform recursion when it doesn't have the record. A 1-bit recursion-available field is set in a reply if the DNS server supports recursion 4 number-of fields, which indicate the number of occurrences of the four types of data sections that follow the header Then there is a question section that contains info about the query that is being made A name field that contains the name that is being queried A type field indicates type of question being asked about the name Type . The answer section contains the resource records for the name that was originally queried. Type , Value , TTL Authority section: contains the records of other authoritative servers Additional section contains other helpful records. We can send a DNS query message directly from the host you're working on to some DNS server with the nslookup program (root, TLD, authoritative) Inserting Records into the DNS Database \u00b6 Registrar: a commercial entry that verifies the uniqueness of the domain name. Let's try to get a .com website. You first register the domain name to a registrar, and collects a small fee from you for its services. You also need to provide the registrar with the names and IP addresses of your primary and secondary authoritative DNS servers. For these two servers, the registrar would then make sure that Type=NS and Type=A record are entered into the TLD com servers. You also have to make sure that the Type A RR for your Web server and the Type MX RR for your mail server are entered into your authoritative DNS servers. Once all of these steps are completed, people will be able to visit your Web site and send emails to the employees at your company. Next section 2.5 Peer-to-Peer File Distribution","title":"2.4 DNS - The Internet's Directory Service"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.4%20DNS%20-%20The%20Internet%27s%20Directory%20Service/#24-dns-the-internets-directory-service","text":"This note describes DNS: what services it provides, how it works, and how messages are structured. Internet hosts can be identified by its hostname. However, since hostnames are variable-length characters, a router would have a hard time identifying them. For this reason, hosts are also identified by IP addresses. An IP address consists of four bytes and has a rigid hierarchical structure. I might look like 121.7.106.83 , where each period separates one of the bytes expressed in decimal notation from \\(0\\) to \\(255\\) . We scan the address from left to right and as we go along, we get more specific information about where the host is located in the Internet.","title":"2.4 DNS - The Internet's Directory Service"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.4%20DNS%20-%20The%20Internet%27s%20Directory%20Service/#services-provided-by-dns","text":"The main task of the Internet's Domain name System (DNS) is to translate hostnames to IP addresses. The DNS is 1. A distributed database implemented in a hierarchy of DNS servers 2. An application-layer protocol that allows hosts to query the distributed database. DNS is commonly employed by other AL protocols, like HTTP and SMTP, to translate user-supplied hostnames to IP addresses. WHen a browser (HTTP client) requests a URL like www.someschool.edu/index.html, it will do the following: 1. The user machine runs the client side of the DNS application 2. The browser extracts the hostname, www.someschool.edu, from the URL and passes the hostname to the client side of the DNS application 3. The DNS client sends a query containing the hostname to a DNS server 4. The DNS client eventually receives a reply, which includes the IP address for the hostname 5. Once the browser receives the IP address from DNS, it can initiate a TCP connection to the HTTP server process located at port 80 at that IP address DNS provides a few other important services in addition to translating hostnames to IP addresses: 1. Host aliasing. For example, a hostname such as relay1.west-coast.enterprise.com could have two aliases such as enterprise.com and www.enterprise.com. The relay1.west-coast.enterprise.com is said to be a canonical hostname. 2. Mail server aliasing, just like host aliasing for mail 3. Load distribution: busy sites, like cnn.com are replicated over multiple servers, with each server running on a different end system and each having a different IP address. For replicated Web servers, a set of IP addresses is thus associated with one alias hostname. The DNS database contains this set of IP addresses.","title":"Services Provided by DNS"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.4%20DNS%20-%20The%20Internet%27s%20Directory%20Service/#overview-of-how-dns-works","text":"A simple design for DNS would have one DNS server that contains all the mappings. In the centralized design, clients simply direct all queries to the single DNS server, and the DNS server responds directly to the querying clients. Challenges of this approach include A single point of failure: if DNS server crashes, the entire Internet does too Traffic volume: There are millions and billions of requests from HTTP and email Distant centralized database: it cannot be \"close to\" all the querying clients Maintenance: would have to keep records for all Internet hosts To fix this, we want to organize it in a hierarchical fashion. There are three classes of DNS servers 1. Root DNS servers: copies of 13 different root servers, managed by 12 different organizations, and coordinated through the Internet Assigned Numbers Authority. Provides the IP addresses of the TLD servers 2. Top-level domain (TLD) DNS servers: top-level domains such as com, org, net, edu, gov, and country top-level domains like uk, fr, ca, jp. There is a TLD server for each of them. 3. Authoriatative DNS servers: Every organization with publicly accessible hosts on the Internet must provide publicly accessible DNS records that map the names of those hosts to IP addresses. Another important type of DNS server is the local DNS server. It does not strictly belong to the hierarchy, but are central to DNS architecture. Each ISP has a local DNS server. When a host connects to an ISP, the ISP provides the host with IP addresses of one or more of its local DNS servers. Basically, it acts as a proxy, forwarding the query into the hierarchy. This image makes the use of both recursive queries and iterative queries. The query sent from cse.nyu.edu to dns.nyu.edu is recursive since the query asks dns.nyu.edu to obtain the mapping on its behalf. However, the subsequent three queries are iterative since all the replies are directly returned to dns.nyu.edu .","title":"Overview of How DNS Works"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.4%20DNS%20-%20The%20Internet%27s%20Directory%20Service/#dns-caching","text":"DNS caching can be exploited to improve the delay performance and to reduce the number of DNS messages ricocheting around the Internet. The idea is like any cache. In a query chain, when a DNS server receives a DNS reply, it can cache the mapping in its local memory.","title":"DNS Caching"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.4%20DNS%20-%20The%20Internet%27s%20Directory%20Service/#dns-records-and-messages","text":"DNS servers that together implement the DNS distributed database store resource records (RRs), including RRs that provide hostname-to-IP address mappings. Each DNS reply message carries one or more RRs. An RR is a four-tuple that contains the following fields: (Name, Value, Type, TTL) TTL is the time to live of the resource record; it determines when a resource should be removed from a cache. Name and Value depend on Type : If Type=A , then Name is a hostname, and Value is the IP address for the hostname If Type=NS , then Name is a domain, and Value is the hostname of an authoritative DNS server taht knows how to obtain the IP address for hosts in the domain. If Type=CNAME , then Value is a canonical hostname for the alias hostname Name . If Type=MX , then Value is the canonical name of a mail server that has an alias hostname Name .","title":"DNS Records and Messages"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.4%20DNS%20-%20The%20Internet%27s%20Directory%20Service/#dns-messages","text":"The semantics of the various fields in a DNS message are as follows: First 12 bytes is the header section, which has a number of fields. 16-bit number that identifies the query, copied into the reply message to a query, allowing the client to match received replies with sent queries 1-bit query/reply flag indicating whether the message is a query (0) or reply (1). 1-bit authoritative flag is set in a reply message when a DNS server is an authoritative server for a queries name A 1-bit recursion-desired flag is set when a client desires that the DNS server perform recursion when it doesn't have the record. A 1-bit recursion-available field is set in a reply if the DNS server supports recursion 4 number-of fields, which indicate the number of occurrences of the four types of data sections that follow the header Then there is a question section that contains info about the query that is being made A name field that contains the name that is being queried A type field indicates type of question being asked about the name Type . The answer section contains the resource records for the name that was originally queried. Type , Value , TTL Authority section: contains the records of other authoritative servers Additional section contains other helpful records. We can send a DNS query message directly from the host you're working on to some DNS server with the nslookup program (root, TLD, authoritative)","title":"DNS Messages"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.4%20DNS%20-%20The%20Internet%27s%20Directory%20Service/#inserting-records-into-the-dns-database","text":"Registrar: a commercial entry that verifies the uniqueness of the domain name. Let's try to get a .com website. You first register the domain name to a registrar, and collects a small fee from you for its services. You also need to provide the registrar with the names and IP addresses of your primary and secondary authoritative DNS servers. For these two servers, the registrar would then make sure that Type=NS and Type=A record are entered into the TLD com servers. You also have to make sure that the Type A RR for your Web server and the Type MX RR for your mail server are entered into your authoritative DNS servers. Once all of these steps are completed, people will be able to visit your Web site and send emails to the employees at your company. Next section 2.5 Peer-to-Peer File Distribution","title":"Inserting Records into the DNS Database"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.5%20Peer-to-Peer%20File%20Distribution/","text":"2.5 Peer-to-Peer File Distribution \u00b6 This note explains P2P file distribution and how it works, as well as the scalability of P2P architectures. Recall that P2P architecture, there is minimal (or no) reliance on always-on infrastructure servers. Instead, pairs of intermittently connected hosts, called peers, communicate directly with each other. The peers are not owned by a service provider, but are instead PCs, laptops, and smartphones controlled by users. Let's consider a very natural P2P application, distributing a large file from a single server to a large number of peers. It might be a Linux OS. In client-server file distribution, server must send a copy of the file to each of the peers. The most popular P2P file distribution protocol is BitTorrent. Scalability of P2P Architectures \u00b6 Consider a simple quantitative model for distributing a file to a fixed set of peers for both architecture types. The server and the peers are connected to the Internet with access links. Let's denote the upload rate of the server's access link by \\(u_s\\) , the upload rate of the \\(i\\) th peer's access link by \\(u_i\\) , and the download rate of the \\(i\\) th peer's access link by \\(d_i\\) . Denote the file size to be distributed by \\(F\\) and the number of peers that want to obtain a copy of the file by \\(N\\) . Distribution time is the time it takes to get a copy of the file to all \\(N\\) peers. Let's assume the Internet core has abundant bandwidth, implying that all the bottlenecks will be in access networks. Also assume the server and clients are not doing any other network applications, so all is devoted to distributing the file. The distribution time for client-server architecture, denoted by \\(D_{cs}\\) . Client-server architecture, none of the peers aids in distributing the file. We observe: 1. Server must transmit one copy of the file to each of the \\(N\\) peers. Thus, the server must transmit \\(NF\\) bits. Since the server's upload rate is \\(u_s\\) , the time to distribute the file must be at least \\(NF/u_s\\) . 2. Let \\(d_{min}\\) denote the download rate of the peer with the lowest download rate. The peer with the lowest download rate cannot obtain all \\(F\\) bits of the file in less than \\(F/d_{min}\\) seconds. Thus the minimum distribution time is at least \\(F/d_{min}\\) . So, we obtain \\[ D_{cs} \\geq max\\left\\{\\frac{NF}{u_s}, \\frac{F}{d_{min}}\\right\\} \\] This is the lower bound. Let's just take this lower bound provided above as the actual distribution time, so we have equality in the equation above. For \\(N\\) large enough, the client-server distribution time is given by \\(NF/u_s\\) . So the distribution time increases linearly with the number of peers \\(N\\) . Let's do a similar analysis for P2P architecture, where each peer assists the server in distributing the file. We observe: 1. Only the server has the file at the beginning of the distribution. To get this file into the community of peers, the server must send each bit of the file at least once into its access link. Thus the minimum distribution time is at least \\(F/u_s\\) . 2. The peer with the lowest download rate cannot obtain all \\(F\\) bits of the file in less than \\(F/d_{min}\\) seconds. The minimum distribution time is at least \\(F/d_{min}\\) . 3. The total upload capacity of the system as a whole is equal to the upload rate of the server plus the upload rates of each individual peer, that is, \\(u_{total} = u_s + u_1 +\\cdots + u_N\\) . The system must deliver \\(F\\) bits to each \\(N\\) peers, thus delivering \\(NF\\) bits. The minimum distribution time is also at least \\(NF/(\\text{sum of u's})\\) . We obtain the minimum distribution time for P2P, denoted by \\(D_{P2P}\\) . \\[ D_{P2P} \\geq max\\left\\{\\frac{F}{u_s}, \\frac{F}{d_{min}}, \\frac{NF}{u_s + \\sum_{i = 1}^{N} u_i}\\right\\} \\] This is a lower bound, but lets say that the actual minimum distribution time is with the equality. Let's compare the distribution time for client-server architectures and P2P architecture: BitTorrent \u00b6 BitTorrent is a popular P2P protocol for file distribution. The collection of all peers participating in the distribution of a particular file is called a torrent. Peers in a torrent download equal-size chunks of the file from one another, with typeical chunk size of 256 KiB. When a peer first joins a torrent, it has no chunks, and over time, it accumulates more and more chunks. While it downloads chunks it also uploads chunks to other peers. When a peer acquires the entire file, it may selfishly leave the torrent, or altruistically remain in the torrent and continue to upload chunks to other peers.","title":"2.5 Peer-to-Peer File Distribution"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.5%20Peer-to-Peer%20File%20Distribution/#25-peer-to-peer-file-distribution","text":"This note explains P2P file distribution and how it works, as well as the scalability of P2P architectures. Recall that P2P architecture, there is minimal (or no) reliance on always-on infrastructure servers. Instead, pairs of intermittently connected hosts, called peers, communicate directly with each other. The peers are not owned by a service provider, but are instead PCs, laptops, and smartphones controlled by users. Let's consider a very natural P2P application, distributing a large file from a single server to a large number of peers. It might be a Linux OS. In client-server file distribution, server must send a copy of the file to each of the peers. The most popular P2P file distribution protocol is BitTorrent.","title":"2.5 Peer-to-Peer File Distribution"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.5%20Peer-to-Peer%20File%20Distribution/#scalability-of-p2p-architectures","text":"Consider a simple quantitative model for distributing a file to a fixed set of peers for both architecture types. The server and the peers are connected to the Internet with access links. Let's denote the upload rate of the server's access link by \\(u_s\\) , the upload rate of the \\(i\\) th peer's access link by \\(u_i\\) , and the download rate of the \\(i\\) th peer's access link by \\(d_i\\) . Denote the file size to be distributed by \\(F\\) and the number of peers that want to obtain a copy of the file by \\(N\\) . Distribution time is the time it takes to get a copy of the file to all \\(N\\) peers. Let's assume the Internet core has abundant bandwidth, implying that all the bottlenecks will be in access networks. Also assume the server and clients are not doing any other network applications, so all is devoted to distributing the file. The distribution time for client-server architecture, denoted by \\(D_{cs}\\) . Client-server architecture, none of the peers aids in distributing the file. We observe: 1. Server must transmit one copy of the file to each of the \\(N\\) peers. Thus, the server must transmit \\(NF\\) bits. Since the server's upload rate is \\(u_s\\) , the time to distribute the file must be at least \\(NF/u_s\\) . 2. Let \\(d_{min}\\) denote the download rate of the peer with the lowest download rate. The peer with the lowest download rate cannot obtain all \\(F\\) bits of the file in less than \\(F/d_{min}\\) seconds. Thus the minimum distribution time is at least \\(F/d_{min}\\) . So, we obtain \\[ D_{cs} \\geq max\\left\\{\\frac{NF}{u_s}, \\frac{F}{d_{min}}\\right\\} \\] This is the lower bound. Let's just take this lower bound provided above as the actual distribution time, so we have equality in the equation above. For \\(N\\) large enough, the client-server distribution time is given by \\(NF/u_s\\) . So the distribution time increases linearly with the number of peers \\(N\\) . Let's do a similar analysis for P2P architecture, where each peer assists the server in distributing the file. We observe: 1. Only the server has the file at the beginning of the distribution. To get this file into the community of peers, the server must send each bit of the file at least once into its access link. Thus the minimum distribution time is at least \\(F/u_s\\) . 2. The peer with the lowest download rate cannot obtain all \\(F\\) bits of the file in less than \\(F/d_{min}\\) seconds. The minimum distribution time is at least \\(F/d_{min}\\) . 3. The total upload capacity of the system as a whole is equal to the upload rate of the server plus the upload rates of each individual peer, that is, \\(u_{total} = u_s + u_1 +\\cdots + u_N\\) . The system must deliver \\(F\\) bits to each \\(N\\) peers, thus delivering \\(NF\\) bits. The minimum distribution time is also at least \\(NF/(\\text{sum of u's})\\) . We obtain the minimum distribution time for P2P, denoted by \\(D_{P2P}\\) . \\[ D_{P2P} \\geq max\\left\\{\\frac{F}{u_s}, \\frac{F}{d_{min}}, \\frac{NF}{u_s + \\sum_{i = 1}^{N} u_i}\\right\\} \\] This is a lower bound, but lets say that the actual minimum distribution time is with the equality. Let's compare the distribution time for client-server architectures and P2P architecture:","title":"Scalability of P2P Architectures"},{"location":"EECS/CS%20168/2.%20Application%20Layer/2.5%20Peer-to-Peer%20File%20Distribution/#bittorrent","text":"BitTorrent is a popular P2P protocol for file distribution. The collection of all peers participating in the distribution of a particular file is called a torrent. Peers in a torrent download equal-size chunks of the file from one another, with typeical chunk size of 256 KiB. When a peer first joins a torrent, it has no chunks, and over time, it accumulates more and more chunks. While it downloads chunks it also uploads chunks to other peers. When a peer acquires the entire file, it may selfishly leave the torrent, or altruistically remain in the torrent and continue to upload chunks to other peers.","title":"BitTorrent"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/","text":"2. How the Internet Works - A Bottom-Up View \u00b6 This note answers a couple of questions: How is data transferred across the Internet? How are network resources shared? What is the life of a packet through the network. Review \u00b6 The goal of the Inernet is to transfer data between end hosts Data Organization: Packets \u00b6 It will construct a packet: a unit of data that gets transported across the Internet. A switch will read a header, which is metadata that describes how data is to be delivered. Header is meaningful to the network and endpoint. What information must a header contain? Destination address. Payload: the information in the packet. Meaningful info only to the endpoints, like bits from a file, video, etc. In practice, a packet has multiple headers (next lecture) [[3. ]] And communication between a pair of endhosts involved multiple packets Flow: stream of packets exchanged between two endpoints Properties of Links \u00b6 Bandwidth: number of bits sent (or received) per unit time (bits/second, bps) \"Width\" of the link Propagation delay: time it takes a bit to travel along the link (seconds) \"Length\" of the link Bandwidth-Delay Product (BDP): bits/time * propagation delay (bits) \"Capacity\" of the link Packets on a Link \u00b6 For now, let's say the packet is something where the size of the packet is 100B. The link is 1Mbps, with propagation delay 1ms. 1Mbps = one bit takes \\(1/10^6\\) s. Time when that one bit reaches Point B = \\(1/10^6 + 1/10^3\\) s. The time to transmit 800 bits = \\(800 * 1/10^6\\) s. The last bit reaches B at \\((800 * 1/10^6) + 1/10^3\\) s \\(= 1.8\\) ms In general \\[ \\text{Packet delay = Transmission Delay + Propagation Delay} \\] where Transmission Delay can be better represented as \\[ \\text{Packet delay = (Packet Size / Link Bandwidth) + Propagation Delay} \\] So, which link is better? Link1: bandwidth = 10Mbps and propagation delay = 10ms Link2: bandwidth = 1 Mbps and propagation delay = 1ms Note that the answer is that it depends. With a 10B packet: \\(L_1 \\approx 10ms, L_2 \\approx 1ms\\) With a 10000B packet: \\(L_1 \\approx 18ms, L_2 \\approx 81ms\\) Alternate Pipe View of Packets on a Link \u00b6 You see the right image tells you how much capacity you have (how busy it is). Packet at the Switch \u00b6 The switch now has to figure out where to go. In other words, which link to forward it to. Every switch has a forwarding table, which says which link the packet should follow Recap: Life of a Packet So Far \u00b6 Source has some data to send to a destination Chunks it up into packets: each packet has a payload and a header Packet travels along a link Arrives at a switch; switch forwards the packet to its next hop Repeat 3-4 until we reach destination Challenges \u00b6 How to scale the forwarding table? Two ports to the same destination What happens when a link goes down? Where does the table come from? How do you know it actually gets there Where did the address come from? Challenge: Addressing and Naming \u00b6 Network address: where host is located Network name: which host it is Need an addressing and naming scheme that works at Internet scale! --> IP addresses Consider when you access a web page Insert URL into browser You want to communicate with the server hosting that URL How do you get to the server? URL is the user-level name (e.g. cnn.com) Network needs address (where is cnn.com) Must map (or resolve) host names to addresses. This is done by the Domain Name System (DNS). Challenge: Routing \u00b6 WHen a packet arrives at a router, the forwarding table determines which outgoing link the packet is sent on How do you compute the forwarding tables necessary to deliver packets? Conceptually, routing involves Distributed routing algorithm run between switches/routers Gather information about the network topology Compute paths through that topology Store forwarding information in each router This is the forwarding table Control Plane vs. Data Plane \u00b6 Control plane: mechanisms used to compute forwarding tables Inherently global: must know topology to compute Routing algorithm is part of the control plane Time scale: per network event Data plane: using those tables to actually forward packets Inherently local: depends only on arriving packet and local routing table Forwarding mechanism is part of data plane Time scale: per packet arrival Control Plane Challenge \u00b6 Computing routes at scale In the face of network failures and topology changes While respecting ISPs need for autonomy. Internet is comprised of many different ISPs, and they each get to make their own decisions about how to do routing within their networks. Typically do not want to reveal the internals of this decision making. Can we ensure that ISPs independent decisions result in usable end-to-end routes? --> BGP Data Plane Challenge \u00b6 Consider a 1 Tbps link receiving 10k bit packets. A new packet arrives every 10 nanoseconds. The following operations must be done after packet arrives (in 10 ns or less) Parse packet (extract address, etc.) Look up address in forwarding table Update other fields in packet header (if needed) Update relevant internal counters, etc. Send packet to appropriate output link Important Topics \u00b6 How do we name endhosts on the Internet? (naming) How do we address endhosts? (addressing) How do we map names to addresses? (DNS) How do we compute forwarding tables? (Routing Control Plane --> Project 1) How do we forward packets? (Routing Data Plane) Fundamental Fact About Networks \u00b6 Network must support many simultaneous flows at the same time. Recall that flow = stream of packets sent between two end hosts. This means network resources (links and switches) are shared between end hosts. Network resources (like bandwidth) are statistically multiplexed. Statistical Multiplexing \u00b6 Combining demands to share resources efficiently (vs. statically partitioning resources). Long history in CS Process on an OS (vs. every process has own core) Cloud computing (vs. everyone has own datacenter) Based on premise: peak of aggregate demand is << aggregate of peak demands Aggregates, Peaks, Etc. \u00b6 Define the peak rate of flow \\(f\\) to be \\(P(f)\\) . The peak rate of a set of flows \\(f_1, f_2\\) : \\(P(f_1 + f_2)\\) . The aggregate of the peaks: \\[ \\sum_{\\{f\\}} [P(f)] \\] Peak of aggregate \\[ P(\\sum_{\\{f\\}} f) \\] Typically \\[ \\sum_{\\{f\\}} [P(f)] >> P(\\sum_{\\{f\\}} f) \\] Typically \\[ P(\\sum_{\\{f\\}}f) \\approx A(\\sum_{\\{f\\}}f) \\] where \\(A(f)\\) is the average rate of flow \\(f\\) ; \\(A(f_1 + f_2)\\) is the average rate of set of flows \\(f_1, f_2\\) . Statistical multiplexing merely means that you don't provision for absolute worst case (When every peaks at the same time). Instead, you share resources and hope that peak rates don't occur at same time. How Would You Share Network Resources? \u00b6 Two approaches to sharing: 1. Reservations: end-hosts explicitly reserve bandwidth when needed (e.g. at the start of a flow). Best-effort: just send data packets when you have them and hope for the best Implementation \u00b6 Reservation: 1. Source sends a reservation request to the destination 2. Switches \"establish a circuit\" 3. Source starts sending data 4. Source sends a \"teardown circuit\" message Idea reserve network capacity for all packets in a flow Best-Effort Idea: allocate resources to each packet independently (independent across switches and across packets) Both approaches embody statistical multiplexing Circuit switching: resources shared between flows currently in system. Reserve the peak demand for a flow, but don't reserve for all flows that might ever exist. Packet switching: resources shared between packets currently in system. Resources given out on packet-by-packet basis, and never reserve resources.","title":"2. How the Internet Works - A Bottom-Up View"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#2-how-the-internet-works-a-bottom-up-view","text":"This note answers a couple of questions: How is data transferred across the Internet? How are network resources shared? What is the life of a packet through the network.","title":"2. How the Internet Works - A Bottom-Up View"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#review","text":"The goal of the Inernet is to transfer data between end hosts","title":"Review"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#data-organization-packets","text":"It will construct a packet: a unit of data that gets transported across the Internet. A switch will read a header, which is metadata that describes how data is to be delivered. Header is meaningful to the network and endpoint. What information must a header contain? Destination address. Payload: the information in the packet. Meaningful info only to the endpoints, like bits from a file, video, etc. In practice, a packet has multiple headers (next lecture) [[3. ]] And communication between a pair of endhosts involved multiple packets Flow: stream of packets exchanged between two endpoints","title":"Data Organization: Packets"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#properties-of-links","text":"Bandwidth: number of bits sent (or received) per unit time (bits/second, bps) \"Width\" of the link Propagation delay: time it takes a bit to travel along the link (seconds) \"Length\" of the link Bandwidth-Delay Product (BDP): bits/time * propagation delay (bits) \"Capacity\" of the link","title":"Properties of Links"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#packets-on-a-link","text":"For now, let's say the packet is something where the size of the packet is 100B. The link is 1Mbps, with propagation delay 1ms. 1Mbps = one bit takes \\(1/10^6\\) s. Time when that one bit reaches Point B = \\(1/10^6 + 1/10^3\\) s. The time to transmit 800 bits = \\(800 * 1/10^6\\) s. The last bit reaches B at \\((800 * 1/10^6) + 1/10^3\\) s \\(= 1.8\\) ms In general \\[ \\text{Packet delay = Transmission Delay + Propagation Delay} \\] where Transmission Delay can be better represented as \\[ \\text{Packet delay = (Packet Size / Link Bandwidth) + Propagation Delay} \\] So, which link is better? Link1: bandwidth = 10Mbps and propagation delay = 10ms Link2: bandwidth = 1 Mbps and propagation delay = 1ms Note that the answer is that it depends. With a 10B packet: \\(L_1 \\approx 10ms, L_2 \\approx 1ms\\) With a 10000B packet: \\(L_1 \\approx 18ms, L_2 \\approx 81ms\\)","title":"Packets on a Link"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#alternate-pipe-view-of-packets-on-a-link","text":"You see the right image tells you how much capacity you have (how busy it is).","title":"Alternate Pipe View of Packets on a Link"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#packet-at-the-switch","text":"The switch now has to figure out where to go. In other words, which link to forward it to. Every switch has a forwarding table, which says which link the packet should follow","title":"Packet at the Switch"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#recap-life-of-a-packet-so-far","text":"Source has some data to send to a destination Chunks it up into packets: each packet has a payload and a header Packet travels along a link Arrives at a switch; switch forwards the packet to its next hop Repeat 3-4 until we reach destination","title":"Recap: Life of a Packet So Far"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#challenges","text":"How to scale the forwarding table? Two ports to the same destination What happens when a link goes down? Where does the table come from? How do you know it actually gets there Where did the address come from?","title":"Challenges"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#challenge-addressing-and-naming","text":"Network address: where host is located Network name: which host it is Need an addressing and naming scheme that works at Internet scale! --> IP addresses Consider when you access a web page Insert URL into browser You want to communicate with the server hosting that URL How do you get to the server? URL is the user-level name (e.g. cnn.com) Network needs address (where is cnn.com) Must map (or resolve) host names to addresses. This is done by the Domain Name System (DNS).","title":"Challenge: Addressing and Naming"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#challenge-routing","text":"WHen a packet arrives at a router, the forwarding table determines which outgoing link the packet is sent on How do you compute the forwarding tables necessary to deliver packets? Conceptually, routing involves Distributed routing algorithm run between switches/routers Gather information about the network topology Compute paths through that topology Store forwarding information in each router This is the forwarding table","title":"Challenge: Routing"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#control-plane-vs-data-plane","text":"Control plane: mechanisms used to compute forwarding tables Inherently global: must know topology to compute Routing algorithm is part of the control plane Time scale: per network event Data plane: using those tables to actually forward packets Inherently local: depends only on arriving packet and local routing table Forwarding mechanism is part of data plane Time scale: per packet arrival","title":"Control Plane vs. Data Plane"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#control-plane-challenge","text":"Computing routes at scale In the face of network failures and topology changes While respecting ISPs need for autonomy. Internet is comprised of many different ISPs, and they each get to make their own decisions about how to do routing within their networks. Typically do not want to reveal the internals of this decision making. Can we ensure that ISPs independent decisions result in usable end-to-end routes? --> BGP","title":"Control Plane Challenge"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#data-plane-challenge","text":"Consider a 1 Tbps link receiving 10k bit packets. A new packet arrives every 10 nanoseconds. The following operations must be done after packet arrives (in 10 ns or less) Parse packet (extract address, etc.) Look up address in forwarding table Update other fields in packet header (if needed) Update relevant internal counters, etc. Send packet to appropriate output link","title":"Data Plane Challenge"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#important-topics","text":"How do we name endhosts on the Internet? (naming) How do we address endhosts? (addressing) How do we map names to addresses? (DNS) How do we compute forwarding tables? (Routing Control Plane --> Project 1) How do we forward packets? (Routing Data Plane)","title":"Important Topics"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#fundamental-fact-about-networks","text":"Network must support many simultaneous flows at the same time. Recall that flow = stream of packets sent between two end hosts. This means network resources (links and switches) are shared between end hosts. Network resources (like bandwidth) are statistically multiplexed.","title":"Fundamental Fact About Networks"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#statistical-multiplexing","text":"Combining demands to share resources efficiently (vs. statically partitioning resources). Long history in CS Process on an OS (vs. every process has own core) Cloud computing (vs. everyone has own datacenter) Based on premise: peak of aggregate demand is << aggregate of peak demands","title":"Statistical Multiplexing"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#aggregates-peaks-etc","text":"Define the peak rate of flow \\(f\\) to be \\(P(f)\\) . The peak rate of a set of flows \\(f_1, f_2\\) : \\(P(f_1 + f_2)\\) . The aggregate of the peaks: \\[ \\sum_{\\{f\\}} [P(f)] \\] Peak of aggregate \\[ P(\\sum_{\\{f\\}} f) \\] Typically \\[ \\sum_{\\{f\\}} [P(f)] >> P(\\sum_{\\{f\\}} f) \\] Typically \\[ P(\\sum_{\\{f\\}}f) \\approx A(\\sum_{\\{f\\}}f) \\] where \\(A(f)\\) is the average rate of flow \\(f\\) ; \\(A(f_1 + f_2)\\) is the average rate of set of flows \\(f_1, f_2\\) . Statistical multiplexing merely means that you don't provision for absolute worst case (When every peaks at the same time). Instead, you share resources and hope that peak rates don't occur at same time.","title":"Aggregates, Peaks, Etc."},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#how-would-you-share-network-resources","text":"Two approaches to sharing: 1. Reservations: end-hosts explicitly reserve bandwidth when needed (e.g. at the start of a flow). Best-effort: just send data packets when you have them and hope for the best","title":"How Would You Share Network Resources?"},{"location":"EECS/CS%20168/Lectures/Introduction/2.%20How%20the%20Internet%20Works%20-%20A%20Bottom-Up%20View/#implementation","text":"Reservation: 1. Source sends a reservation request to the destination 2. Switches \"establish a circuit\" 3. Source starts sending data 4. Source sends a \"teardown circuit\" message Idea reserve network capacity for all packets in a flow Best-Effort Idea: allocate resources to each packet independently (independent across switches and across packets) Both approaches embody statistical multiplexing Circuit switching: resources shared between flows currently in system. Reserve the peak demand for a flow, but don't reserve for all flows that might ever exist. Packet switching: resources shared between packets currently in system. Resources given out on packet-by-packet basis, and never reserve resources.","title":"Implementation"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/","text":"3. Architectural Principles \u00b6 Recall \u00b6 Two canonical approaches to sharing 1. Reservations: end-hosts explicitly reserve BW when needed (e.g., aat the start of a flow) 2. Best-effort: just send data packets when you have them and hope for the best Two canonical designs to implementing these approaches: 1. Reservations via circuit switching 2. Best-effort via packet switching Circuit switching: idea is to reserve network capacity for all packets in a flow. Make sure you can send a packet through and establish a circuit When it is done, then the circuit will teardown the reservations. Packet switching: allocate resources to each packet independently Circuit vs. Packet Switching: Which is Better? \u00b6 What are the dimensions along which we should compare? As an abstraction to applications: it is useful for the application we are making? Efficiency (at scale): how well are you using network resrouces? Bandwidth is expensive... Handling failures (at scale): the system needs to be resilient to any failures Complexity of implementation (at scale): complicated usages are not really good From an Application Viewpoint \u00b6 Circuits offer better application performance (reserved bandwidth) More predictable and understandable behavior (w/o failures) Also very intuitive abstraction in support of business models! Which Makes More Efficient Use of Network Capacity? \u00b6 Packet switching is typically more efficient, but it much better depends on the \"burstiness\" of the traffic sources. This is because packet switching implements statistical multiplexing at a finer granularity than circuit switching (packets vs. flows) Ex: 3 constant rate sources sharing a link. Total link bandwidth is 30 Mbps, and the demands are that each source needs a constant rate of 10Mbps. Circuit and packet switching give approximately the same result. Every source gets what they need, no wasted bandwidth, etc. Ex: Three bursty sources. For a reservation system: and with best effort: Smooth vs. Bursty Applications: Characterized by the ratio between an app's peak to average transmission rate Some apps have relatively small peak-to-average ratios. Voice might have a ratio of 3:1 or so Data applications tend to be rather bursty: E.g. ratios of 100 r greater are common when web browsing That is why the phone network used reservations and the Internet does not! Other differences in efficiency: Circuit switching spends some time to setup/teardown circuits. Very inefficient when you don't have much data to send (short flows) Handling Failures \u00b6 For packet switching: If there is a failure, just send to another switch. The end host doesn't even need to know there was a failure. This is because decisions are made independent of each other. 1. Link goes down, then what? 2. Network must detect failure 3. Network recalculates routes: job of routing control plane 4. Endhosts and individual flows do nothing special: expect cop with the temporary loss of service For circuit switching: if there is a failure, the network needs to recompute a new path. The endhost needs to send another reservation. The new reservation might not be able to accomodate the resources. We need to teardown, and then send a new reservation. It might not even work if they don't have the resources 1. Network must do all the things needed for packet switching 2. In addition, endhosts must detect failure, teardown old reservations, send a new reservation request 3. All impacted endhosts must do this, for each impacted flow 4. If milllions of flows were going through a switch, then millions of reservation requests are being simultaneously re-established Complexity of Implementation \u00b6 Recall reservations 1. Source sends a reservation request to destination 2. Every switch must say yes to establish a reservation. How do you know that the reservation went through? Extend the design so the switches know the reservation got through. 3. What happens if the reservation request is lost midway? Let's extend the implementation and create a timer that will know if the timer ran out of time, the reservation request was dropped. 4. What happens if the confirmation that the reservation made it is lost? Extend the design 5. What should the endhost do if the reservation is declined. Extend the design... 6. What happens if the underlying route changes? Extend the design... It's hard. Dependencies on consistency. But the states are highly dynamic but agree with each other. Recap: Circuit vs. Packet Switching \u00b6 Pros for circuit switching: Better applicaiton performance (reserved bandwidth) More predictable and understandable (w/o failures) Pros for packet switching: Better efficiency Faster startup to first packet delivered Easier recovery from failure Simpler implementation (avoids dynamic per-flow state management in switches) What does the Internet Use Today? \u00b6 Packet swtiching is the default --> the public Internet Limited use of RSVP (Resource Reservation Protocol) within one domain But you can also buy a dedicated circuit (e.g., MPLS circuits, leased lines, etc.) often used by enterprises from one branch location to another (or to/from cloud) Very expensive (e.g., 10-20x higher than a normal connection) Often statically set up (manually), long-lived (e.g., years) and per user (vs. per flow) So, a far cry from the vision of dynamic reservations that we just discussed Circuit vs. Packet Switching: A Bit of History \u00b6 The early Internet (70s-80s) packet switched. Well suited to bursty file transfer applications. The next iteration (80s-90s): research and industry believed we would need circuit switching Envisioned that voice/live TV/ would be the Internet's true killer app Spent 10+ years trying to realize this vision (man Berkeley folks were pioneers in this space!) Ultimately a failed vision. Why? All the reasons we discussed... but also The killer app became the email and the Web People rewrote apps to be adaptive (turns out we didn't really need guaranteed BW) This is a lesson in how technology can transform user behavior! More About Packet Switching \u00b6 Recall, packets in flight: pipe view.","title":"3. Architectural Principles"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#3-architectural-principles","text":"","title":"3. Architectural Principles"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#recall","text":"Two canonical approaches to sharing 1. Reservations: end-hosts explicitly reserve BW when needed (e.g., aat the start of a flow) 2. Best-effort: just send data packets when you have them and hope for the best Two canonical designs to implementing these approaches: 1. Reservations via circuit switching 2. Best-effort via packet switching Circuit switching: idea is to reserve network capacity for all packets in a flow. Make sure you can send a packet through and establish a circuit When it is done, then the circuit will teardown the reservations. Packet switching: allocate resources to each packet independently","title":"Recall"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#circuit-vs-packet-switching-which-is-better","text":"What are the dimensions along which we should compare? As an abstraction to applications: it is useful for the application we are making? Efficiency (at scale): how well are you using network resrouces? Bandwidth is expensive... Handling failures (at scale): the system needs to be resilient to any failures Complexity of implementation (at scale): complicated usages are not really good","title":"Circuit vs. Packet Switching: Which is Better?"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#from-an-application-viewpoint","text":"Circuits offer better application performance (reserved bandwidth) More predictable and understandable behavior (w/o failures) Also very intuitive abstraction in support of business models!","title":"From an Application Viewpoint"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#which-makes-more-efficient-use-of-network-capacity","text":"Packet switching is typically more efficient, but it much better depends on the \"burstiness\" of the traffic sources. This is because packet switching implements statistical multiplexing at a finer granularity than circuit switching (packets vs. flows) Ex: 3 constant rate sources sharing a link. Total link bandwidth is 30 Mbps, and the demands are that each source needs a constant rate of 10Mbps. Circuit and packet switching give approximately the same result. Every source gets what they need, no wasted bandwidth, etc. Ex: Three bursty sources. For a reservation system: and with best effort: Smooth vs. Bursty Applications: Characterized by the ratio between an app's peak to average transmission rate Some apps have relatively small peak-to-average ratios. Voice might have a ratio of 3:1 or so Data applications tend to be rather bursty: E.g. ratios of 100 r greater are common when web browsing That is why the phone network used reservations and the Internet does not! Other differences in efficiency: Circuit switching spends some time to setup/teardown circuits. Very inefficient when you don't have much data to send (short flows)","title":"Which Makes More Efficient Use of Network Capacity?"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#handling-failures","text":"For packet switching: If there is a failure, just send to another switch. The end host doesn't even need to know there was a failure. This is because decisions are made independent of each other. 1. Link goes down, then what? 2. Network must detect failure 3. Network recalculates routes: job of routing control plane 4. Endhosts and individual flows do nothing special: expect cop with the temporary loss of service For circuit switching: if there is a failure, the network needs to recompute a new path. The endhost needs to send another reservation. The new reservation might not be able to accomodate the resources. We need to teardown, and then send a new reservation. It might not even work if they don't have the resources 1. Network must do all the things needed for packet switching 2. In addition, endhosts must detect failure, teardown old reservations, send a new reservation request 3. All impacted endhosts must do this, for each impacted flow 4. If milllions of flows were going through a switch, then millions of reservation requests are being simultaneously re-established","title":"Handling Failures"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#complexity-of-implementation","text":"Recall reservations 1. Source sends a reservation request to destination 2. Every switch must say yes to establish a reservation. How do you know that the reservation went through? Extend the design so the switches know the reservation got through. 3. What happens if the reservation request is lost midway? Let's extend the implementation and create a timer that will know if the timer ran out of time, the reservation request was dropped. 4. What happens if the confirmation that the reservation made it is lost? Extend the design 5. What should the endhost do if the reservation is declined. Extend the design... 6. What happens if the underlying route changes? Extend the design... It's hard. Dependencies on consistency. But the states are highly dynamic but agree with each other.","title":"Complexity of Implementation"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#recap-circuit-vs-packet-switching","text":"Pros for circuit switching: Better applicaiton performance (reserved bandwidth) More predictable and understandable (w/o failures) Pros for packet switching: Better efficiency Faster startup to first packet delivered Easier recovery from failure Simpler implementation (avoids dynamic per-flow state management in switches)","title":"Recap: Circuit vs. Packet Switching"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#what-does-the-internet-use-today","text":"Packet swtiching is the default --> the public Internet Limited use of RSVP (Resource Reservation Protocol) within one domain But you can also buy a dedicated circuit (e.g., MPLS circuits, leased lines, etc.) often used by enterprises from one branch location to another (or to/from cloud) Very expensive (e.g., 10-20x higher than a normal connection) Often statically set up (manually), long-lived (e.g., years) and per user (vs. per flow) So, a far cry from the vision of dynamic reservations that we just discussed","title":"What does the Internet Use Today?"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#circuit-vs-packet-switching-a-bit-of-history","text":"The early Internet (70s-80s) packet switched. Well suited to bursty file transfer applications. The next iteration (80s-90s): research and industry believed we would need circuit switching Envisioned that voice/live TV/ would be the Internet's true killer app Spent 10+ years trying to realize this vision (man Berkeley folks were pioneers in this space!) Ultimately a failed vision. Why? All the reasons we discussed... but also The killer app became the email and the Web People rewrote apps to be adaptive (turns out we didn't really need guaranteed BW) This is a lesson in how technology can transform user behavior!","title":"Circuit vs. Packet Switching: A Bit of History"},{"location":"EECS/CS%20168/Lectures/Introduction/3.%20Architectural%20Principles/#more-about-packet-switching","text":"Recall, packets in flight: pipe view.","title":"More About Packet Switching"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/","text":"4. Designing the Internet \u00b6 This note is about how to break down the construction of the Internet into modules, and see how one might go about desining the Internet through these pieces. Recall \u00b6 The Internet's layered architecture: 1. Applications, which are built on 2. (Un)reliable data delivery, which are built on 3. Best-effort global packet delivery, which is built on 4. Best-effort local packet delivery, which is built on 5. Physical transfer of bits Local vs. Global Delivery \u00b6 Ethernet networks only know how to cross ethernet networks. Optical networks only know how to cross optical networks. This is the local delivery. We need some way to deliver packets across ethernet, optical, then ethernet. This is the global end-to-end delivery. Protocols \u00b6 Different protocols at the same layer simply means that there are other ways to accomplish the same goal. We get to make the choice of how to transfer to the next layer. Notice there is just one network-layer protocol. Peers Understand the Same Things \u00b6 Communication between peer layers on different systems is defined by protocols. Applications use application protocols to communicate, etc. A protocol is a specificatio nof how parties ocmmunicate. It defines the syntax of communication: Each protocol defines the format of its packet headers (e.g. first 32 bits carry destination address, etc.) And semantics: First a hello, then a request Essentially a state machine Protocols exist at many levels, defined by a variety of standard bodies (IETF, IEEE, ITU) Three Important Properties \u00b6 Each layer: depends on the layer below, supports layer above. Independent of others Multiple versions in a layer: the interfaces differ somewhat, and components at one layer pick which lower-level protocol to use But only one IP layer: Unifying protocol Why Layering Important? \u00b6 Innovation can proceed largely in parallel! Pursued by very different communities: App devs (L7) vs chip designers (L1/L2) Leading to innovation at most levels: applications (lots), transport (some), network (few), physical (lots) Distributing Layers Across Network \u00b6 Layers are simple if only on a single machine. Just a stack of modules interacting with those above/below But we need to implement layers across: 1. Hosts 2. Routers (switches) What Gets Implemented at the End Host? \u00b6 Bits arrive on wire (must implement L1). Also make it up to app (must implement L7). Therefore all layers must exist at host. What Gets Implemented in the Network \u00b6 Bits arrive on wire (Physical Layer L1) Packets must be delivered across links and local networks (Datalink layer L2) Packets must be delivered between networks for global delivery (Network layer L3) The network does not support reliable delivery (Transport layer and above not supported) High level of our design: Closer Look: End Host \u00b6 Addressing within the end host: recal the packet contains the destination host's address. Now the packet is at the endhost. When the packet is at the OS, how does the OS know which app to send the packet to. Port number identifies attachment point between application and OS. Network Ports: Two Types \u00b6 Switches/routers have physical ports. Places where links connect to switches OS supports logical ports: Place where app conntects to OS network stack Sockets and Ports \u00b6 Socket: an OS mechanism that connects app processes to the networking stack When an app wants to access to the network, it opens a socket, whic his associated with a port. This is not a physical port, just a logical one THe port number is used bythe OS to direct incoming packets to its associated socket Implications for Packet Header \u00b6 Packet header must include: 1. Destination host address (used by the network to reach host) 2. Destination port (used by host OS to reach application) When a packet arrives at the destination end-host, it is delivered to the socket (process) associated with the packet's destination port OS Network Stack Is an Intermediary \u00b6 Application has a very clear task with respect to network. It thinks about data. NIC/driver has very dclear task. It thinks about packets Network stack in the intermediary between them. It translates between their abstractions. Recap: Layers at the end host \u00b6 Application layer: part of the app: browser, mail client, etc. (L7) Transport and Network Layer: typically part of the OS (L3, L4) Datalink and Physical layer: hardware/firmware/drivers (L1, L2) Closer Look: Network \u00b6 Bits on a wire (L1) Local delivery of packets (L2) Global delivery of packets (L3) Recall: Logical Communication \u00b6 Layers interact with peer's corresponding layer. The lower three layers implemented everywhere, and the top two layers implemented only at hosts. Protocl Diagram \u00b6 First Physical Communication: Communication goes down to physical network Then up to relevant layer So, for an HTTP message at the application layer, it would travel like this. Where dashed lines are logical communication, but solid lines are physical communication. Layer Encapsulation \u00b6 See how going down, we package the information on top of it. As communication goes down to the physical network, it will package more, and as it goes up, it will unpack. Packets contain multiple headers! Review \u00b6 Architectural Wisdom \u00b6 David Clark: Chief protocol architect for the Internet in the 80s. Gave he language of it, not its implementation \"End-to-End Arguments in System Design\" (1981) \"The Design Philosophy of the DARPA Internet Protocols\" (1988) Articulates the rationale underlying the Internet's architecture End-to-End Principles \u00b6 Guides the debate about what functionality the network does or doesn't implement. Today: should we implement reliability in the network? What does it mean for the network to implement reliability? Let's see what happens: Application reads file from disk, sends it to OS, sends it to host B. OS B will read and send it to application, then the application on host B will send it to its disk. We want to achieve reliability. Solution: implement reliability at each step (network implments reliability); some check sum at each step Solution: end-to-end check and retry (does not assume network is reliable); a check sum overall It seems like there is a problem: what if the checksum check at any of the solution fails? 1. Solution 1 cannot be made perfectly reliable: what happens if a component fails between two steps? What happens if a component has a bug (i.e. check sum passes because of bug)? Guaranteeing correctness: that means receive has to do the end-to-end check anyway (solution 2). If not, the endpoints mihght be left in an incorrect state 2. Solution 2 can also fail but will never leave the endpoints in an incorrect state. Host B will neveer accept a corrupted file. Impact of Network Failure \u00b6 Solution 1: Network failures/bugs impact endpoint semantics. Requires endpoints trust other elements! That is bad Solution 2: Endpoint semantics decoupled from network failure> Endpoint only relies on what it can control! End-to-End Argument: Intuition \u00b6 Some application requirements can only be correctly implemented end-to-end Reliability, security, etc. End-systems Must do so, for correctness Can satisfy the requirement without network's help Thesis: Implementing these functions in the network is unnecessary and adds complexity to the network. Therefore... \u00b6 Should you ever implement reliability in network? I.e., in addition to doing so in the hosts Performance: If each link drps packets 10% of the time, and we have 10 links, then E2E failure rate is 65%. What if the link implemented two retransactions? Per-link drop rate reduced to 0.1%, E2E failure rate is ~1% Perhaps, as a performance optimization, but not for correctness. Need for it must be evaluated on a case-by-case basis Recap: End-to-End \u00b6 Implementing this function (reliability) in the network: 1. Doesn't reduce host implementation complexity 2. Does increase network complixity 3. Imposes overhead on all applications 4. However, implementing in network can enhance performance in some cases (e.g., very lossy link) In Clark's Works: \"The function in question can completely and correctly be implemented only with the knowledge and help of the application at the end points. Therefore, providing that function as a feature of the communication system itself is not possible. (Sometimes an incomplete version of the function provided by the communication system may be useful as a performance enhancement)\" The \"how\" 1. How to decompose system into modules? Layering 2. Where are the layers implemented? End hosts (L1-L7) and Networks (L1-L3) 3. One unifying protocol at the network layer? IP The \"why\" 1. Layering provided a clean separation of concerns and hence enabled innovation! 2. End-to-End Principle kept unnecessary state and functionality out of the network and hence allowed the Internet to scale!","title":"4. Designing the Internet"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#4-designing-the-internet","text":"This note is about how to break down the construction of the Internet into modules, and see how one might go about desining the Internet through these pieces.","title":"4. Designing the Internet"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#recall","text":"The Internet's layered architecture: 1. Applications, which are built on 2. (Un)reliable data delivery, which are built on 3. Best-effort global packet delivery, which is built on 4. Best-effort local packet delivery, which is built on 5. Physical transfer of bits","title":"Recall"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#local-vs-global-delivery","text":"Ethernet networks only know how to cross ethernet networks. Optical networks only know how to cross optical networks. This is the local delivery. We need some way to deliver packets across ethernet, optical, then ethernet. This is the global end-to-end delivery.","title":"Local vs. Global Delivery"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#protocols","text":"Different protocols at the same layer simply means that there are other ways to accomplish the same goal. We get to make the choice of how to transfer to the next layer. Notice there is just one network-layer protocol.","title":"Protocols"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#peers-understand-the-same-things","text":"Communication between peer layers on different systems is defined by protocols. Applications use application protocols to communicate, etc. A protocol is a specificatio nof how parties ocmmunicate. It defines the syntax of communication: Each protocol defines the format of its packet headers (e.g. first 32 bits carry destination address, etc.) And semantics: First a hello, then a request Essentially a state machine Protocols exist at many levels, defined by a variety of standard bodies (IETF, IEEE, ITU)","title":"Peers Understand the Same Things"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#three-important-properties","text":"Each layer: depends on the layer below, supports layer above. Independent of others Multiple versions in a layer: the interfaces differ somewhat, and components at one layer pick which lower-level protocol to use But only one IP layer: Unifying protocol","title":"Three Important Properties"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#why-layering-important","text":"Innovation can proceed largely in parallel! Pursued by very different communities: App devs (L7) vs chip designers (L1/L2) Leading to innovation at most levels: applications (lots), transport (some), network (few), physical (lots)","title":"Why Layering Important?"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#distributing-layers-across-network","text":"Layers are simple if only on a single machine. Just a stack of modules interacting with those above/below But we need to implement layers across: 1. Hosts 2. Routers (switches)","title":"Distributing Layers Across Network"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#what-gets-implemented-at-the-end-host","text":"Bits arrive on wire (must implement L1). Also make it up to app (must implement L7). Therefore all layers must exist at host.","title":"What Gets Implemented at the End Host?"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#what-gets-implemented-in-the-network","text":"Bits arrive on wire (Physical Layer L1) Packets must be delivered across links and local networks (Datalink layer L2) Packets must be delivered between networks for global delivery (Network layer L3) The network does not support reliable delivery (Transport layer and above not supported) High level of our design:","title":"What Gets Implemented in the Network"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#closer-look-end-host","text":"Addressing within the end host: recal the packet contains the destination host's address. Now the packet is at the endhost. When the packet is at the OS, how does the OS know which app to send the packet to. Port number identifies attachment point between application and OS.","title":"Closer Look: End Host"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#network-ports-two-types","text":"Switches/routers have physical ports. Places where links connect to switches OS supports logical ports: Place where app conntects to OS network stack","title":"Network Ports: Two Types"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#sockets-and-ports","text":"Socket: an OS mechanism that connects app processes to the networking stack When an app wants to access to the network, it opens a socket, whic his associated with a port. This is not a physical port, just a logical one THe port number is used bythe OS to direct incoming packets to its associated socket","title":"Sockets and Ports"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#implications-for-packet-header","text":"Packet header must include: 1. Destination host address (used by the network to reach host) 2. Destination port (used by host OS to reach application) When a packet arrives at the destination end-host, it is delivered to the socket (process) associated with the packet's destination port","title":"Implications for Packet Header"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#os-network-stack-is-an-intermediary","text":"Application has a very clear task with respect to network. It thinks about data. NIC/driver has very dclear task. It thinks about packets Network stack in the intermediary between them. It translates between their abstractions.","title":"OS Network Stack Is an Intermediary"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#recap-layers-at-the-end-host","text":"Application layer: part of the app: browser, mail client, etc. (L7) Transport and Network Layer: typically part of the OS (L3, L4) Datalink and Physical layer: hardware/firmware/drivers (L1, L2)","title":"Recap: Layers at the end host"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#closer-look-network","text":"Bits on a wire (L1) Local delivery of packets (L2) Global delivery of packets (L3)","title":"Closer Look: Network"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#recall-logical-communication","text":"Layers interact with peer's corresponding layer. The lower three layers implemented everywhere, and the top two layers implemented only at hosts.","title":"Recall: Logical Communication"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#protocl-diagram","text":"First Physical Communication: Communication goes down to physical network Then up to relevant layer So, for an HTTP message at the application layer, it would travel like this. Where dashed lines are logical communication, but solid lines are physical communication.","title":"Protocl Diagram"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#layer-encapsulation","text":"See how going down, we package the information on top of it. As communication goes down to the physical network, it will package more, and as it goes up, it will unpack. Packets contain multiple headers!","title":"Layer Encapsulation"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#review","text":"","title":"Review"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#architectural-wisdom","text":"David Clark: Chief protocol architect for the Internet in the 80s. Gave he language of it, not its implementation \"End-to-End Arguments in System Design\" (1981) \"The Design Philosophy of the DARPA Internet Protocols\" (1988) Articulates the rationale underlying the Internet's architecture","title":"Architectural Wisdom"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#end-to-end-principles","text":"Guides the debate about what functionality the network does or doesn't implement. Today: should we implement reliability in the network? What does it mean for the network to implement reliability? Let's see what happens: Application reads file from disk, sends it to OS, sends it to host B. OS B will read and send it to application, then the application on host B will send it to its disk. We want to achieve reliability. Solution: implement reliability at each step (network implments reliability); some check sum at each step Solution: end-to-end check and retry (does not assume network is reliable); a check sum overall It seems like there is a problem: what if the checksum check at any of the solution fails? 1. Solution 1 cannot be made perfectly reliable: what happens if a component fails between two steps? What happens if a component has a bug (i.e. check sum passes because of bug)? Guaranteeing correctness: that means receive has to do the end-to-end check anyway (solution 2). If not, the endpoints mihght be left in an incorrect state 2. Solution 2 can also fail but will never leave the endpoints in an incorrect state. Host B will neveer accept a corrupted file.","title":"End-to-End Principles"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#impact-of-network-failure","text":"Solution 1: Network failures/bugs impact endpoint semantics. Requires endpoints trust other elements! That is bad Solution 2: Endpoint semantics decoupled from network failure> Endpoint only relies on what it can control!","title":"Impact of Network Failure"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#end-to-end-argument-intuition","text":"Some application requirements can only be correctly implemented end-to-end Reliability, security, etc. End-systems Must do so, for correctness Can satisfy the requirement without network's help Thesis: Implementing these functions in the network is unnecessary and adds complexity to the network.","title":"End-to-End Argument: Intuition"},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#therefore","text":"Should you ever implement reliability in network? I.e., in addition to doing so in the hosts Performance: If each link drps packets 10% of the time, and we have 10 links, then E2E failure rate is 65%. What if the link implemented two retransactions? Per-link drop rate reduced to 0.1%, E2E failure rate is ~1% Perhaps, as a performance optimization, but not for correctness. Need for it must be evaluated on a case-by-case basis","title":"Therefore..."},{"location":"EECS/CS%20168/Lectures/Introduction/4.%20Designing%20the%20Internet/#recap-end-to-end","text":"Implementing this function (reliability) in the network: 1. Doesn't reduce host implementation complexity 2. Does increase network complixity 3. Imposes overhead on all applications 4. However, implementing in network can enhance performance in some cases (e.g., very lossy link) In Clark's Works: \"The function in question can completely and correctly be implemented only with the knowledge and help of the application at the end points. Therefore, providing that function as a feature of the communication system itself is not possible. (Sometimes an incomplete version of the function provided by the communication system may be useful as a performance enhancement)\" The \"how\" 1. How to decompose system into modules? Layering 2. Where are the layers implemented? End hosts (L1-L7) and Networks (L1-L3) 3. One unifying protocol at the network layer? IP The \"why\" 1. Layering provided a clean separation of concerns and hence enabled innovation! 2. End-to-End Principle kept unnecessary state and functionality out of the network and hence allowed the Internet to scale!","title":"Recap: End-to-End"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/","text":"5. Routing Fundamentals \u00b6 This note introduces routing: what it is, why we need it, and challenges of routing. Outline \u00b6 Setting the Scene Theoretical Perspective and Routing Validity Setting the Scene \u00b6 Disclaimer \u00b6 There are an endless numbers of possible solutions to routing. We will constrain the initial discussion of how \"archetypal Internet\" works. Recall Packets \u00b6 Packets have a payload (actual data) and headers (metadata). The headers must contain destination address, which implies that a host has an address (or more than one). For now, we will think of hosts having one address. What is a Router? \u00b6 A router is an intermediate node that is usually connected to multiple neighbors. Why do we have Routers? 1. If we were to put a link that goes from every router to other router, the Internet wouldn't scale. Consider adding an \\(n\\) router, we would need to connect \\(n - 1\\) new switches. However, this approach is very robust. But everyone gets a reserved link to send data to each other. 2. If all hosts share the same wire, it scales really well (adding a bit more wire). However, it is not robust; one wire breaks, hosts can disconnect completely from each other. Also, everyone is fighting for the same bandwidth. Very cheap. These two approaches might combine into: Way fewer links tha a full mesh! But more than just a single link Alternate paths! Challenges of Routing \u00b6 The basic challenge When a packket arrives at a router, how does the router know where to send it next such that it will eventually arive at the desried destination We want to find paths which are good: Good may have several meanings (cheapest, fewest number of hops) No random routing: random routing is wasteful in terms of resources and time. No just sending it to everyone (it works, but it congests the network, super wasteful) We want to adapt to arbitrary topologies The graph describing a network can vary a lot! Different networks (parts of the Internet) may use different routing, but generality is good Especially since every topology is dynamic (any router can go down) Forwarding Problem \u00b6 When a packet arrives, router forwards it to one of its neighbors. You want to make the decision about which neighbor quickly. This implies the decision process is simple. The solution: use a table Given tables, decisions depends only on destination field of packet We call it destination-based forwarding/routing. Very common. One of those \"archetypal Internet\" things. We will think of alternatives later Two Things Routers Do \u00b6 Forwarding Looks up packet's destination in table and sends packet to given neighbor Inherently local: depends only on arriving packet and local table Primary responsibility of router's data plane Time scale: per packet arrival (nanoseconds?) Routing Communicates with other routers to deterine how to populate tables for forwarding Inherently global: must know about all destinations, not just local ones Primary responsibility of router's control plane Time scale: per network event (e.g. per failure) Theory \u00b6 Directed Delivery Trees \u00b6 We can graph paths packets to a destination will take if they follow tables. NextHop becomes an arrow Only one NextHop per destination, which means only one outgoing arrow per node!. Once paths \"meet\", they never split The set of all paths create \"directed delivery tree\" Must cover every node (we want to be able to reach it from anywhere) It is an oriented spanning tree rooted at the destination Spanning tree: a tree that touches every node (no cycles) Routing State Validity \u00b6 Earlier, said we wanted \"goog\" paths between hosts. Notion of goodness is flexible, but minimum requirement must be that packets actaully reach their destinations. It would be usefule to be able to reason about this. This is articulated by Scott Shenker as routing state validity. Local routing state is table in single router. By itself, the state in a single router can't be evaluated for validity. It must be evaluated in terms of the global context. Global state is collection of tables in all routers. Global state determines which paths packets take. It is valid if it produces forwarding decisions that always deliver packets to their destinations Goal of routing protocols: compute valid state: Eventually talk about how you build routing state But given some state ... how can you tell if it's valid? Need a succint correctness condition for routing... what makes routing correct/incorrect? Global routing state is valid if and only if: - For each destination: there are no dead ends, there are no loops Dead end: when there is no outgoing link (next-hop) Packet arrives, but is not forwarded (e.g., because there's no table entry for destination) The destination doesn't forward, butdoesn't count as a dead end! But other hosts generally are dead ends, since hosts don't generally forward packets Loop: when packet cycles around the same set of nodes If forwarding is deterministic and only depends on destination field, this will go on indefinitely. If there are no loops or dead ends, that is sufficient to know the state is valid (This is more subtle): Assume the routing state has no loops or dead ends Packet can't hit the same node twice (no loops) Packet can't stop before hitting destination (no dead ends) So a packet must keep wandering the network, hitting different nodes. Only a finite number of unique nodes to visit. Must eventually hit the destination Thus: if no loops and no dead ends, then routing state is valid. Validation \u00b6 Couple Notes \u00b6 Hosts generally do not participate in routing. In common cases, hosts: 1. Have a single link to a single router 2. Have a default route that sends everything to that router They are not interesting, so we often ignore them except as destinations Routers might be legal destinations (in addition to hosts) - Depends on network design Internet Protocol routers can be But how often have you wanted to talk to a specific router? Host-to-host communication much more common: we'll often ignore routers as destinations But do think of all routers as potential sources (packets may arrive in unexpected ways) Verifying Routing State Validity \u00b6 Focus only on a single destination. Ignore all other hosts. Ignore all other routing states For each router, mark outgoing edge with arrow (point at next hop). There can only be one at each node (destination-based) Eliminate all links with no arrows Look at what's left: state is valid if and only if remaining graph is a directed delivery tree (all paths point towards root) There is a dead end in the second image. There is a dead end in this example Very easy to check validity of routing state for a particular destination. Dead ends are obvious: a node with no outgoing arrow can't reach destination Loops are obvious: disconnected from destination Now just repeat for each destination Note on Generality \u00b6 We are looking at this from perspective of destination-based routing. Same basic no loops or dead ends conditions generalizes to at least* any other system that does deterministic forwarding based on fixed packet headers (that is, it is not limited to destination-based routing) We just need to: Make one minor addition Carefully consider what constitutes a loop Bellman-Ford Algorithm \u00b6 Two things we know about networks... 1. They are distributed (many independent components) 2. They are asynchronous (components don't operate in sync) Very promising algorithm to turn into a routing protocol: my_number = infinity offer_to_neighbors(my_number + 1) while True: offer = wait_for_offer_from_a_neighbor() if offer < my_number: my_number = offer offer_to_neighbors(my_number + 1) Distance-Vector Protocols \u00b6 Routing protocols that work like this are called Distance-Vector protocols Adjacent routers conceptually exchange a vector (i.e., array) of distances. More like a vector of (destination, distance) tuples? Used in ARPANET (Internet precursor) as far back as 1969 Later used by XEROX Then by routed in Berkeley Software Distribution Unix 1983 Routed's protocol standardized as RFC 1058 (Routing Information Protocol / RIP) in 1988 Updated for classless addressing (we'll find out about that) in RFC 1723 in 1994 Updated for IPv6 in RFC 2080 in 1997 Kind of the \"prototypical distance-vector protocol\" DV pretty widely deployed historically; less popular today, but not dead Cisco EIGRP (1993) more advanced, published in RFC 7868 in 2016. Babel published as experimental RFC 6126 in 2011; actively worked on","title":"5. Routing Fundamentals"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#5-routing-fundamentals","text":"This note introduces routing: what it is, why we need it, and challenges of routing.","title":"5. Routing Fundamentals"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#outline","text":"Setting the Scene Theoretical Perspective and Routing Validity","title":"Outline"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#setting-the-scene","text":"","title":"Setting the Scene"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#disclaimer","text":"There are an endless numbers of possible solutions to routing. We will constrain the initial discussion of how \"archetypal Internet\" works.","title":"Disclaimer"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#recall-packets","text":"Packets have a payload (actual data) and headers (metadata). The headers must contain destination address, which implies that a host has an address (or more than one). For now, we will think of hosts having one address.","title":"Recall Packets"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#what-is-a-router","text":"A router is an intermediate node that is usually connected to multiple neighbors. Why do we have Routers? 1. If we were to put a link that goes from every router to other router, the Internet wouldn't scale. Consider adding an \\(n\\) router, we would need to connect \\(n - 1\\) new switches. However, this approach is very robust. But everyone gets a reserved link to send data to each other. 2. If all hosts share the same wire, it scales really well (adding a bit more wire). However, it is not robust; one wire breaks, hosts can disconnect completely from each other. Also, everyone is fighting for the same bandwidth. Very cheap. These two approaches might combine into: Way fewer links tha a full mesh! But more than just a single link Alternate paths!","title":"What is a Router?"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#challenges-of-routing","text":"The basic challenge When a packket arrives at a router, how does the router know where to send it next such that it will eventually arive at the desried destination We want to find paths which are good: Good may have several meanings (cheapest, fewest number of hops) No random routing: random routing is wasteful in terms of resources and time. No just sending it to everyone (it works, but it congests the network, super wasteful) We want to adapt to arbitrary topologies The graph describing a network can vary a lot! Different networks (parts of the Internet) may use different routing, but generality is good Especially since every topology is dynamic (any router can go down)","title":"Challenges of Routing"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#forwarding-problem","text":"When a packet arrives, router forwards it to one of its neighbors. You want to make the decision about which neighbor quickly. This implies the decision process is simple. The solution: use a table Given tables, decisions depends only on destination field of packet We call it destination-based forwarding/routing. Very common. One of those \"archetypal Internet\" things. We will think of alternatives later","title":"Forwarding Problem"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#two-things-routers-do","text":"Forwarding Looks up packet's destination in table and sends packet to given neighbor Inherently local: depends only on arriving packet and local table Primary responsibility of router's data plane Time scale: per packet arrival (nanoseconds?) Routing Communicates with other routers to deterine how to populate tables for forwarding Inherently global: must know about all destinations, not just local ones Primary responsibility of router's control plane Time scale: per network event (e.g. per failure)","title":"Two Things Routers Do"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#theory","text":"","title":"Theory"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#directed-delivery-trees","text":"We can graph paths packets to a destination will take if they follow tables. NextHop becomes an arrow Only one NextHop per destination, which means only one outgoing arrow per node!. Once paths \"meet\", they never split The set of all paths create \"directed delivery tree\" Must cover every node (we want to be able to reach it from anywhere) It is an oriented spanning tree rooted at the destination Spanning tree: a tree that touches every node (no cycles)","title":"Directed Delivery Trees"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#routing-state-validity","text":"Earlier, said we wanted \"goog\" paths between hosts. Notion of goodness is flexible, but minimum requirement must be that packets actaully reach their destinations. It would be usefule to be able to reason about this. This is articulated by Scott Shenker as routing state validity. Local routing state is table in single router. By itself, the state in a single router can't be evaluated for validity. It must be evaluated in terms of the global context. Global state is collection of tables in all routers. Global state determines which paths packets take. It is valid if it produces forwarding decisions that always deliver packets to their destinations Goal of routing protocols: compute valid state: Eventually talk about how you build routing state But given some state ... how can you tell if it's valid? Need a succint correctness condition for routing... what makes routing correct/incorrect? Global routing state is valid if and only if: - For each destination: there are no dead ends, there are no loops Dead end: when there is no outgoing link (next-hop) Packet arrives, but is not forwarded (e.g., because there's no table entry for destination) The destination doesn't forward, butdoesn't count as a dead end! But other hosts generally are dead ends, since hosts don't generally forward packets Loop: when packet cycles around the same set of nodes If forwarding is deterministic and only depends on destination field, this will go on indefinitely. If there are no loops or dead ends, that is sufficient to know the state is valid (This is more subtle): Assume the routing state has no loops or dead ends Packet can't hit the same node twice (no loops) Packet can't stop before hitting destination (no dead ends) So a packet must keep wandering the network, hitting different nodes. Only a finite number of unique nodes to visit. Must eventually hit the destination Thus: if no loops and no dead ends, then routing state is valid.","title":"Routing State Validity"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#validation","text":"","title":"Validation"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#couple-notes","text":"Hosts generally do not participate in routing. In common cases, hosts: 1. Have a single link to a single router 2. Have a default route that sends everything to that router They are not interesting, so we often ignore them except as destinations Routers might be legal destinations (in addition to hosts) - Depends on network design Internet Protocol routers can be But how often have you wanted to talk to a specific router? Host-to-host communication much more common: we'll often ignore routers as destinations But do think of all routers as potential sources (packets may arrive in unexpected ways)","title":"Couple Notes"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#verifying-routing-state-validity","text":"Focus only on a single destination. Ignore all other hosts. Ignore all other routing states For each router, mark outgoing edge with arrow (point at next hop). There can only be one at each node (destination-based) Eliminate all links with no arrows Look at what's left: state is valid if and only if remaining graph is a directed delivery tree (all paths point towards root) There is a dead end in the second image. There is a dead end in this example Very easy to check validity of routing state for a particular destination. Dead ends are obvious: a node with no outgoing arrow can't reach destination Loops are obvious: disconnected from destination Now just repeat for each destination","title":"Verifying Routing State Validity"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#note-on-generality","text":"We are looking at this from perspective of destination-based routing. Same basic no loops or dead ends conditions generalizes to at least* any other system that does deterministic forwarding based on fixed packet headers (that is, it is not limited to destination-based routing) We just need to: Make one minor addition Carefully consider what constitutes a loop","title":"Note on Generality"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#bellman-ford-algorithm","text":"Two things we know about networks... 1. They are distributed (many independent components) 2. They are asynchronous (components don't operate in sync) Very promising algorithm to turn into a routing protocol: my_number = infinity offer_to_neighbors(my_number + 1) while True: offer = wait_for_offer_from_a_neighbor() if offer < my_number: my_number = offer offer_to_neighbors(my_number + 1)","title":"Bellman-Ford Algorithm"},{"location":"EECS/CS%20168/Lectures/Routing/5.%20Routing%20Fundamentals/#distance-vector-protocols","text":"Routing protocols that work like this are called Distance-Vector protocols Adjacent routers conceptually exchange a vector (i.e., array) of distances. More like a vector of (destination, distance) tuples? Used in ARPANET (Internet precursor) as far back as 1969 Later used by XEROX Then by routed in Berkeley Software Distribution Unix 1983 Routed's protocol standardized as RFC 1058 (Routing Information Protocol / RIP) in 1988 Updated for classless addressing (we'll find out about that) in RFC 1723 in 1994 Updated for IPv6 in RFC 2080 in 1997 Kind of the \"prototypical distance-vector protocol\" DV pretty widely deployed historically; less popular today, but not dead Cisco EIGRP (1993) more advanced, published in RFC 7868 in 2016. Babel published as experimental RFC 6126 in 2011; actively worked on","title":"Distance-Vector Protocols"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/","text":"6. Routing Approaches I \u00b6 This note is all about the kings of routing and the kings of routers: IGPs, EGPs, Least-cost routing, trial and static routes, distance-vector Kinds of Routing, Kinds of Routers \u00b6 The Internet does not work by having a single giant routing protocol. The Internet is a network of networks. The best way to route on one may not be the best way on another (why not?) Networks differ: Physical size, number of hosts, number of routers, bandwidth, latency, failure rate, topology (densely vs. sparsely connected), support staff size, when built. So, let's have all individual networks choose how to route insider their network (intradomain), and all networks agree on how to route between themselves and other networks (interdomain) Interdomain and Intradomain Routing \u00b6 Intradomain routing: means routing within a single network (technically an \"autonomous system\"). Protocols used are often called IGPs or Interior Gateway Protocols Interdomain routing: routing between networks (ASes). The routing glue which binds many networks into the Internet! Protocols used are the EGPs or Exterior Gateway Protocols Only one is ever used at a time! All ASes agree Internet has used BGP since the mid 1900s Least-Cost Routing \u00b6 We wanted good routes: 1. Routes that work! State must not have any loops. Must not have any dead ends. Both of these 2. Routes that are in some way \"good\". Commonly this is done by minimizing some \"bad\" quantity which we might call cost -- hence least-cost routing 3. What else we might minimize: price, propagation delay, distance, unreliability, others. Let's have a topology where we associate a cost with each edge. Our goal is to find the path with the smallest sum. Where do the costs come from? 1. Generally, local to router: routers know the costs of their attached links 2. May be configured by an operator 3. May be determined automatically: OSPF (intradomain routing protocol) uses the link bandwidth. Higher bandwidth = smaller cost (gets highest-average-bandwidth paths) Other notes: 1. Least cost routes are an easy way to avoid loops: no sensible cost metric is minimized by traversing a loop 2. Least cost routes are destination-based: only depends on the destination 3. They form a spanning tree: no loops 4. Shortest path really means least cost path 5. When weights are 1, these are the same thing -- the hop count Trivial and Static Routes \u00b6 Trivial Routes \u00b6 There are a couple types of routes which are uninteresting, you probably get for free, We will often ignore. These are trivial routes 1. Route to yourself: with a cost of zero 2. If you have only one neighbor, a default route. Cost doesn't matter; it is the only way. Hosts with multiple neighbors usually have one anyway Static Routes \u00b6 Static routes are manually by an operator 1. Sometimes operator just knows what they want! 2. Hosts don't generally participate in routing protocols, so how do the routers know where the hosts are? Operator adds static route on router next to host Distance-Vector Routing Protocols \u00b6 Long history on the Internet. The prototypical DV protocol is RIP (Routing Information Protocol). There is also a strong relationship to Bellman-Ford shortest path algorithm. Aside Routing vs. Forwarding \u00b6 Routing 1. Communicate with other routers to determine how to populate tables for forwarding 2. Figuring out best friends by sharing magic numbers with neighbors Forwarding 1. Looks up packet's destination in table and sends packet to given neighbor 2. Passing envelopes to our best friends Bellman-Ford \u00b6 Here is the serial Bellman-Ford algorithm def bellman_ford(dst, routers, links): distance = {} nexthop = {} for r in routers: distance[r] = INFINITY nexthop[r] = None distance[dst] = 0 for _ in range(len(routers) - 1): for (r1, r2, dist) in links: if distance[r1] + dist < distance[r2]: distance[r2] = distance[r1] + dist nexthop[r2] = r1 return distance, nexthop We can see things we recognize: 1. Magic number and best friend 2. Start with infinity (except destination) 3. Compare offer to current 4. Accept offer 5. Remember best friend But we did it in parallel! and asynchronously! Also what is up with the for _ in range(len(routers) - 1) ? Also, nobody new the whole topology! Is Dijkstra's algorithm better? It is \\(O(|E| + |V|\\log |V|)\\) , and Bellman-Ford is \\(O(|E||V|)\\) . It is not a fair comparison because Dijkstra's assumes you know everything about the topology. Putting Together Distance-Vector \u00b6 Keep processing updates/ advertisements from neighbors... However, what if the router that gave you the magic number sends you another advertisement of a more terrible one? Just update the one from the previous router? That's fine because if the R11 router gives you the 9 again, you'd update it. Split Horizon \u00b6 Router timers aren't synchonized with each other! Between offset timers, packet drops, triggered updates, advertisements can come in many orders In following examples, let's show things that can happen, but doesn't mean they always will happen. Lets begin with the A, R1, R2, R3 topology. R1 has its static connection to A, then sends the advertisement to R2, which sends it to R3. Now let' something terrible happen to the R1-R2 router. Since R3 will start sending back to R2. This is split horizon. Why would you advertise a path back to the person who advertised it to you? Telling them about your entry going through them: doesn't tell them anything new, and can mislead them into thinking you have independent path. Solution: if you are using a next-hop's path for some destination: don't advertise that destination to them! Counting to Infinity \u00b6 There is a scenario where R2-R3 will keep on advertising to each other with costs that they will accept. The tables will not converge in this case. Solving split horizon also solves this scenario Dealing with New Links \u00b6 Have periodic updates when adding new links, so that it just works out Failed Links \u00b6 Solution: Each route only has a finite Time to Live. Gets recharged by the periodic advertisements. If you don't get a periodic update, expire and remove route","title":"6. Routing Approaches I"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#6-routing-approaches-i","text":"This note is all about the kings of routing and the kings of routers: IGPs, EGPs, Least-cost routing, trial and static routes, distance-vector","title":"6. Routing Approaches I"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#kinds-of-routing-kinds-of-routers","text":"The Internet does not work by having a single giant routing protocol. The Internet is a network of networks. The best way to route on one may not be the best way on another (why not?) Networks differ: Physical size, number of hosts, number of routers, bandwidth, latency, failure rate, topology (densely vs. sparsely connected), support staff size, when built. So, let's have all individual networks choose how to route insider their network (intradomain), and all networks agree on how to route between themselves and other networks (interdomain)","title":"Kinds of Routing, Kinds of Routers"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#interdomain-and-intradomain-routing","text":"Intradomain routing: means routing within a single network (technically an \"autonomous system\"). Protocols used are often called IGPs or Interior Gateway Protocols Interdomain routing: routing between networks (ASes). The routing glue which binds many networks into the Internet! Protocols used are the EGPs or Exterior Gateway Protocols Only one is ever used at a time! All ASes agree Internet has used BGP since the mid 1900s","title":"Interdomain and Intradomain Routing"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#least-cost-routing","text":"We wanted good routes: 1. Routes that work! State must not have any loops. Must not have any dead ends. Both of these 2. Routes that are in some way \"good\". Commonly this is done by minimizing some \"bad\" quantity which we might call cost -- hence least-cost routing 3. What else we might minimize: price, propagation delay, distance, unreliability, others. Let's have a topology where we associate a cost with each edge. Our goal is to find the path with the smallest sum. Where do the costs come from? 1. Generally, local to router: routers know the costs of their attached links 2. May be configured by an operator 3. May be determined automatically: OSPF (intradomain routing protocol) uses the link bandwidth. Higher bandwidth = smaller cost (gets highest-average-bandwidth paths) Other notes: 1. Least cost routes are an easy way to avoid loops: no sensible cost metric is minimized by traversing a loop 2. Least cost routes are destination-based: only depends on the destination 3. They form a spanning tree: no loops 4. Shortest path really means least cost path 5. When weights are 1, these are the same thing -- the hop count","title":"Least-Cost Routing"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#trivial-and-static-routes","text":"","title":"Trivial and Static Routes"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#trivial-routes","text":"There are a couple types of routes which are uninteresting, you probably get for free, We will often ignore. These are trivial routes 1. Route to yourself: with a cost of zero 2. If you have only one neighbor, a default route. Cost doesn't matter; it is the only way. Hosts with multiple neighbors usually have one anyway","title":"Trivial Routes"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#static-routes","text":"Static routes are manually by an operator 1. Sometimes operator just knows what they want! 2. Hosts don't generally participate in routing protocols, so how do the routers know where the hosts are? Operator adds static route on router next to host","title":"Static Routes"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#distance-vector-routing-protocols","text":"Long history on the Internet. The prototypical DV protocol is RIP (Routing Information Protocol). There is also a strong relationship to Bellman-Ford shortest path algorithm.","title":"Distance-Vector Routing Protocols"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#aside-routing-vs-forwarding","text":"Routing 1. Communicate with other routers to determine how to populate tables for forwarding 2. Figuring out best friends by sharing magic numbers with neighbors Forwarding 1. Looks up packet's destination in table and sends packet to given neighbor 2. Passing envelopes to our best friends","title":"Aside Routing vs. Forwarding"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#bellman-ford","text":"Here is the serial Bellman-Ford algorithm def bellman_ford(dst, routers, links): distance = {} nexthop = {} for r in routers: distance[r] = INFINITY nexthop[r] = None distance[dst] = 0 for _ in range(len(routers) - 1): for (r1, r2, dist) in links: if distance[r1] + dist < distance[r2]: distance[r2] = distance[r1] + dist nexthop[r2] = r1 return distance, nexthop We can see things we recognize: 1. Magic number and best friend 2. Start with infinity (except destination) 3. Compare offer to current 4. Accept offer 5. Remember best friend But we did it in parallel! and asynchronously! Also what is up with the for _ in range(len(routers) - 1) ? Also, nobody new the whole topology! Is Dijkstra's algorithm better? It is \\(O(|E| + |V|\\log |V|)\\) , and Bellman-Ford is \\(O(|E||V|)\\) . It is not a fair comparison because Dijkstra's assumes you know everything about the topology.","title":"Bellman-Ford"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#putting-together-distance-vector","text":"Keep processing updates/ advertisements from neighbors... However, what if the router that gave you the magic number sends you another advertisement of a more terrible one? Just update the one from the previous router? That's fine because if the R11 router gives you the 9 again, you'd update it.","title":"Putting Together Distance-Vector"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#split-horizon","text":"Router timers aren't synchonized with each other! Between offset timers, packet drops, triggered updates, advertisements can come in many orders In following examples, let's show things that can happen, but doesn't mean they always will happen. Lets begin with the A, R1, R2, R3 topology. R1 has its static connection to A, then sends the advertisement to R2, which sends it to R3. Now let' something terrible happen to the R1-R2 router. Since R3 will start sending back to R2. This is split horizon. Why would you advertise a path back to the person who advertised it to you? Telling them about your entry going through them: doesn't tell them anything new, and can mislead them into thinking you have independent path. Solution: if you are using a next-hop's path for some destination: don't advertise that destination to them!","title":"Split Horizon"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#counting-to-infinity","text":"There is a scenario where R2-R3 will keep on advertising to each other with costs that they will accept. The tables will not converge in this case. Solving split horizon also solves this scenario","title":"Counting to Infinity"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#dealing-with-new-links","text":"Have periodic updates when adding new links, so that it just works out","title":"Dealing with New Links"},{"location":"EECS/CS%20168/Lectures/Routing/6.%20Routing%20Approaches%20I/#failed-links","text":"Solution: Each route only has a finite Time to Live. Gets recharged by the periodic advertisements. If you don't get a periodic update, expire and remove route","title":"Failed Links"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/","text":"7. Routing Approaches II \u00b6 This note is the final lecture on routing, which will finish up distance-vector protocols, talk about Link-State protocols, switches, and spanning tree protocol. Review \u00b6 If you have valid routing state, does that mean the network will never drop any packets? Answer: No Routing does not ensure reliable delivery of packets between end hosts. Routing may be necessary, but is not sufficient Does \"no loops, no dead ends\" theorem only hold true for destination-based forwarding? Answer: No Same basic no loops or dead ends conditions generalizes to at least any othe rsystem that does deterministic forwarding based on fix packet headers (that is, it's not limited to destination-based routing) Routing occurs when a data packet arrives at a router and is sent out another port. Answer: False When a packet arrives, router forwards it to one of its neighbors. Forwarding occurs when a data packet arrives at a router and is sent out another port Finishing up Distance-Vector \u00b6 From BF to DV \u00b6 We refined our update rule, we resolved some wacky problems with split horizon, we ensured that we eventually converge instead of counting to infinity, we made it robust to packet drops/ordering by advertising periodically, we saw that we can adapt to new links easily, we can identify failed links and dead routes by missing advertisements. Solution to Failed Links: Poison \u00b6 Failed links become a big problem because you have to wait a long time for the TTL to expire all the way through. Key idea: instead of not advertising a route, actively advertise that you don't have a route. Do this by advertising an impossibly high cost (a poison route) The poison route will propagate like other routes, poisoning the entry on any other router that was using it. It can be much faster than waiting for timeouts. And this doesn't just work for timed advertisements. If you get a poison advertisement and it changes your table, it will trigger you to send poison so it propagates dead routes as fast as they can reach and be processed by neighbor. Can be much, much faster than waiting for timeouts Besides expired routers, we also did not advertise when split horizon happens. In split horizon, we had a route but chose not to advertise. Don't want to advertise a route back to router that advertised it to us! Can lead to sending things bacwards (or even looping) Instead of not advertising in this case, advertise infinite cost. We call this poison reverse. In both cases (poisoning and poison reverse), without poisoning, you would not have sent a route. Instead, send an explicitly terrible route (any other route will be bettter), and never forward using these terrible infinite-length routes. More Triggers \u00b6 We know that our table changing should trigger us to send an update. Can be useful to handle other events too Sometimes we can detect when a link becomes available. Immediately send new neighbor advertisements, no need to wait for timer Sometimes we can detect when a link fails. Immediately poison all table entries using that link. If there are any, advertise the newly poisoned ones Summing Up Distance-Vector \u00b6 We now add to our list at the beginning: we can converge faster by explicitly signaling the absence of a route, we can adapte more quickly by advertising when \"triggered\" by events. This is now a pretty good routing protocol! Link-State Routing \u00b6 Another major class of routing protocols: Link-State routing. It is newer than Distance-Vector. It is also very common to use as an Interior Gateway Protocol. Two major Examples: 1. IS-IS (Intermediate System to Intermediate System) 2. OSPF (Open Shortest Path First): used at Berkeley DV vs. LS \u00b6 DV: Uses Global computation (it's distributed across all nodes) using local data (from just itself and its neighbors) LS: Uses local computation using global data (from all parts of the network) Global Data \u00b6 Global data is the state of every link in the network. It is up? What is the cost? It contains information about: the state of links and the destinations. We use this info to build a complete map (global view) of topology. If a router had global view, could easily comput paths Every router: Gets the state of all links and location of all destinations Uses that global information to build full graph Finds paths from itself to every destination on graph Uses the second hop in those paths to populate its forwarding table How to Find Paths? \u00b6 Each router has the complete tpology; can basically do it however it wants! For least-cost routes, this is called Single Source Shortest Path (SSSP) Some obvious algorithm choices: Bellman-Ford algorithm -- serial version -- \\(O(|E||V|)\\) Dijkstra's algorithm -- \\(O(|E| + |V|\\log |V|)\\) Breadth First Search (hop count only) -- \\(O(|E| + |V|)\\) Dynamic shortest path algorithms -- time complexity varies Approximate shortest path algorithms -- various Parallel SSSP algorithms But there is nothing that says you need to do least-cost routing! Populating Tables \u00b6 Important: Remember, each router can only influence its own next hop. Other routers must be coming up with paths which are \"compatible\". It is pretty easy for least-cost routing if: Minimizing the same cost All costs are > 0 All routers agree on topology Given all those, don't even need to implement same exact algorithm (e.g., bread ties exactly the same) How Do We Share Info Globally \u00b6 All routers need info about all links between all routers, and all destinations. Every router must: Find out who its neighbors are Tell everyone about its neighbors (i.e., its links to them) Tell everyone else about any adjacent destinations Finding Your Neighbors \u00b6 How do people do this? They introduce themselves. Routers periodically send hello messages to neighbors. If a neighbor goes quiet, eventually assume they're gone Telling Neighbors: Flooding \u00b6 Exchanging hellos tells you who your neighbors are (local info), but we need to know who everyone's neighbors are! The solution is called flooding. Strawman solution: When local information changes, send to all neighbors. When you receive info packet from neighbor, send to all other neighbors Does this always work? What happens if there is a loop? It will go on forever... Two loops make exponential growth of information Naive solution doesn't work when topology has loops. Solution? When local information changes, send to all neighbors. When you receive info packet from neighbor, send to all other neighbors (add on to the statement, unless you've already seen this info packet, in which case, drop it) How do you know if it is the first time you've seen it? Easy solution: routers put a sequence number in their updates. Every router has its own sequence number When it sends a routing message, it puts it in the packet, and then increments it Every router tracks largest sequence number seen from every other router If it sees an update with a smaller/equal sequence number, the update is old -- drop it If it sees an update with a larger sequence number, the update is new, remember the sequence number and flood update to all other neighbors If we used this protocol as an EGP? Scaling is not really that good How do you make flooding reliable? Periodically resend it (same old trick) IS-IS and OSPF both do this But do more clever stuff too: delivers reliability faster without resending more often, but we won't explore this in detail in context of LS Tell Everyone Else About Adjacent Destinations \u00b6 By flooding iinfo about destinations too (e.g., static routes) Flood info about destinations using same flooding mechanism you use to share information about router topology Link State Convergence \u00b6 Using plain non-parallel Dijkstra's algorithm. Dijkstra's will never find a looping path, so we never have loops in Link-State protocols... is this true? No! We only have control of our own next hop! If routers don't have same global view of topology, all bets are off! Sources of convergence delay: 1. Time to detect failure 2. Time to flood link-state information (proportional to network diameter) 3. Time to re-compute paths/tables Problems during convergence period: 1. Deadends 2. Looping packets 3. Out-of-order packets reaching the destination (should not cause semantic problems, but can create performance problems! We will see why later) Timeline for Local Failure \u00b6 Failure not detected: packets sent into dead link (dropped) Detected, not recomputed: deadends Detected, computed, not globally notified/computed: could be loops As nodes become aware, routers may change. Continued loopings, and possible reorderings. Link State Summary \u00b6 Link state is super simple conceptually: Everyone floods link/destination information Everyone then has global map of network Everyone independently computes next hops All the complexity is in the details Learning Switches and Spanning Tree Protocol \u00b6 Learning Switches \u00b6 We've been looking at DV and LS protocols: Tables filled in by ongoing routing process Are seeded with static routes for destinations Very common for routing at the network layer (L3), like for IP addresses Let's look at a very different approach to filling in our tables! Learning switches: Tables filled in opportunistically using data packets (assume there is a path to B from A, so then flood it to the neighbors) No seeding with static entries required Very common for routing at the link layer (L2). many people would say it is not routing. Rather than dropping the packet, it will opportunistically flood the packet to its neighbors, while updating a table saying it got it from the source. Now, if B replies to A, then the table is filled in and we don't have to flood! It breaks down if you have a loop... Major problem: floods when destination is unknown, floods have problems when topology has loops. The previous solution doesn't work in this case, but we will come back to it later. The decision to flood is done on a switch-by-switch basis... packets are not purely flooded or purely point-to-point throughout their lifetimes. Instead at each switch, packets are sent out correct port if table entry exists, or flooded out all ports (except incoming) if not.","title":"7. Routing Approaches II"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#7-routing-approaches-ii","text":"This note is the final lecture on routing, which will finish up distance-vector protocols, talk about Link-State protocols, switches, and spanning tree protocol.","title":"7. Routing Approaches II"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#review","text":"If you have valid routing state, does that mean the network will never drop any packets? Answer: No Routing does not ensure reliable delivery of packets between end hosts. Routing may be necessary, but is not sufficient Does \"no loops, no dead ends\" theorem only hold true for destination-based forwarding? Answer: No Same basic no loops or dead ends conditions generalizes to at least any othe rsystem that does deterministic forwarding based on fix packet headers (that is, it's not limited to destination-based routing) Routing occurs when a data packet arrives at a router and is sent out another port. Answer: False When a packet arrives, router forwards it to one of its neighbors. Forwarding occurs when a data packet arrives at a router and is sent out another port","title":"Review"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#finishing-up-distance-vector","text":"","title":"Finishing up Distance-Vector"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#from-bf-to-dv","text":"We refined our update rule, we resolved some wacky problems with split horizon, we ensured that we eventually converge instead of counting to infinity, we made it robust to packet drops/ordering by advertising periodically, we saw that we can adapt to new links easily, we can identify failed links and dead routes by missing advertisements.","title":"From BF to DV"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#solution-to-failed-links-poison","text":"Failed links become a big problem because you have to wait a long time for the TTL to expire all the way through. Key idea: instead of not advertising a route, actively advertise that you don't have a route. Do this by advertising an impossibly high cost (a poison route) The poison route will propagate like other routes, poisoning the entry on any other router that was using it. It can be much faster than waiting for timeouts. And this doesn't just work for timed advertisements. If you get a poison advertisement and it changes your table, it will trigger you to send poison so it propagates dead routes as fast as they can reach and be processed by neighbor. Can be much, much faster than waiting for timeouts Besides expired routers, we also did not advertise when split horizon happens. In split horizon, we had a route but chose not to advertise. Don't want to advertise a route back to router that advertised it to us! Can lead to sending things bacwards (or even looping) Instead of not advertising in this case, advertise infinite cost. We call this poison reverse. In both cases (poisoning and poison reverse), without poisoning, you would not have sent a route. Instead, send an explicitly terrible route (any other route will be bettter), and never forward using these terrible infinite-length routes.","title":"Solution to Failed Links: Poison"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#more-triggers","text":"We know that our table changing should trigger us to send an update. Can be useful to handle other events too Sometimes we can detect when a link becomes available. Immediately send new neighbor advertisements, no need to wait for timer Sometimes we can detect when a link fails. Immediately poison all table entries using that link. If there are any, advertise the newly poisoned ones","title":"More Triggers"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#summing-up-distance-vector","text":"We now add to our list at the beginning: we can converge faster by explicitly signaling the absence of a route, we can adapte more quickly by advertising when \"triggered\" by events. This is now a pretty good routing protocol!","title":"Summing Up Distance-Vector"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#link-state-routing","text":"Another major class of routing protocols: Link-State routing. It is newer than Distance-Vector. It is also very common to use as an Interior Gateway Protocol. Two major Examples: 1. IS-IS (Intermediate System to Intermediate System) 2. OSPF (Open Shortest Path First): used at Berkeley","title":"Link-State Routing"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#dv-vs-ls","text":"DV: Uses Global computation (it's distributed across all nodes) using local data (from just itself and its neighbors) LS: Uses local computation using global data (from all parts of the network)","title":"DV vs. LS"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#global-data","text":"Global data is the state of every link in the network. It is up? What is the cost? It contains information about: the state of links and the destinations. We use this info to build a complete map (global view) of topology. If a router had global view, could easily comput paths Every router: Gets the state of all links and location of all destinations Uses that global information to build full graph Finds paths from itself to every destination on graph Uses the second hop in those paths to populate its forwarding table","title":"Global Data"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#how-to-find-paths","text":"Each router has the complete tpology; can basically do it however it wants! For least-cost routes, this is called Single Source Shortest Path (SSSP) Some obvious algorithm choices: Bellman-Ford algorithm -- serial version -- \\(O(|E||V|)\\) Dijkstra's algorithm -- \\(O(|E| + |V|\\log |V|)\\) Breadth First Search (hop count only) -- \\(O(|E| + |V|)\\) Dynamic shortest path algorithms -- time complexity varies Approximate shortest path algorithms -- various Parallel SSSP algorithms But there is nothing that says you need to do least-cost routing!","title":"How to Find Paths?"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#populating-tables","text":"Important: Remember, each router can only influence its own next hop. Other routers must be coming up with paths which are \"compatible\". It is pretty easy for least-cost routing if: Minimizing the same cost All costs are > 0 All routers agree on topology Given all those, don't even need to implement same exact algorithm (e.g., bread ties exactly the same)","title":"Populating Tables"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#how-do-we-share-info-globally","text":"All routers need info about all links between all routers, and all destinations. Every router must: Find out who its neighbors are Tell everyone about its neighbors (i.e., its links to them) Tell everyone else about any adjacent destinations","title":"How Do We Share Info Globally"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#finding-your-neighbors","text":"How do people do this? They introduce themselves. Routers periodically send hello messages to neighbors. If a neighbor goes quiet, eventually assume they're gone","title":"Finding Your Neighbors"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#telling-neighbors-flooding","text":"Exchanging hellos tells you who your neighbors are (local info), but we need to know who everyone's neighbors are! The solution is called flooding. Strawman solution: When local information changes, send to all neighbors. When you receive info packet from neighbor, send to all other neighbors Does this always work? What happens if there is a loop? It will go on forever... Two loops make exponential growth of information Naive solution doesn't work when topology has loops. Solution? When local information changes, send to all neighbors. When you receive info packet from neighbor, send to all other neighbors (add on to the statement, unless you've already seen this info packet, in which case, drop it) How do you know if it is the first time you've seen it? Easy solution: routers put a sequence number in their updates. Every router has its own sequence number When it sends a routing message, it puts it in the packet, and then increments it Every router tracks largest sequence number seen from every other router If it sees an update with a smaller/equal sequence number, the update is old -- drop it If it sees an update with a larger sequence number, the update is new, remember the sequence number and flood update to all other neighbors If we used this protocol as an EGP? Scaling is not really that good How do you make flooding reliable? Periodically resend it (same old trick) IS-IS and OSPF both do this But do more clever stuff too: delivers reliability faster without resending more often, but we won't explore this in detail in context of LS","title":"Telling Neighbors: Flooding"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#tell-everyone-else-about-adjacent-destinations","text":"By flooding iinfo about destinations too (e.g., static routes) Flood info about destinations using same flooding mechanism you use to share information about router topology","title":"Tell Everyone Else About Adjacent Destinations"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#link-state-convergence","text":"Using plain non-parallel Dijkstra's algorithm. Dijkstra's will never find a looping path, so we never have loops in Link-State protocols... is this true? No! We only have control of our own next hop! If routers don't have same global view of topology, all bets are off! Sources of convergence delay: 1. Time to detect failure 2. Time to flood link-state information (proportional to network diameter) 3. Time to re-compute paths/tables Problems during convergence period: 1. Deadends 2. Looping packets 3. Out-of-order packets reaching the destination (should not cause semantic problems, but can create performance problems! We will see why later)","title":"Link State Convergence"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#timeline-for-local-failure","text":"Failure not detected: packets sent into dead link (dropped) Detected, not recomputed: deadends Detected, computed, not globally notified/computed: could be loops As nodes become aware, routers may change. Continued loopings, and possible reorderings.","title":"Timeline for Local Failure"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#link-state-summary","text":"Link state is super simple conceptually: Everyone floods link/destination information Everyone then has global map of network Everyone independently computes next hops All the complexity is in the details","title":"Link State Summary"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#learning-switches-and-spanning-tree-protocol","text":"","title":"Learning Switches and Spanning Tree Protocol"},{"location":"EECS/CS%20168/Lectures/Routing/7.%20Routing%20Approaches%20II/#learning-switches","text":"We've been looking at DV and LS protocols: Tables filled in by ongoing routing process Are seeded with static routes for destinations Very common for routing at the network layer (L3), like for IP addresses Let's look at a very different approach to filling in our tables! Learning switches: Tables filled in opportunistically using data packets (assume there is a path to B from A, so then flood it to the neighbors) No seeding with static entries required Very common for routing at the link layer (L2). many people would say it is not routing. Rather than dropping the packet, it will opportunistically flood the packet to its neighbors, while updating a table saying it got it from the source. Now, if B replies to A, then the table is filled in and we don't have to flood! It breaks down if you have a loop... Major problem: floods when destination is unknown, floods have problems when topology has loops. The previous solution doesn't work in this case, but we will come back to it later. The decision to flood is done on a switch-by-switch basis... packets are not purely flooded or purely point-to-point throughout their lifetimes. Instead at each switch, packets are sent out correct port if table entry exists, or flooded out all ports (except incoming) if not.","title":"Learning Switches"},{"location":"EECS/CS%2061A/0.%20Introduction%20to%20CS%2061A/","text":"0. Introduction \u00b6 Welcome to CS61A! My name is Matthew Dharmawan, and I want to create these notes/videos/etc. as a means to help you all succeed in this class. I took CS61A in Fall 2021, and I thoroughly enjoyed this class. It actually was my second experiece in programming (if you count AP Computer Science Principles). About this Course \u00b6 You'll primarily learn two skills from this course. How to read code and write it yourself. Now this class uses Python and Scheme as two programming languages to learn, but unlike learning languages like Spanish, French, etc., once you learn one and are comfortable with handling code in one language, learning another will only require a few days work. How to approach difficult problems. Now when I took this course, I was surprised to find how difficult some of the problems were throughout the semester; the midterm and final problems were especially super challenging. One thing that I really like how this course runs is that you'll see how to approach these complicated problems. Along the way, you will gain essential problem-solving skills that you will carry in your toolbox. The Purpose of These Notes \u00b6 Now my main priority here is to focus on being able to gain problem-solving skills necessary for not only this class, but future EE/CS classes you'll take in later semesters. What that means is I will approach looking at problems from your perspective, a student who may be looking at these problems for the first or second time. I do know that I am not alone in achieving this goal, and I know that other students have done something similar to these notes. These notes are just another resource for you to use. With that said, I hope that you will takeaway some important skills by going throught any resource from Instructors, TAs, Tutors, Academic Interns. I'll be sure to share the resources I found helpful when I took this class when we get to those topics. Overview \u00b6 I think that giving you all a high-level overview of what is to come in this course will allow you to understand the bigger picture of this course. You can read through what I have to say below (or not), but I hope that reading through this will give you excitement and motivation to learn and see how each of these different topics fit together. Once you come to understand the topics more, you'll appreciate reading this overview again to see how far you have come in your Computer Science journey. The overview is how I plan to continue these notes. We will start with the tools you will be using: Python and your Terminal. Getting to know how to use it and getting a general workflow in running your programs will basically be what you will be doing in this class all the time, so getting used to basic Python syntax and basic terminal commands is a good start. Variables, Expressions, and Functions: I like to think of programming as like math -- there are certain rules you must follow and also a strict way of evaluating the rules. In addition, there are ways to generalize concepts and abstract the nitty-gritty of things. For example, variables can be used and referenced again and again; functions can be called again and again without repeating yourself too much. Functions are just like those in math -- they take in parameters, operate on them, and then (possibly) spit out an answer. Unlike in math, functions in code can be any series of steps that can repeat itself, call other functions, and they don't have to evaluate to just numbers (or anything at all)! Control: Of course, your code won't always be read line by line. What happens if you want to do the same operation 500 times? Are you going to just copy-paste it 500 times? No! How about if your program depends on if a condition is met? Well, control will help you break away from sequential reading of your code and add in the ideas of iteration and selection. Higher-Order Functions: At this point, you'll be used to implementing some functions using control and what you already know. However, we can take it one step further... remember when I said functions take in parameters? What if those paramaters are functions? What if the function returns a different function? And why is doing this useful at all? Environment Diagrams: Now the implementation of code that you are writing is getting more and more complex. What an environment diagram does is that it helps you visualize what is going on in your program and allows you to see what variables functions can and cannot see. We will be revisiting this topic a couple of times throughout this course. Recursion: When I first learned recursion it didn't make sense. It never really started clicking until after midterm 2... when most of the exam was... recursion... I didn't do too well on that midterm. But now I understand it pretty well. So what is recursion? It is basically this idea that you might not know the answer immediately, so what if you ask that same question again to someone else but for a simpler case? Well they still might not know it, so ask it again to another person. At some point someone will know the answer because the input is so simple. Now that person will tell the person their answer, so that the answer can be combined to form the answer for that person, who tells it to the person who asked them... until it reaches you, and then you can create the answer. Why this topic is always a hard topic is that you basically call the function inside itself, and you have to trust that it will give you the right answer. Recursion will be a topic that will appear a lot on this course, so you will be hopefully good at it by the end of this course. Containers: You know some basic types in Python, such as strings, int, booleans, but now we want to store these values into more complicated structures. Here, we will discuss some important containers -- lists, tuples, dictionaries, as well as some operations we can perform on containers that will help us solve more problems. Mutability: Containers are definitely more complicated than a single entity, and there might be cases when we need to add new values to our containers, remove some. Mutability is the concept of mutating these containers. However, there are some containers that are immutable. Object-Oriented Programming: One can think of the container as an object. What is an object in Computer Science? It is something that holds data. Object-Oriented Programming (OOP) is organizes code to be all about the data, and the methods that operate on them. This is opposed to the organization of code to be functions and logic that you have been doing from the beginning. Trees and Linked Lists: OOP is great because it allows us to solve really complex problems. A specific data structure that you will learn here are the Trees and the Linked Lists. These are two specific types of objects that allow you to solve a ton of problems. There is a lot of recursion happening here, and it is a huge topic in this class and for future classes too (like CS 61B) Iterators and Generators: Maybe you have written so many functions using a for loop. Let's analyze the syntax of a for loop and understand that it iterates over somethng that is iterable. An iterator is an iterable, and a generator is an iterator. The best part about the generator is that you can define the generator to be anything you want, and we can iterate over that generator. Iterators and Generators are not too terrible to understand, but they do have their trickiness associated with it. Efficiency: How fast are the programs that you create? Is there a way to quantify the speed of your program? Efficiency is a topic that comes up a lot in CS, and you'll see it in almost every CS class you'll take. I will introduce the concept of Efficiency here. Scheme: Now it's time to move on to the second half of the course, also conveniently the second half of the course name: The Interpretation. In order to do this, you'll first have to learn the Scheme language. The Scheme language is not really a used language in today's world, but you will learn how to use it for the purpose of the end of this class. Interpreters: Did you know that Python is an interpreted language? That means the text of Python is read by the C language, and then the C language creates the necessary components to run your program (then C is compiled into an assembly language, then machine code). Now what you will learn is how to create an interpreter of the Scheme language using Python. How do you know what to read in Scheme and how do you break down the syntax of Scheme and create the necessary Python components to run the code? Regex: We are now moving on to a different type of programming called declarative programming. We've discussed functional programming and object-oriented programming. Declarative programming is all about just stating what you want, without really any regards to how the internals really work. In this case, we will be trying to create a grammar that can read strings and code. Regex is a tool that is used to match text; when you use CTRL+F, the words you type in are kind of like regex! SQL: Here is another programming language that you will be introduced to that is also declarative. When you store information in a database, how can you retrieve that information. What if you want to retrieve data that has a specific attribute to it? SQL is the language to do that.","title":"0. Introduction"},{"location":"EECS/CS%2061A/0.%20Introduction%20to%20CS%2061A/#0-introduction","text":"Welcome to CS61A! My name is Matthew Dharmawan, and I want to create these notes/videos/etc. as a means to help you all succeed in this class. I took CS61A in Fall 2021, and I thoroughly enjoyed this class. It actually was my second experiece in programming (if you count AP Computer Science Principles).","title":"0. Introduction"},{"location":"EECS/CS%2061A/0.%20Introduction%20to%20CS%2061A/#about-this-course","text":"You'll primarily learn two skills from this course. How to read code and write it yourself. Now this class uses Python and Scheme as two programming languages to learn, but unlike learning languages like Spanish, French, etc., once you learn one and are comfortable with handling code in one language, learning another will only require a few days work. How to approach difficult problems. Now when I took this course, I was surprised to find how difficult some of the problems were throughout the semester; the midterm and final problems were especially super challenging. One thing that I really like how this course runs is that you'll see how to approach these complicated problems. Along the way, you will gain essential problem-solving skills that you will carry in your toolbox.","title":"About this Course"},{"location":"EECS/CS%2061A/0.%20Introduction%20to%20CS%2061A/#the-purpose-of-these-notes","text":"Now my main priority here is to focus on being able to gain problem-solving skills necessary for not only this class, but future EE/CS classes you'll take in later semesters. What that means is I will approach looking at problems from your perspective, a student who may be looking at these problems for the first or second time. I do know that I am not alone in achieving this goal, and I know that other students have done something similar to these notes. These notes are just another resource for you to use. With that said, I hope that you will takeaway some important skills by going throught any resource from Instructors, TAs, Tutors, Academic Interns. I'll be sure to share the resources I found helpful when I took this class when we get to those topics.","title":"The Purpose of These Notes"},{"location":"EECS/CS%2061A/0.%20Introduction%20to%20CS%2061A/#overview","text":"I think that giving you all a high-level overview of what is to come in this course will allow you to understand the bigger picture of this course. You can read through what I have to say below (or not), but I hope that reading through this will give you excitement and motivation to learn and see how each of these different topics fit together. Once you come to understand the topics more, you'll appreciate reading this overview again to see how far you have come in your Computer Science journey. The overview is how I plan to continue these notes. We will start with the tools you will be using: Python and your Terminal. Getting to know how to use it and getting a general workflow in running your programs will basically be what you will be doing in this class all the time, so getting used to basic Python syntax and basic terminal commands is a good start. Variables, Expressions, and Functions: I like to think of programming as like math -- there are certain rules you must follow and also a strict way of evaluating the rules. In addition, there are ways to generalize concepts and abstract the nitty-gritty of things. For example, variables can be used and referenced again and again; functions can be called again and again without repeating yourself too much. Functions are just like those in math -- they take in parameters, operate on them, and then (possibly) spit out an answer. Unlike in math, functions in code can be any series of steps that can repeat itself, call other functions, and they don't have to evaluate to just numbers (or anything at all)! Control: Of course, your code won't always be read line by line. What happens if you want to do the same operation 500 times? Are you going to just copy-paste it 500 times? No! How about if your program depends on if a condition is met? Well, control will help you break away from sequential reading of your code and add in the ideas of iteration and selection. Higher-Order Functions: At this point, you'll be used to implementing some functions using control and what you already know. However, we can take it one step further... remember when I said functions take in parameters? What if those paramaters are functions? What if the function returns a different function? And why is doing this useful at all? Environment Diagrams: Now the implementation of code that you are writing is getting more and more complex. What an environment diagram does is that it helps you visualize what is going on in your program and allows you to see what variables functions can and cannot see. We will be revisiting this topic a couple of times throughout this course. Recursion: When I first learned recursion it didn't make sense. It never really started clicking until after midterm 2... when most of the exam was... recursion... I didn't do too well on that midterm. But now I understand it pretty well. So what is recursion? It is basically this idea that you might not know the answer immediately, so what if you ask that same question again to someone else but for a simpler case? Well they still might not know it, so ask it again to another person. At some point someone will know the answer because the input is so simple. Now that person will tell the person their answer, so that the answer can be combined to form the answer for that person, who tells it to the person who asked them... until it reaches you, and then you can create the answer. Why this topic is always a hard topic is that you basically call the function inside itself, and you have to trust that it will give you the right answer. Recursion will be a topic that will appear a lot on this course, so you will be hopefully good at it by the end of this course. Containers: You know some basic types in Python, such as strings, int, booleans, but now we want to store these values into more complicated structures. Here, we will discuss some important containers -- lists, tuples, dictionaries, as well as some operations we can perform on containers that will help us solve more problems. Mutability: Containers are definitely more complicated than a single entity, and there might be cases when we need to add new values to our containers, remove some. Mutability is the concept of mutating these containers. However, there are some containers that are immutable. Object-Oriented Programming: One can think of the container as an object. What is an object in Computer Science? It is something that holds data. Object-Oriented Programming (OOP) is organizes code to be all about the data, and the methods that operate on them. This is opposed to the organization of code to be functions and logic that you have been doing from the beginning. Trees and Linked Lists: OOP is great because it allows us to solve really complex problems. A specific data structure that you will learn here are the Trees and the Linked Lists. These are two specific types of objects that allow you to solve a ton of problems. There is a lot of recursion happening here, and it is a huge topic in this class and for future classes too (like CS 61B) Iterators and Generators: Maybe you have written so many functions using a for loop. Let's analyze the syntax of a for loop and understand that it iterates over somethng that is iterable. An iterator is an iterable, and a generator is an iterator. The best part about the generator is that you can define the generator to be anything you want, and we can iterate over that generator. Iterators and Generators are not too terrible to understand, but they do have their trickiness associated with it. Efficiency: How fast are the programs that you create? Is there a way to quantify the speed of your program? Efficiency is a topic that comes up a lot in CS, and you'll see it in almost every CS class you'll take. I will introduce the concept of Efficiency here. Scheme: Now it's time to move on to the second half of the course, also conveniently the second half of the course name: The Interpretation. In order to do this, you'll first have to learn the Scheme language. The Scheme language is not really a used language in today's world, but you will learn how to use it for the purpose of the end of this class. Interpreters: Did you know that Python is an interpreted language? That means the text of Python is read by the C language, and then the C language creates the necessary components to run your program (then C is compiled into an assembly language, then machine code). Now what you will learn is how to create an interpreter of the Scheme language using Python. How do you know what to read in Scheme and how do you break down the syntax of Scheme and create the necessary Python components to run the code? Regex: We are now moving on to a different type of programming called declarative programming. We've discussed functional programming and object-oriented programming. Declarative programming is all about just stating what you want, without really any regards to how the internals really work. In this case, we will be trying to create a grammar that can read strings and code. Regex is a tool that is used to match text; when you use CTRL+F, the words you type in are kind of like regex! SQL: Here is another programming language that you will be introduced to that is also declarative. When you store information in a database, how can you retrieve that information. What if you want to retrieve data that has a specific attribute to it? SQL is the language to do that.","title":"Overview"},{"location":"EECS/CS%2061A/1.%20Python%20Interpreter/","text":"1. Python Interpreter \u00b6 To start off with programming, you first need to get used to how Python works. Knowing how a language works is unique to each language (like the setup, syntax, etc.), but knowing how Python is handled and a general workflow of using the language is a great place to start. Get back to toc CS61A Here are the topics we will cover: 1.1 Expressions in the Terminal 1.2 Evaluation Procedure","title":"1. Python Interpreter"},{"location":"EECS/CS%2061A/1.%20Python%20Interpreter/#1-python-interpreter","text":"To start off with programming, you first need to get used to how Python works. Knowing how a language works is unique to each language (like the setup, syntax, etc.), but knowing how Python is handled and a general workflow of using the language is a great place to start. Get back to toc CS61A Here are the topics we will cover: 1.1 Expressions in the Terminal 1.2 Evaluation Procedure","title":"1. Python Interpreter"},{"location":"EECS/CS%2061A/1.1%20Expressions%20in%20the%20Terminal/","text":"1.1 Expressions in the Terminal \u00b6 This note introduces Python in your terminal, how it works at a high level as well as the general evaluation procedure. Get back to toc CS61A . Our Goal \u00b6 Our goal here is simple. Type code into the terminal, and see it execute your code. Later on in the course, you'll see exactly how one might go about interpreting the code you type in your terminal. This is the Interpretation of Computer Programs, but as of now, we are interested in gaining prerequisite knowledge to understand the Structure of Computer Programs. First, make sure you have Python on your system. Once you have it, continue reading on. Open up whatever terminal you use. You can activate what we call an interactive Python session through the command python3 . By interactive, I mean you can write code line-by-line and Python will read it as you put it in. You'll know if you are in a Python session if you see the triple greater than sign >>> . You can type in whatever mathematical expression you want (kind of like a more powerful calculator). Try putting some arithmetic expressions in the line and press ENTER. The result will be spit out on the line below, then Python will ask you for the next line. >>> 2 2 >>> 2 + 2 4 >>> 24 - 12 * 2 0 >>> You can exit out of a Python interactive session by typing in exit() on the input line. Summary \u00b6 Try some expressions out in your terminal. There are many nuances to things you'll learn in the class, and whenever you are confused, test it out by just typing python3 in your terminal. Next section 1.2 Evaluation Procedure Get back to 1. Python Interpreter or toc CS61A","title":"1.1 Expressions in the Terminal"},{"location":"EECS/CS%2061A/1.1%20Expressions%20in%20the%20Terminal/#11-expressions-in-the-terminal","text":"This note introduces Python in your terminal, how it works at a high level as well as the general evaluation procedure. Get back to toc CS61A .","title":"1.1 Expressions in the Terminal"},{"location":"EECS/CS%2061A/1.1%20Expressions%20in%20the%20Terminal/#our-goal","text":"Our goal here is simple. Type code into the terminal, and see it execute your code. Later on in the course, you'll see exactly how one might go about interpreting the code you type in your terminal. This is the Interpretation of Computer Programs, but as of now, we are interested in gaining prerequisite knowledge to understand the Structure of Computer Programs. First, make sure you have Python on your system. Once you have it, continue reading on. Open up whatever terminal you use. You can activate what we call an interactive Python session through the command python3 . By interactive, I mean you can write code line-by-line and Python will read it as you put it in. You'll know if you are in a Python session if you see the triple greater than sign >>> . You can type in whatever mathematical expression you want (kind of like a more powerful calculator). Try putting some arithmetic expressions in the line and press ENTER. The result will be spit out on the line below, then Python will ask you for the next line. >>> 2 2 >>> 2 + 2 4 >>> 24 - 12 * 2 0 >>> You can exit out of a Python interactive session by typing in exit() on the input line.","title":"Our Goal"},{"location":"EECS/CS%2061A/1.1%20Expressions%20in%20the%20Terminal/#summary","text":"Try some expressions out in your terminal. There are many nuances to things you'll learn in the class, and whenever you are confused, test it out by just typing python3 in your terminal. Next section 1.2 Evaluation Procedure Get back to 1. Python Interpreter or toc CS61A","title":"Summary"},{"location":"EECS/CS%2061A/1.2%20Evaluation%20Procedure/","text":"1.2 Evaluation Procedure \u00b6 This note expresses how to evaluate more complicated expressions, such as nested expressions. Get back to toc CS61A Expression Evaluation \u00b6 You can import modules in python with the import command. import add >>> add(2, 3) 5 You can also nest calls inside of another. from operator import add, mul >>> add(1, 1) 2 >>> mul(2, add(1, 1)) 4 You don't have to understand the from operator... line, but just know that is how we can use add and mul as functions. Now, we can get very complicated and ask Python do do something like add(3, 4, mul(3, add(2, 4, mul(4, mul(8, 2)))), 9) . How might we evaluate this expression? It might be easy for us to see what to do, but how would a computer look at something like this? Remember, must have a system to determine more complicated expressions like this. In fact there is one. You should get familiar with the following procedure for evaluating procedures Evaluate the Operator: By this, I mean making sure the operator exists and is defined. Evaluate the Operands: The arguments in the function must fully be evaluated first. If the argument is another operation, you have to finish this procedure fully on that subexpression before you continue on. Apply the Operator to the Operands: This is defined by whatever function. For add and mul , applying the operator to the operands just means doing the arithmetic operation. For other functions that we will create, it might involve more computation. As a quick example, let's go through this procedure with the expression add(mul(2, 3), add(1, 2)) Evaluate the operator: add is a function. Evaluate the operands: Ok, I see that the first subexpression evaluates to something I have to apply the procedure to first, Evaluate the operator: mul is a function Evaluate the operands: 2 is 2 and 3 is 3. Apply the operator to the operands: mul(2, 3) is 6. That was just the first operand, we evaluate the second operand through the procedure again 1. Evaluate the operator: add is a function 2. Evaluate the operands: 1 is 1 and 2 is 2 3. Apply the operator to the operands: add(1, 2) is 3 The second operand is fully evaluated, now we go on to the third step 3. Apply add(6, 3): this is 9, so the result of this whole expression is 9. I think you can see how this procedure goes with more complicated expressions, but this is a very important idea of execution. Summary \u00b6 One thing to take away is the evaluate of call expressions. You'll see this idea alot, such as in [[5. Environment Diagrams]], where we explore the idea in detail, and then in [[14. Interpreters]], where you will actually program this procedure. Go to next chapter: 2. Expressions, Variables, and Functions Get back to toc CS61A","title":"1.2 Evaluation Procedure"},{"location":"EECS/CS%2061A/1.2%20Evaluation%20Procedure/#12-evaluation-procedure","text":"This note expresses how to evaluate more complicated expressions, such as nested expressions. Get back to toc CS61A","title":"1.2 Evaluation Procedure"},{"location":"EECS/CS%2061A/1.2%20Evaluation%20Procedure/#expression-evaluation","text":"You can import modules in python with the import command. import add >>> add(2, 3) 5 You can also nest calls inside of another. from operator import add, mul >>> add(1, 1) 2 >>> mul(2, add(1, 1)) 4 You don't have to understand the from operator... line, but just know that is how we can use add and mul as functions. Now, we can get very complicated and ask Python do do something like add(3, 4, mul(3, add(2, 4, mul(4, mul(8, 2)))), 9) . How might we evaluate this expression? It might be easy for us to see what to do, but how would a computer look at something like this? Remember, must have a system to determine more complicated expressions like this. In fact there is one. You should get familiar with the following procedure for evaluating procedures Evaluate the Operator: By this, I mean making sure the operator exists and is defined. Evaluate the Operands: The arguments in the function must fully be evaluated first. If the argument is another operation, you have to finish this procedure fully on that subexpression before you continue on. Apply the Operator to the Operands: This is defined by whatever function. For add and mul , applying the operator to the operands just means doing the arithmetic operation. For other functions that we will create, it might involve more computation. As a quick example, let's go through this procedure with the expression add(mul(2, 3), add(1, 2)) Evaluate the operator: add is a function. Evaluate the operands: Ok, I see that the first subexpression evaluates to something I have to apply the procedure to first, Evaluate the operator: mul is a function Evaluate the operands: 2 is 2 and 3 is 3. Apply the operator to the operands: mul(2, 3) is 6. That was just the first operand, we evaluate the second operand through the procedure again 1. Evaluate the operator: add is a function 2. Evaluate the operands: 1 is 1 and 2 is 2 3. Apply the operator to the operands: add(1, 2) is 3 The second operand is fully evaluated, now we go on to the third step 3. Apply add(6, 3): this is 9, so the result of this whole expression is 9. I think you can see how this procedure goes with more complicated expressions, but this is a very important idea of execution.","title":"Expression Evaluation"},{"location":"EECS/CS%2061A/1.2%20Evaluation%20Procedure/#summary","text":"One thing to take away is the evaluate of call expressions. You'll see this idea alot, such as in [[5. Environment Diagrams]], where we explore the idea in detail, and then in [[14. Interpreters]], where you will actually program this procedure. Go to next chapter: 2. Expressions, Variables, and Functions Get back to toc CS61A","title":"Summary"},{"location":"EECS/CS%2061A/2.%20Expressions%2C%20Variables%2C%20and%20Functions/","text":"2. Expressions, Variables, and Functions \u00b6 At this point, you probably think programming is as good as a calculator; you can add, subtract, multiply, divide, etc. But it is more than that. This chapter focuses on seeing programs as more than just a fancy calculator, seeing how we can manipulate values stored in variables, and create functions that can operate on parameters and return a value based on some procedure. Then later, we will use the results from 3. Control to create even more complex functions, and then the rest of these set of notes is about creating functions that solves problems. Get back to toc CS61A . Here are the topics we will cover: 2.1 Expressions and Variables 2.2 Defining and Using Functions","title":"2. Expressions, Variables, and Functions"},{"location":"EECS/CS%2061A/2.%20Expressions%2C%20Variables%2C%20and%20Functions/#2-expressions-variables-and-functions","text":"At this point, you probably think programming is as good as a calculator; you can add, subtract, multiply, divide, etc. But it is more than that. This chapter focuses on seeing programs as more than just a fancy calculator, seeing how we can manipulate values stored in variables, and create functions that can operate on parameters and return a value based on some procedure. Then later, we will use the results from 3. Control to create even more complex functions, and then the rest of these set of notes is about creating functions that solves problems. Get back to toc CS61A . Here are the topics we will cover: 2.1 Expressions and Variables 2.2 Defining and Using Functions","title":"2. Expressions, Variables, and Functions"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/","text":"2.1 Expressions and Variables \u00b6 In this note, I introduce the concept of variables - how to visualize them, how to determine its value, parallel assignment, and more. Get back to 2. Expressions, Variables, and Functions or toc CS61A Anatomy of Variable Assignmnet \u00b6 In future notes, you'll be given complicated expressions that will be assigned to a variable, so you'll have to know how to break it down in to something systematic. The anatomy of variable assignment is the following: \\( \\(\\text{<var\\_name> = <expression>}\\) \\) where the \\(\\text{<var\\_name>}\\) is any name you give, such as x , y , first , last , etc., and \\(\\text{<expression>}\\) is anything that evaluates to something. A proper variable name must have the following attributes: 1. It cannot start with a number, but numbers can appear in the variable name. So 3badname is not a valid variable name, but g0odname3 is valid. 2. There may not be any spaces in the variable name. For example, first num is not valid, but first_num is valid. There are also conventions, which you don't necessarily have to follow, but in Python, the convention is to name the variables with snake case. Snake case refers to the style of writing in which each space is replaced by an underscore \\((\\_)\\) character, and the first letter of each word is written in lowercase. For example, snake_case is written in snake case. How to Determing a Variable's Value \u00b6 You might see later in the course that variables can be assigned to many different things instead of integers, strings, booleans, etc. In fact, we will learn how to assign functions to variable names in [[4. Higher Order Functions]]. Because of this, I think a systematic way to view variable assignment is important to know. Variable Assignment: Evaluate the right-hand side of the statement first Once you have the value, assign it to the name on the left hand side For example x = mul(2, 3, 5) + mul(4, add(2, 3)) One way I like to say this statement in my mind is \"the variable x is being assigned the value that is the result of mul(2, 3, 5) + mul(4, add(2, 3)) \". More generally, \"the variable named \\(\\text{<left\\_hand\\_side>}\\) is being assigned the value \\(\\text{<right\\_hand\\_side>}\\) \". Right now, it seems like all of this is super unnecessary, but when we get to later parts in the course, having this phrase in your mind will be helpful. Examples with Variable Assignment \u00b6 Let's look at the example below x = 5 y = x y = y + 3 x = y + x print(x) Our goal is to determine the value of x which will be printed out to the terminal. Here are two key parts about variable assignment: Values are copied, however it takes the snapshot of that value at that line as it is currently defined. Variables can be assigned based on the variable itself. Again you must view the assignment as \"the value on the right side, once fully evaluated, will be assigned ot the left side.\" Let's see how these two ideas play a role in this example. I'll go through it line-by-line. Line 1: x = 5 . We will keep that value stored in x until changed. So x is bound to the value 5 . Line 2: y = x . Here, we don't bind y to the value x . We instead bind y to the value that the variable x contains (slightly different wording), Therefore y is bound to 5 . Line 3: y = y + 3 . Remember the order of execution: Let's first evaluate the right side completely. Ok, that means it is y + 3 which is 5 + 3 = 8 . Therefore, the value y is being bound to the value 8 . Line 4: x = y + x . Same thing, what is the right side? We ask what the values of y and x are on that line, and we see y is 8 and x is 5. Therefore, 8 + 5 = 13 , and that is what is being bound to x . x is bound to the value 13 . Line 5: So we print out x , but that means we print out 13 . Things to takeaway from the example: The line y = y + 1 is a super common thing in computer science. Notice that this statement doesn't make any sense in mathematics, but it makes perfect sense in computer science. In fact, we use it so much, there are shorthands for this statement: y += 1 is equivalent to y = y + 1 , and yt += 10 is equivalent to t = t + 10 . Notice that we reveal the value that is contained in the variable when we reference it on the right side. However, we will quickly see in future notes like [[4. Higher Order Functions]] and [[5. Environment Diagrams]] that they will appear in very tricky ways through the idea of pointers. Strings \u00b6 Strings are also things we can apply operations to, except they are handled slightly different than integers. We will learn future operations on strings like slicing in [[7. Sequences]], but for now, you should know the following operations on strings. Adding two strings together will concatenate them together. In other words, you just join them together. \"hello\" + \"world\" = \"helloworld\" . See how spaces really matter in concatenation. Multiplying a string by a number will replicate the string. Just like how multiplication is just repeated addition, it follows exactly here. 3 * \"a\" = \"aaa\" . Another Variable Example \u00b6 I will be working through this example now x = \"abc\" y = \"def\" z = 1 z += 1 x = x + y z = z * x print(z) We are tasked with finding the result that gets printed, which is the variable z in the state of line 7. Line 1: x is bound to the string \"abc\" Line 2: y is bound to the string \"def\" Line 3: z is bound to the integer 1 Line 4: z is bound to the value z + 1 = 1 + 1 = 2 . z is bound to 2 now. Line 5: x is bound to the value x + y . Since x and y are strings, we concatenate them together to get the result \"abcdef\" . Now that the right side is evaluated, it is bound to the variable named x . Line 6: Let's evaluate the right side. z is currently 2 , and x is currently \"abcdef\" . If we replace the values on the right side, we get the expression 2 * \"abcdef\" , which results in \"abcdefabcdef\" . Now that the right side is evaluated completely, we will bind it to the variable name z . z is now bound to the string \"abcdefabcdef\" . Line 7: z is bound to the string \"abcdefabcdef\" so this is what gets printed. Quick Note on Errors and the str Function \u00b6 We now know two different types of variables, integers and strings. Now we know that multiplication of integers and strings exist, and addition of two strings exist, but an operation like an integer plus a string doesn't make sense. Because of that if you were to put a value like 1 + \"hi\" will lead the Python interpreter to give you an error, and the error message that pops up deals with something like TypeError: unsupported operator types(s) for +: 'int' and 'str' . When you progress to know different variable types, you may face an error like this. This means you tried to operate on two types where its operation is not defined. Maybe you wished that it would do something like 1 + \"hi\" = \"1hi\" . That seems reasonable. We can actually do such a thing by calling the str function on the integer. str will try to convert whatever gets passed in into a string, so x = str(1) results in x being bound to \"1\" rather than 1 . Now since it is a string type, we can add together two strings. Therefore, to do what we originally wanted, we need str(1) + \"hi\" to get \"1hi\" . There is also an int function that tries to convert the thing you pass into it into an int type. For example int(\"5\") returns the integer 5 , but str(5) returns the string \"5\" . Note the difference between these two. Parallel Assignment \u00b6 There is a nice shorthand that allows us to define more than one variable in the same line, and this is known as parallel assignment. Here is a quick example x, y = 1, 2 Here, x is bound to 1 , and y is bound to 2 . Notice that the order of the variable assignment matters. We also can do as many assignments in one line, such as a, b, c, d, e = 1, 2, 3, 4, 5 print(a, b, c, d, e) Where we will print 1 2 3 4 5 . This brings another problem: how does this deal with our idea of variable assignment, for example n = 10 m = 5 n, m = n - m, n + m which happens first? If the first set happened first, then n is now bound to 5 , and then since n is now 5 , m would be bound to 10 . If m was bound first, m would be 15 and n would be -5 . So which one is it? It is actually neither. They happen at the same time. Remember our phrase is to figure out what the right side is first, and then once we know everything about the right side, then we do assignment. In our case here if I were to figure out the values of the right side, they would be 5 and 15 . Finally assign these values to n and m , so n is bound to 5 and m is bound fo 15 . You can test your understanding of this section by figuring out the values of a , b , c , and d below a = 1 b, c = a + 2, a - 2 d = b + a a, b = d, d + c b = d - c Test this out in your terminal to see if you are correct! Summary \u00b6 In this note, we looked at how to deal with more complicated Python programs with variables. Variables are important because when we make more complicated programs, we would rather work in the general case of an arbitrary x value rather than a specific value. Variables are assigned with figuring out what the right side is first before you assign it to the variable named on the left. Parallel assignment follows this rule as well, however you can do multiple values in one line. Next note: 2.2 Defining and Using Functions Get back to 2. Expressions, Variables, and Functions or toc CS61A","title":"2.1 Expressions and Variables"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/#21-expressions-and-variables","text":"In this note, I introduce the concept of variables - how to visualize them, how to determine its value, parallel assignment, and more. Get back to 2. Expressions, Variables, and Functions or toc CS61A","title":"2.1 Expressions and Variables"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/#anatomy-of-variable-assignmnet","text":"In future notes, you'll be given complicated expressions that will be assigned to a variable, so you'll have to know how to break it down in to something systematic. The anatomy of variable assignment is the following: \\( \\(\\text{<var\\_name> = <expression>}\\) \\) where the \\(\\text{<var\\_name>}\\) is any name you give, such as x , y , first , last , etc., and \\(\\text{<expression>}\\) is anything that evaluates to something. A proper variable name must have the following attributes: 1. It cannot start with a number, but numbers can appear in the variable name. So 3badname is not a valid variable name, but g0odname3 is valid. 2. There may not be any spaces in the variable name. For example, first num is not valid, but first_num is valid. There are also conventions, which you don't necessarily have to follow, but in Python, the convention is to name the variables with snake case. Snake case refers to the style of writing in which each space is replaced by an underscore \\((\\_)\\) character, and the first letter of each word is written in lowercase. For example, snake_case is written in snake case.","title":"Anatomy of Variable Assignmnet"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/#how-to-determing-a-variables-value","text":"You might see later in the course that variables can be assigned to many different things instead of integers, strings, booleans, etc. In fact, we will learn how to assign functions to variable names in [[4. Higher Order Functions]]. Because of this, I think a systematic way to view variable assignment is important to know. Variable Assignment: Evaluate the right-hand side of the statement first Once you have the value, assign it to the name on the left hand side For example x = mul(2, 3, 5) + mul(4, add(2, 3)) One way I like to say this statement in my mind is \"the variable x is being assigned the value that is the result of mul(2, 3, 5) + mul(4, add(2, 3)) \". More generally, \"the variable named \\(\\text{<left\\_hand\\_side>}\\) is being assigned the value \\(\\text{<right\\_hand\\_side>}\\) \". Right now, it seems like all of this is super unnecessary, but when we get to later parts in the course, having this phrase in your mind will be helpful.","title":"How to Determing a Variable's Value"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/#examples-with-variable-assignment","text":"Let's look at the example below x = 5 y = x y = y + 3 x = y + x print(x) Our goal is to determine the value of x which will be printed out to the terminal. Here are two key parts about variable assignment: Values are copied, however it takes the snapshot of that value at that line as it is currently defined. Variables can be assigned based on the variable itself. Again you must view the assignment as \"the value on the right side, once fully evaluated, will be assigned ot the left side.\" Let's see how these two ideas play a role in this example. I'll go through it line-by-line. Line 1: x = 5 . We will keep that value stored in x until changed. So x is bound to the value 5 . Line 2: y = x . Here, we don't bind y to the value x . We instead bind y to the value that the variable x contains (slightly different wording), Therefore y is bound to 5 . Line 3: y = y + 3 . Remember the order of execution: Let's first evaluate the right side completely. Ok, that means it is y + 3 which is 5 + 3 = 8 . Therefore, the value y is being bound to the value 8 . Line 4: x = y + x . Same thing, what is the right side? We ask what the values of y and x are on that line, and we see y is 8 and x is 5. Therefore, 8 + 5 = 13 , and that is what is being bound to x . x is bound to the value 13 . Line 5: So we print out x , but that means we print out 13 . Things to takeaway from the example: The line y = y + 1 is a super common thing in computer science. Notice that this statement doesn't make any sense in mathematics, but it makes perfect sense in computer science. In fact, we use it so much, there are shorthands for this statement: y += 1 is equivalent to y = y + 1 , and yt += 10 is equivalent to t = t + 10 . Notice that we reveal the value that is contained in the variable when we reference it on the right side. However, we will quickly see in future notes like [[4. Higher Order Functions]] and [[5. Environment Diagrams]] that they will appear in very tricky ways through the idea of pointers.","title":"Examples with Variable Assignment"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/#strings","text":"Strings are also things we can apply operations to, except they are handled slightly different than integers. We will learn future operations on strings like slicing in [[7. Sequences]], but for now, you should know the following operations on strings. Adding two strings together will concatenate them together. In other words, you just join them together. \"hello\" + \"world\" = \"helloworld\" . See how spaces really matter in concatenation. Multiplying a string by a number will replicate the string. Just like how multiplication is just repeated addition, it follows exactly here. 3 * \"a\" = \"aaa\" .","title":"Strings"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/#another-variable-example","text":"I will be working through this example now x = \"abc\" y = \"def\" z = 1 z += 1 x = x + y z = z * x print(z) We are tasked with finding the result that gets printed, which is the variable z in the state of line 7. Line 1: x is bound to the string \"abc\" Line 2: y is bound to the string \"def\" Line 3: z is bound to the integer 1 Line 4: z is bound to the value z + 1 = 1 + 1 = 2 . z is bound to 2 now. Line 5: x is bound to the value x + y . Since x and y are strings, we concatenate them together to get the result \"abcdef\" . Now that the right side is evaluated, it is bound to the variable named x . Line 6: Let's evaluate the right side. z is currently 2 , and x is currently \"abcdef\" . If we replace the values on the right side, we get the expression 2 * \"abcdef\" , which results in \"abcdefabcdef\" . Now that the right side is evaluated completely, we will bind it to the variable name z . z is now bound to the string \"abcdefabcdef\" . Line 7: z is bound to the string \"abcdefabcdef\" so this is what gets printed.","title":"Another Variable Example"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/#quick-note-on-errors-and-the-str-function","text":"We now know two different types of variables, integers and strings. Now we know that multiplication of integers and strings exist, and addition of two strings exist, but an operation like an integer plus a string doesn't make sense. Because of that if you were to put a value like 1 + \"hi\" will lead the Python interpreter to give you an error, and the error message that pops up deals with something like TypeError: unsupported operator types(s) for +: 'int' and 'str' . When you progress to know different variable types, you may face an error like this. This means you tried to operate on two types where its operation is not defined. Maybe you wished that it would do something like 1 + \"hi\" = \"1hi\" . That seems reasonable. We can actually do such a thing by calling the str function on the integer. str will try to convert whatever gets passed in into a string, so x = str(1) results in x being bound to \"1\" rather than 1 . Now since it is a string type, we can add together two strings. Therefore, to do what we originally wanted, we need str(1) + \"hi\" to get \"1hi\" . There is also an int function that tries to convert the thing you pass into it into an int type. For example int(\"5\") returns the integer 5 , but str(5) returns the string \"5\" . Note the difference between these two.","title":"Quick Note on Errors and the str Function"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/#parallel-assignment","text":"There is a nice shorthand that allows us to define more than one variable in the same line, and this is known as parallel assignment. Here is a quick example x, y = 1, 2 Here, x is bound to 1 , and y is bound to 2 . Notice that the order of the variable assignment matters. We also can do as many assignments in one line, such as a, b, c, d, e = 1, 2, 3, 4, 5 print(a, b, c, d, e) Where we will print 1 2 3 4 5 . This brings another problem: how does this deal with our idea of variable assignment, for example n = 10 m = 5 n, m = n - m, n + m which happens first? If the first set happened first, then n is now bound to 5 , and then since n is now 5 , m would be bound to 10 . If m was bound first, m would be 15 and n would be -5 . So which one is it? It is actually neither. They happen at the same time. Remember our phrase is to figure out what the right side is first, and then once we know everything about the right side, then we do assignment. In our case here if I were to figure out the values of the right side, they would be 5 and 15 . Finally assign these values to n and m , so n is bound to 5 and m is bound fo 15 . You can test your understanding of this section by figuring out the values of a , b , c , and d below a = 1 b, c = a + 2, a - 2 d = b + a a, b = d, d + c b = d - c Test this out in your terminal to see if you are correct!","title":"Parallel Assignment"},{"location":"EECS/CS%2061A/2.1%20Expressions%20and%20Variables/#summary","text":"In this note, we looked at how to deal with more complicated Python programs with variables. Variables are important because when we make more complicated programs, we would rather work in the general case of an arbitrary x value rather than a specific value. Variables are assigned with figuring out what the right side is first before you assign it to the variable named on the left. Parallel assignment follows this rule as well, however you can do multiple values in one line. Next note: 2.2 Defining and Using Functions Get back to 2. Expressions, Variables, and Functions or toc CS61A","title":"Summary"},{"location":"EECS/CS%2061A/2.2%20Defining%20and%20Using%20Functions/","text":"2.2 Defining and Using Functions \u00b6 This note explains why we use functions, as well as how to create a function. Built-In Functions \u00b6 In our examples, we've used two functions that we can import into Python, such as add and mul . There are also built-in functions that don't require any import, such as print . Let's see what we can learn from these functions before we try to implement our own. A function, just like in math, takes a couple of variables, and spits out the result. If you've taken multivariable calculus, you know that functions have take in more than one variable, and also spit out more than one result. It is just like this with Python: I can put three parameters in to a function foo and it can spit out more than one result. add and mul are two functions that can accept any arbitrary amount of parameters, but will always result in one value to be returned. Things like add(1, 2, 3, 4, 5, 6, 7, 8, 9) takes in 9 values, but will alway return one integer value, namely 45 . This brings me to emphasize the following point: \\[\\text{Always note the input and output types.} \\] In our example above, the add takes in int s and it returns an int . Although this point seems very trivial, it is super, super important in analyzing more complicated functions that take in different types. Return Types \u00b6 Functions may return values, in the case of our add and mul functions, it returns an integer value. Other functions might not return anything at all. If that is the case, we say it returns None . None is another type, just like int s and str s. Specifically the word None is a NoneType . In Python, None is really nothing. You can try and input None into a Python session, and nothing will be spit out. It will just ask you for the next line to read. >>> None >>> Python print \u00b6 print is an odd function you encounter. Just type in >>> print(3) 3 and you might assume print takes in a type and spits out what was passed into it. This may seem like the case, and all the following examples seem to support this assumption: >>> print(\"Hello World\") Hello World >>> print(3 + 3, 4) 6 4 >>> print(None) None One quirk is that printing None actually will spit out None in the terminal (like the physical word None ), while just typing in None without any print over it spits out literally nothing. Also, note how printing strings removes the quotes that delimit it. Finally, print can take in as many parameters as needed like add and mul . It will separate the parameters with a space. But we never really know what a value returns unless we try variable assignment; take a guess at what happens with the code segment >>> x = print(3) 3 >>> print(x) What is the result of print(x) ? If you try this into a Python session, you'll be surprised that the line print(x) prints out None , just like the example above. Weird, but let's analyze this situation based on what we know so far. With any complicated segment of code, we should go through it line by line. Let's evaluate the right side first. Somehow it assigns the value None to the value x , since that is what appears in the next input line. Then why does it display 3 in the following line? Another clue is that variable assignment should never output something, unless something is up with the print function. I'll just straight up tell you that print does two things. Displays the value passed in to the user Returns None So then let's now analyze this line-by-line. Line 1: Evaluate the right hand side first. print(3) will display 3 in the terminal, then return None . Therefore, x is bound to the value None . We see 3 displayed in the terminal. Line 2: Lookup the vlaue of x . It is None , so we are really evaluating print(None) , which we have seen before. It prints None . print Nesting \u00b6 Let's go one step further. Figure out what is outputted with the following code segment: >>> print(print(1), print(print(2, 3))) You type it into a Python session, and you get the following result: >>> print(print(1), print(print(2, 3))) 1 2 3 None None None Now that was confusing! But let's again take it with what we know using our methods in 1.2 Evaluation Procedure . Evaluate operator: print is a built-in function, so we move on to step 2 Evaluate the operands. The first operand is another expression, so we have to evaluate it first. Evaluate operator: print is a built-in function Evaluate the operands: 1 evaluates to 1 . Apply the operator to the operands: we display 1 , then we return None , so that whole expression print(1) evaluates to None Now we evaluate the second argument. It's another procedure. 1. Evaluate operator: print is a built-in function 2. Evaluate operand: It's another procedure, so apply the evaluation procedure 1. Evaluate operator: print is a built-in function 2. Evaluate operands: each evaluate to 2 and 3 , respectively 3. Apply operator to operands: We display 2 3 to the output, but then return None . print(2, 3) evaluates to None 3. Apply operator to operands: We display the result of our computation, which is None , so we are really doing print(None) . That is what you see in the next line of the output. 3. Apply operator to operands: Both operands evaluate to None , so we really are doing print(None, None) , and that is what appears in the last line you see. The whole expression evaluates to None , but since we aren't printing that, it should just literally show nothing and ask for the next line. That was a difficult one! I'd recommend to try an pretend you are explaining this to an imaginary person to make sure you really understand what is going on. But the point of this exercise is to realize the importance of return types and evaluation procedure. As an extra practice, try to figure out the result of >>> from operator import add, mul >>> print(add(2, 3), print(2, mul(2, 3), print(1))) You can see if you are correct by testing it in a Python session. Anatomy of a Function \u00b6 Now it is time to create your own functions that do what you want. A function is composed of 3 main parts: A define statement followed by a name. Unlike variables, functions require special syntax and a name to go by. A set of parameters, each given a name to be known by. A body, which can contain one or more lines of code that are indented. If you've programmed in other languages, like Java, you've noticed that spacing doesn't really matter, as long as you separate segments of code with a semicolon and delimit multi-line code with curly braces. However, in Python, spacing matters. In our case, indenting your code is important. Here is an example function that follows the proper syntax: def square(x): return x * x y = square(3) print(y) And running the code in a .py file will print out 9 . Notice the body of the function is indented. We can put more than one line if we want to separate the steps. def square(x) number = x * x return number So you see we can define new variables inside the body of the function. Does this do anything different? Can I reference number outside of the function?The answer is no, but the explanation will be covered in [[4. Higher Order Functions]] and [[5. Environment Diagrams]]. For now, just assume that variables defined inside a function can only be accessed inside the function, but variables declared outside a function can be accessed inside a function. Again, once we get to the later chapters, you'll know a systematic way of knowing if you are allowed to reference variables inside or outside functions. The general form of a function definition is def <name>(<param_1>, <param_2>, ..., <param_n>): <body> You also don't have to have any parameters at all. Let's say you just want a function that returns a hardcoded value. You simply don't need to put anything in the parameter list. def hardcode_hello_world(): return \"Hello World\" print(hardcode_hello_world()) The last line will display Hello World , and you can try it yourself in a .py file. Functions that Return Nothing or More than One Value \u00b6 Let's say you want a function that returns nothing, like the print function. You can do this two ways: (1) don't include return , or (2) explicitly write return None . def do_nothing(): return None def do_nothing2(): x = \"hi\" Now, I wish I could really write nothing in the body of the function of do_nothing2 . but Python expects at least something in the body of any function. I just added a random line that does nothing since we never return that value. To return more than one value, simply separate them with a comma in the return statement. For example, if I wanted to return the positive and negative values of a number x that is passed in, I might write def pos_neg(x): return x, -x A new question arises: how do I store both these values at the same time? It is just like parallel assignment, as discussed in 2.1 Expressions and Variables . So I might try and write a, b = pos_neg(2) print(a) # Will print 2 print(b) # Will print -2 Summary \u00b6 Now you know how functions should work. They are just like multivariable functions in math: you can take in zero or more parameters, do some operations to them, and then return zero or more items. In the next chapter, we will make our functions more useful by introducing iteration and selection. Next chapter 3. Control .","title":"2.2 Defining and Using Functions"},{"location":"EECS/CS%2061A/2.2%20Defining%20and%20Using%20Functions/#22-defining-and-using-functions","text":"This note explains why we use functions, as well as how to create a function.","title":"2.2 Defining and Using Functions"},{"location":"EECS/CS%2061A/2.2%20Defining%20and%20Using%20Functions/#built-in-functions","text":"In our examples, we've used two functions that we can import into Python, such as add and mul . There are also built-in functions that don't require any import, such as print . Let's see what we can learn from these functions before we try to implement our own. A function, just like in math, takes a couple of variables, and spits out the result. If you've taken multivariable calculus, you know that functions have take in more than one variable, and also spit out more than one result. It is just like this with Python: I can put three parameters in to a function foo and it can spit out more than one result. add and mul are two functions that can accept any arbitrary amount of parameters, but will always result in one value to be returned. Things like add(1, 2, 3, 4, 5, 6, 7, 8, 9) takes in 9 values, but will alway return one integer value, namely 45 . This brings me to emphasize the following point: \\[\\text{Always note the input and output types.} \\] In our example above, the add takes in int s and it returns an int . Although this point seems very trivial, it is super, super important in analyzing more complicated functions that take in different types.","title":"Built-In Functions"},{"location":"EECS/CS%2061A/2.2%20Defining%20and%20Using%20Functions/#return-types","text":"Functions may return values, in the case of our add and mul functions, it returns an integer value. Other functions might not return anything at all. If that is the case, we say it returns None . None is another type, just like int s and str s. Specifically the word None is a NoneType . In Python, None is really nothing. You can try and input None into a Python session, and nothing will be spit out. It will just ask you for the next line to read. >>> None >>>","title":"Return Types"},{"location":"EECS/CS%2061A/2.2%20Defining%20and%20Using%20Functions/#python-print","text":"print is an odd function you encounter. Just type in >>> print(3) 3 and you might assume print takes in a type and spits out what was passed into it. This may seem like the case, and all the following examples seem to support this assumption: >>> print(\"Hello World\") Hello World >>> print(3 + 3, 4) 6 4 >>> print(None) None One quirk is that printing None actually will spit out None in the terminal (like the physical word None ), while just typing in None without any print over it spits out literally nothing. Also, note how printing strings removes the quotes that delimit it. Finally, print can take in as many parameters as needed like add and mul . It will separate the parameters with a space. But we never really know what a value returns unless we try variable assignment; take a guess at what happens with the code segment >>> x = print(3) 3 >>> print(x) What is the result of print(x) ? If you try this into a Python session, you'll be surprised that the line print(x) prints out None , just like the example above. Weird, but let's analyze this situation based on what we know so far. With any complicated segment of code, we should go through it line by line. Let's evaluate the right side first. Somehow it assigns the value None to the value x , since that is what appears in the next input line. Then why does it display 3 in the following line? Another clue is that variable assignment should never output something, unless something is up with the print function. I'll just straight up tell you that print does two things. Displays the value passed in to the user Returns None So then let's now analyze this line-by-line. Line 1: Evaluate the right hand side first. print(3) will display 3 in the terminal, then return None . Therefore, x is bound to the value None . We see 3 displayed in the terminal. Line 2: Lookup the vlaue of x . It is None , so we are really evaluating print(None) , which we have seen before. It prints None .","title":"Python print"},{"location":"EECS/CS%2061A/2.2%20Defining%20and%20Using%20Functions/#print-nesting","text":"Let's go one step further. Figure out what is outputted with the following code segment: >>> print(print(1), print(print(2, 3))) You type it into a Python session, and you get the following result: >>> print(print(1), print(print(2, 3))) 1 2 3 None None None Now that was confusing! But let's again take it with what we know using our methods in 1.2 Evaluation Procedure . Evaluate operator: print is a built-in function, so we move on to step 2 Evaluate the operands. The first operand is another expression, so we have to evaluate it first. Evaluate operator: print is a built-in function Evaluate the operands: 1 evaluates to 1 . Apply the operator to the operands: we display 1 , then we return None , so that whole expression print(1) evaluates to None Now we evaluate the second argument. It's another procedure. 1. Evaluate operator: print is a built-in function 2. Evaluate operand: It's another procedure, so apply the evaluation procedure 1. Evaluate operator: print is a built-in function 2. Evaluate operands: each evaluate to 2 and 3 , respectively 3. Apply operator to operands: We display 2 3 to the output, but then return None . print(2, 3) evaluates to None 3. Apply operator to operands: We display the result of our computation, which is None , so we are really doing print(None) . That is what you see in the next line of the output. 3. Apply operator to operands: Both operands evaluate to None , so we really are doing print(None, None) , and that is what appears in the last line you see. The whole expression evaluates to None , but since we aren't printing that, it should just literally show nothing and ask for the next line. That was a difficult one! I'd recommend to try an pretend you are explaining this to an imaginary person to make sure you really understand what is going on. But the point of this exercise is to realize the importance of return types and evaluation procedure. As an extra practice, try to figure out the result of >>> from operator import add, mul >>> print(add(2, 3), print(2, mul(2, 3), print(1))) You can see if you are correct by testing it in a Python session.","title":"print Nesting"},{"location":"EECS/CS%2061A/2.2%20Defining%20and%20Using%20Functions/#anatomy-of-a-function","text":"Now it is time to create your own functions that do what you want. A function is composed of 3 main parts: A define statement followed by a name. Unlike variables, functions require special syntax and a name to go by. A set of parameters, each given a name to be known by. A body, which can contain one or more lines of code that are indented. If you've programmed in other languages, like Java, you've noticed that spacing doesn't really matter, as long as you separate segments of code with a semicolon and delimit multi-line code with curly braces. However, in Python, spacing matters. In our case, indenting your code is important. Here is an example function that follows the proper syntax: def square(x): return x * x y = square(3) print(y) And running the code in a .py file will print out 9 . Notice the body of the function is indented. We can put more than one line if we want to separate the steps. def square(x) number = x * x return number So you see we can define new variables inside the body of the function. Does this do anything different? Can I reference number outside of the function?The answer is no, but the explanation will be covered in [[4. Higher Order Functions]] and [[5. Environment Diagrams]]. For now, just assume that variables defined inside a function can only be accessed inside the function, but variables declared outside a function can be accessed inside a function. Again, once we get to the later chapters, you'll know a systematic way of knowing if you are allowed to reference variables inside or outside functions. The general form of a function definition is def <name>(<param_1>, <param_2>, ..., <param_n>): <body> You also don't have to have any parameters at all. Let's say you just want a function that returns a hardcoded value. You simply don't need to put anything in the parameter list. def hardcode_hello_world(): return \"Hello World\" print(hardcode_hello_world()) The last line will display Hello World , and you can try it yourself in a .py file.","title":"Anatomy of a Function"},{"location":"EECS/CS%2061A/2.2%20Defining%20and%20Using%20Functions/#functions-that-return-nothing-or-more-than-one-value","text":"Let's say you want a function that returns nothing, like the print function. You can do this two ways: (1) don't include return , or (2) explicitly write return None . def do_nothing(): return None def do_nothing2(): x = \"hi\" Now, I wish I could really write nothing in the body of the function of do_nothing2 . but Python expects at least something in the body of any function. I just added a random line that does nothing since we never return that value. To return more than one value, simply separate them with a comma in the return statement. For example, if I wanted to return the positive and negative values of a number x that is passed in, I might write def pos_neg(x): return x, -x A new question arises: how do I store both these values at the same time? It is just like parallel assignment, as discussed in 2.1 Expressions and Variables . So I might try and write a, b = pos_neg(2) print(a) # Will print 2 print(b) # Will print -2","title":"Functions that Return Nothing or More than One Value"},{"location":"EECS/CS%2061A/2.2%20Defining%20and%20Using%20Functions/#summary","text":"Now you know how functions should work. They are just like multivariable functions in math: you can take in zero or more parameters, do some operations to them, and then return zero or more items. In the next chapter, we will make our functions more useful by introducing iteration and selection. Next chapter 3. Control .","title":"Summary"},{"location":"EECS/CS%2061A/3.%20Control/","text":"3. Control \u00b6 Now it is time to introduce ways of controlling our programs, rather than just sequential, line-by-line, reading of your code. Control allows us to implement functions that depend on values passed in. A consequence of this is that the problems we will face will become more difficult, so I will be sure to indicate problem-solving strategies that are critical to solving these problems. Sections that will be covered: 3.1 If, Elif, Else Clauses [[3.2 ]]","title":"3. Control"},{"location":"EECS/CS%2061A/3.%20Control/#3-control","text":"Now it is time to introduce ways of controlling our programs, rather than just sequential, line-by-line, reading of your code. Control allows us to implement functions that depend on values passed in. A consequence of this is that the problems we will face will become more difficult, so I will be sure to indicate problem-solving strategies that are critical to solving these problems. Sections that will be covered: 3.1 If, Elif, Else Clauses [[3.2 ]]","title":"3. Control"},{"location":"EECS/CS%2061A/3.1%20If%2C%20Elif%2C%20Else%20Clauses/","text":"3.1 If, Elif, Else Clauses \u00b6 In this note, I will discuss conditional statements, and how we can use them to control the execution of our program under specific conditions. Booleans \u00b6 Now it is time to introduce another variable type in programming. Just like int , str , and NoneType , we now have another type to analyze: bool (short for boolean). A bool is something that is true or false. There are really no other values that a bool can take on. However, other types can thought of as boolean-like types, for which we call them \"truthy\" or \"falsey\" values. Truthy and Falsey Values \u00b6 We assign truth values to each of the types we know so far, soon we will grow these items to include more types of objects. For now, I would remember these items: For an int type, every single number except 0 is truthy. So, 0 is false, and -10 is true. For a str type, only the empty string (written as \"\" ) is falsey, and every non-empty string is truthy. That means a string like \" \" is truthy since is it non-empty (there is a space between the quotes). None is falsey We can say the truth value explicitly with True and False . Of course, True is truthy and False if falsey. We will encounter other types of objects, however, a general rule is that an item is falsey if it is the empty for of that object, otherwise it is truthy. You can actually see if items are truthy and falsey by calling bool over the item you seek the truth of. For example, in your Python interpreter, you can write: >>> bool(4) True >>> bool(None) False >>> bool(\"\") False >>> bool(\" \") True >>> bool(0) False >>> bool(True) True Truthy values pop-up every once in a while, and these truthy values are specific to the Python language. When we look at the Scheme language, truthy values are slightly different. (In the language C, truthy values are also different, and the same is apparent in Java, Rust, Go, etc.). You'll have to briefly look at the coding language you use to see what is truthy and what is falsey. However, the above is what Python considers true and false. Logical Operators and Short Circuiting \u00b6 Sometimes, we rely on multiple conditions being truthy, and other times, we rely on only one of many possible conditions being truthy. Thus, logical operators are used to be the solution to this problem. Python's logical operators are the English words and , or , and not . (In other languages, you might see it as && , || , and ! , respectively). Logical statements in Python therefore reads like English. Logically, A and B requires both conditions A and B to be true. We can chain them together such as A and B and C and D and E to require A , B , C , D , and E to be true. If any of them are falsey values, the whole logical statement is falsey. A or B requires only one of the items to be truthy. A could be truthy and B could be falsey, it can appear vice versa, or A and B are truthy. Only when both entries are falsey does this logical operator become falsey. Like chaining and s together, we can chain or . A or B or C or D or E requires at least one of the 5 conditions to be truthy to be a truthy statement (there could be two, three, four, five truthy values, but as long as one of them are truthy, it doesn't really matter what the others are). It will be falsey only if all 5 conditions are falsey. not simply switches the truthy value of the item it is applied to. not True is falsey, and not False is truthy. However, there is something unique about logical operators. They actually return something (like a function) besides True and False . Let's investigate this behavior. Look at these two statements: >>> 0 or 5 5 >>> 0 and 5 0 It seems the or evaluated to the second item, and the and evaluated the first item. Let's also look at >>> 5 or 0 5 >>> 5 and 0 0 Now the or returned the first item, and the and returned the second item. Also, they return numbers! Let's look at some combination of int s and str s and NoneType s and bool s: >>> 5 and None and 3 >>> 3 or None or False 3 >>> None or 3 or 5 3 >>> None or False or 3 3 The first line evaluates to None , so you see nothing in the interpreter. But it seems like it returns a specific item. I'll just tell you what is happening here. This is called short-circuiting, and what happens is that if we already know the result of the logical statement, why do we need to evaluate even further? For example, the evaluation of 5 and None and 3 is already known once we see the None , and the return of 3 or None or False is already known when we see 3 . Here are the rules of short-circuiting and : Return the first falsey value. Otherwise, return the last item. or : Return the first truthy value. Otherwise, return the last item. You can see that and is like a mirror of or . Let me also say something about not not will change what ever it is being applied on to be the bool type True or False . The reason for the not working this way instead of evaluating to the type's truth counterpart is that things like not 0 is nonsensical to find a counterpart. Is the counterpart 1 , -1 , 100 ? Who knows? So we just change not 0 to True , and not \"hello\" to False . Let's run through some more examples of short-circuiting: Try these out and check your answers with your Python terminal. I'll explain it below. Some of the statements will give you a ZeroDivisionError , so keep track of those too. >>> 3 and 8 and 0 >>> 3 or 1/0 >>> \"\" or \".\" or \"\" >>> False and None >>> None or False >>> not True and not False We can combine both logical operators. You would need to make sure you simplify the expressions down as you see the parenthesis: >>> 3 or (4 and 0) >>> 3 and ((5 or 8) and (9 and None)) >>> 0 and (1/0 or 1/0 and 1/0) After you have seen the solutions, read the solutions I wrote here: 3 and 8 and 0 The rule here is to keep evaluating the next items until we reach the first falsey one. If all of them are truthy, we would then return the last item. We go through it one-by-one: 3 is truthy, 8 is truthy, 0 is falsey. This is the first falsey value, so we return 0 . 3 or 1/0 The rule here is to keep evaluating the next item until we reach the first truthy one. If all of them are falsey, return the last item. We just evaluate 3 since it is our first truthy value, so we return 3 . Note that 1/0 does not get read since we knew the result of the logical statement before we actually evaluated 1/0 . \"\" or \".\" or \"\" I'll start speeding up now. Since we are working with or , the first truthy value is \".\" , so we return '\".\"' False and None The first falsey value is False , so we return False . None or False All values are falsey, so we need to return the last item: False not True and not False . Each individual item becomes False and True . Since False is the first falsey value, it evaluates to False . Here are the solutions to the more involved compound logical statements: 3 or (4 and 0) . We only read the first item to find the first truthy value, so it is 3 . We don't even have to read the parenthetical expression. 3 and ((5 or 8) and (9 and None)) : 3 is truthy, now we need to evaluate the second item, which is (5 or 8) and (9 and None) . The first item of this subexpression, we need to evaluate. 5 or 8 evaluates to 5 , this is truthy, so we keep on going. 9 and None evaluates to None . Therefore, we are really trying to figure out 5 and None , which results in None . The main logical statement simplifies to 3 and None , which is None . 0 and (1/0 or 1/0 and 1/0) : 0 evaluates to falsey, so the whole statement results in 0 . Again, we do not have to evaluate all the 1/0 conditions because short-circuiting makes us stop once we know the answer. Relational Operators \u00b6 Relational operators evaluate to True or False . These are the actual bool types, not some alternative truthy/falsey values. A short list includes: < less than > greater than <= less than or equal to >= greater than or less than == equal. Note that it has to be double equals, since we already dedicated a single equals = to be variable assignment. A statement like 1 == 2 evaluates to False , and not 1 == 2 evaluates to True . Anatomy of if \u00b6 Now it's time to discuss the syntax of selection using the if clause. Similar to a function, you need 3 parts: the word if to indicate you are using selection conditional statement(s). Here is where you use your condition making, truthy/falsey, short-circuity logic a suite to execute in the case that your condition is true. This can be things like assigning a value to a variable, returning a value, or even putting another if clause there. In english, it might read as the following: \"if are met, then . If are not met, skip the and continue with what is next.\" A general form might look like: if <condition(s)>: <do_the_following> An example is checking whether a number is odd, the function I might implement could look like def parity(n): \"\"\"Returns 1 if n is odd, and 0 otherwise.\"\"\" if n % 2 == 1: return 1 return 0 A couple things to think about: return fully stops the execution of your function. It will simply return the value that you put into the return statement. See how the above case has 2 different return s, but both do not get read; only one of them and then the function stops. the piece of code must be indented so that Python knows what it should/should not run if the condition is true. I will be adding docstrings to each functions from now on to detail what each function will be accomplishing in high-level terms. Documentation, in general, is really good to do because it allows you and others to understand your code. if , elif , else Chains \u00b6 Now there are other things we can do with selection. Sometimes, the selection depends on separated conditions, not all under one. For example, if a number is a multiple of 3 , do this, otherwise if the number is a multiple of 5 , do this other thing, otherwise, the catch-all case is to do this other thing. For this we introduce the words elif and else . elif is just like another if statement, and else is the catch-all case. The pedagogical example is the fizzbuzz function. I'll modify its implementation to be the following: returns 'fizz' if the input is divisble by 3 , buzz if the input is divisible by 5 , 'fizzbuzz' if the input is divisible by 3 and 5 , and returns None if no other case applies. I implemented the function below def fizzbuzz(n): \"\"\"Returns 'fizz' if the n is divisible by 3, 'buzz' if n is divisible by 5, 'fizzbuzz' if it is divisible by 3 and 5, and returns None for any other case. \"\"\" if n % 3 == 0 and n % 5 == 0: return \"fizzbuzz\" elif n % 3 == 0: return \"fizz\" elif n % 5 == 0: return \"buzz\" else: return None Let me analyze this program: - First question, does the order of the conditions matter? What if I did the divisible by 3 case before I did the divisible by 3 and 5 case? Well remember, return stops execution of the function and returns the value. So, putting the divisible by 3 case before all the other cases might produce incorrect results. In general, when chaining if , elif , and else statements, you want to start with the most specific case, and then work your way towards the most general. When putting all three selection statements, you can only end up evaluating one of the s. I'll show you this by modifying our fizzbuzz specification to: print 'fizz' if the number is divisible by 3 , 'buzz' if it is divisible by 5 , 'fizzbuzz' if it is divisible by both 3 and 5 , and prints None if no cases match; the function will return None. Again, I'll write it below. def fizzbuzz(n): \"\"\"Prints 'fizz' if the n is divisible by 3, 'buzz' if n is divisible by 5, 'fizzbuzz' if it is divisible by 3 and 5, and prints None for any other case. Returns None\"\"\" if n % 3 == 0 and n % 5 == 0: print(\"fizzbuzz\") elif n % 3 == 0: return print(\"fizz\") elif n % 5 == 0: return print(\"buzz\") else: print(None) return Again, let's analyze this function: all inputs will go to the return statement at the very end. For example, if I were to input 3 , I land on the case of printing 'fizz' . Once I finish that I go to the end of our chain, where I return . I could also just not write the return at all, or write return None explicitly. All cases return None . The structure of chaining the selection makes it so only one is evaluated. If I were to, say write \"if\" for each case and then an else in the following way: def fizzbuzz(n): \"\"\"Prints 'fizz' if the n is divisible by 3, 'buzz' if n is divisible by 5, 'fizzbuzz' if it is divisible by 3 and 5, and prints None for any other case. Returns None\"\"\" if n % 3 == 0 and n % 5 == 0: print(\"fizzbuzz\") if n % 3 == 0: return print(\"fizz\") if n % 5 == 0: return print(\"buzz\") else: print(None) return it would be wrong. Let's say I inputted 15 All division cases pass, so a Python session like >>> fizzbuzz(15) fizzbuzz fizz buzz >>> will end up like the above. That is because we didn't chain any statements as we did with the elif and else . There is actually an interesting way to do this using string concatenation which does only if . I'll modify the implementation a slight in that the catch-all case will print out the empty string. def fizzbuzz(n): s = \"\" if n % 3 == 0: s += 'fizz' if n % 5 == 0: s += 'buzz' print(s) See how the if s being separated in this way allows us to check both separated conditions. If I were to use an elif in the second case, only one of the two would execute its . Summary \u00b6 In this note, we covered boolean logic, short-circuiting, relational operators, and the nuances among the if , elif , and else . These build the foundation of the idea of executing one's program with selection. In the next note, we will consider another way of control, known as iteration. Go to next section: [[3.2 While Clauses]] Get back to 3. Control or toc CS61A .","title":"3.1 If, Elif, Else Clauses"},{"location":"EECS/CS%2061A/3.1%20If%2C%20Elif%2C%20Else%20Clauses/#31-if-elif-else-clauses","text":"In this note, I will discuss conditional statements, and how we can use them to control the execution of our program under specific conditions.","title":"3.1 If, Elif, Else Clauses"},{"location":"EECS/CS%2061A/3.1%20If%2C%20Elif%2C%20Else%20Clauses/#booleans","text":"Now it is time to introduce another variable type in programming. Just like int , str , and NoneType , we now have another type to analyze: bool (short for boolean). A bool is something that is true or false. There are really no other values that a bool can take on. However, other types can thought of as boolean-like types, for which we call them \"truthy\" or \"falsey\" values.","title":"Booleans"},{"location":"EECS/CS%2061A/3.1%20If%2C%20Elif%2C%20Else%20Clauses/#truthy-and-falsey-values","text":"We assign truth values to each of the types we know so far, soon we will grow these items to include more types of objects. For now, I would remember these items: For an int type, every single number except 0 is truthy. So, 0 is false, and -10 is true. For a str type, only the empty string (written as \"\" ) is falsey, and every non-empty string is truthy. That means a string like \" \" is truthy since is it non-empty (there is a space between the quotes). None is falsey We can say the truth value explicitly with True and False . Of course, True is truthy and False if falsey. We will encounter other types of objects, however, a general rule is that an item is falsey if it is the empty for of that object, otherwise it is truthy. You can actually see if items are truthy and falsey by calling bool over the item you seek the truth of. For example, in your Python interpreter, you can write: >>> bool(4) True >>> bool(None) False >>> bool(\"\") False >>> bool(\" \") True >>> bool(0) False >>> bool(True) True Truthy values pop-up every once in a while, and these truthy values are specific to the Python language. When we look at the Scheme language, truthy values are slightly different. (In the language C, truthy values are also different, and the same is apparent in Java, Rust, Go, etc.). You'll have to briefly look at the coding language you use to see what is truthy and what is falsey. However, the above is what Python considers true and false.","title":"Truthy and Falsey Values"},{"location":"EECS/CS%2061A/3.1%20If%2C%20Elif%2C%20Else%20Clauses/#logical-operators-and-short-circuiting","text":"Sometimes, we rely on multiple conditions being truthy, and other times, we rely on only one of many possible conditions being truthy. Thus, logical operators are used to be the solution to this problem. Python's logical operators are the English words and , or , and not . (In other languages, you might see it as && , || , and ! , respectively). Logical statements in Python therefore reads like English. Logically, A and B requires both conditions A and B to be true. We can chain them together such as A and B and C and D and E to require A , B , C , D , and E to be true. If any of them are falsey values, the whole logical statement is falsey. A or B requires only one of the items to be truthy. A could be truthy and B could be falsey, it can appear vice versa, or A and B are truthy. Only when both entries are falsey does this logical operator become falsey. Like chaining and s together, we can chain or . A or B or C or D or E requires at least one of the 5 conditions to be truthy to be a truthy statement (there could be two, three, four, five truthy values, but as long as one of them are truthy, it doesn't really matter what the others are). It will be falsey only if all 5 conditions are falsey. not simply switches the truthy value of the item it is applied to. not True is falsey, and not False is truthy. However, there is something unique about logical operators. They actually return something (like a function) besides True and False . Let's investigate this behavior. Look at these two statements: >>> 0 or 5 5 >>> 0 and 5 0 It seems the or evaluated to the second item, and the and evaluated the first item. Let's also look at >>> 5 or 0 5 >>> 5 and 0 0 Now the or returned the first item, and the and returned the second item. Also, they return numbers! Let's look at some combination of int s and str s and NoneType s and bool s: >>> 5 and None and 3 >>> 3 or None or False 3 >>> None or 3 or 5 3 >>> None or False or 3 3 The first line evaluates to None , so you see nothing in the interpreter. But it seems like it returns a specific item. I'll just tell you what is happening here. This is called short-circuiting, and what happens is that if we already know the result of the logical statement, why do we need to evaluate even further? For example, the evaluation of 5 and None and 3 is already known once we see the None , and the return of 3 or None or False is already known when we see 3 . Here are the rules of short-circuiting and : Return the first falsey value. Otherwise, return the last item. or : Return the first truthy value. Otherwise, return the last item. You can see that and is like a mirror of or . Let me also say something about not not will change what ever it is being applied on to be the bool type True or False . The reason for the not working this way instead of evaluating to the type's truth counterpart is that things like not 0 is nonsensical to find a counterpart. Is the counterpart 1 , -1 , 100 ? Who knows? So we just change not 0 to True , and not \"hello\" to False . Let's run through some more examples of short-circuiting: Try these out and check your answers with your Python terminal. I'll explain it below. Some of the statements will give you a ZeroDivisionError , so keep track of those too. >>> 3 and 8 and 0 >>> 3 or 1/0 >>> \"\" or \".\" or \"\" >>> False and None >>> None or False >>> not True and not False We can combine both logical operators. You would need to make sure you simplify the expressions down as you see the parenthesis: >>> 3 or (4 and 0) >>> 3 and ((5 or 8) and (9 and None)) >>> 0 and (1/0 or 1/0 and 1/0) After you have seen the solutions, read the solutions I wrote here: 3 and 8 and 0 The rule here is to keep evaluating the next items until we reach the first falsey one. If all of them are truthy, we would then return the last item. We go through it one-by-one: 3 is truthy, 8 is truthy, 0 is falsey. This is the first falsey value, so we return 0 . 3 or 1/0 The rule here is to keep evaluating the next item until we reach the first truthy one. If all of them are falsey, return the last item. We just evaluate 3 since it is our first truthy value, so we return 3 . Note that 1/0 does not get read since we knew the result of the logical statement before we actually evaluated 1/0 . \"\" or \".\" or \"\" I'll start speeding up now. Since we are working with or , the first truthy value is \".\" , so we return '\".\"' False and None The first falsey value is False , so we return False . None or False All values are falsey, so we need to return the last item: False not True and not False . Each individual item becomes False and True . Since False is the first falsey value, it evaluates to False . Here are the solutions to the more involved compound logical statements: 3 or (4 and 0) . We only read the first item to find the first truthy value, so it is 3 . We don't even have to read the parenthetical expression. 3 and ((5 or 8) and (9 and None)) : 3 is truthy, now we need to evaluate the second item, which is (5 or 8) and (9 and None) . The first item of this subexpression, we need to evaluate. 5 or 8 evaluates to 5 , this is truthy, so we keep on going. 9 and None evaluates to None . Therefore, we are really trying to figure out 5 and None , which results in None . The main logical statement simplifies to 3 and None , which is None . 0 and (1/0 or 1/0 and 1/0) : 0 evaluates to falsey, so the whole statement results in 0 . Again, we do not have to evaluate all the 1/0 conditions because short-circuiting makes us stop once we know the answer.","title":"Logical Operators and Short Circuiting"},{"location":"EECS/CS%2061A/3.1%20If%2C%20Elif%2C%20Else%20Clauses/#relational-operators","text":"Relational operators evaluate to True or False . These are the actual bool types, not some alternative truthy/falsey values. A short list includes: < less than > greater than <= less than or equal to >= greater than or less than == equal. Note that it has to be double equals, since we already dedicated a single equals = to be variable assignment. A statement like 1 == 2 evaluates to False , and not 1 == 2 evaluates to True .","title":"Relational Operators"},{"location":"EECS/CS%2061A/3.1%20If%2C%20Elif%2C%20Else%20Clauses/#anatomy-of-if","text":"Now it's time to discuss the syntax of selection using the if clause. Similar to a function, you need 3 parts: the word if to indicate you are using selection conditional statement(s). Here is where you use your condition making, truthy/falsey, short-circuity logic a suite to execute in the case that your condition is true. This can be things like assigning a value to a variable, returning a value, or even putting another if clause there. In english, it might read as the following: \"if are met, then . If are not met, skip the and continue with what is next.\" A general form might look like: if <condition(s)>: <do_the_following> An example is checking whether a number is odd, the function I might implement could look like def parity(n): \"\"\"Returns 1 if n is odd, and 0 otherwise.\"\"\" if n % 2 == 1: return 1 return 0 A couple things to think about: return fully stops the execution of your function. It will simply return the value that you put into the return statement. See how the above case has 2 different return s, but both do not get read; only one of them and then the function stops. the piece of code must be indented so that Python knows what it should/should not run if the condition is true. I will be adding docstrings to each functions from now on to detail what each function will be accomplishing in high-level terms. Documentation, in general, is really good to do because it allows you and others to understand your code.","title":"Anatomy of if"},{"location":"EECS/CS%2061A/3.1%20If%2C%20Elif%2C%20Else%20Clauses/#if-elif-else-chains","text":"Now there are other things we can do with selection. Sometimes, the selection depends on separated conditions, not all under one. For example, if a number is a multiple of 3 , do this, otherwise if the number is a multiple of 5 , do this other thing, otherwise, the catch-all case is to do this other thing. For this we introduce the words elif and else . elif is just like another if statement, and else is the catch-all case. The pedagogical example is the fizzbuzz function. I'll modify its implementation to be the following: returns 'fizz' if the input is divisble by 3 , buzz if the input is divisible by 5 , 'fizzbuzz' if the input is divisible by 3 and 5 , and returns None if no other case applies. I implemented the function below def fizzbuzz(n): \"\"\"Returns 'fizz' if the n is divisible by 3, 'buzz' if n is divisible by 5, 'fizzbuzz' if it is divisible by 3 and 5, and returns None for any other case. \"\"\" if n % 3 == 0 and n % 5 == 0: return \"fizzbuzz\" elif n % 3 == 0: return \"fizz\" elif n % 5 == 0: return \"buzz\" else: return None Let me analyze this program: - First question, does the order of the conditions matter? What if I did the divisible by 3 case before I did the divisible by 3 and 5 case? Well remember, return stops execution of the function and returns the value. So, putting the divisible by 3 case before all the other cases might produce incorrect results. In general, when chaining if , elif , and else statements, you want to start with the most specific case, and then work your way towards the most general. When putting all three selection statements, you can only end up evaluating one of the s. I'll show you this by modifying our fizzbuzz specification to: print 'fizz' if the number is divisible by 3 , 'buzz' if it is divisible by 5 , 'fizzbuzz' if it is divisible by both 3 and 5 , and prints None if no cases match; the function will return None. Again, I'll write it below. def fizzbuzz(n): \"\"\"Prints 'fizz' if the n is divisible by 3, 'buzz' if n is divisible by 5, 'fizzbuzz' if it is divisible by 3 and 5, and prints None for any other case. Returns None\"\"\" if n % 3 == 0 and n % 5 == 0: print(\"fizzbuzz\") elif n % 3 == 0: return print(\"fizz\") elif n % 5 == 0: return print(\"buzz\") else: print(None) return Again, let's analyze this function: all inputs will go to the return statement at the very end. For example, if I were to input 3 , I land on the case of printing 'fizz' . Once I finish that I go to the end of our chain, where I return . I could also just not write the return at all, or write return None explicitly. All cases return None . The structure of chaining the selection makes it so only one is evaluated. If I were to, say write \"if\" for each case and then an else in the following way: def fizzbuzz(n): \"\"\"Prints 'fizz' if the n is divisible by 3, 'buzz' if n is divisible by 5, 'fizzbuzz' if it is divisible by 3 and 5, and prints None for any other case. Returns None\"\"\" if n % 3 == 0 and n % 5 == 0: print(\"fizzbuzz\") if n % 3 == 0: return print(\"fizz\") if n % 5 == 0: return print(\"buzz\") else: print(None) return it would be wrong. Let's say I inputted 15 All division cases pass, so a Python session like >>> fizzbuzz(15) fizzbuzz fizz buzz >>> will end up like the above. That is because we didn't chain any statements as we did with the elif and else . There is actually an interesting way to do this using string concatenation which does only if . I'll modify the implementation a slight in that the catch-all case will print out the empty string. def fizzbuzz(n): s = \"\" if n % 3 == 0: s += 'fizz' if n % 5 == 0: s += 'buzz' print(s) See how the if s being separated in this way allows us to check both separated conditions. If I were to use an elif in the second case, only one of the two would execute its .","title":"if, elif, else Chains"},{"location":"EECS/CS%2061A/3.1%20If%2C%20Elif%2C%20Else%20Clauses/#summary","text":"In this note, we covered boolean logic, short-circuiting, relational operators, and the nuances among the if , elif , and else . These build the foundation of the idea of executing one's program with selection. In the next note, we will consider another way of control, known as iteration. Go to next section: [[3.2 While Clauses]] Get back to 3. Control or toc CS61A .","title":"Summary"},{"location":"EECS/CS%2061A/4.%20Higher-Order%20Functions%20I/","text":"4. Higher Order Functions I \u00b6 These next 3 chapters: 4. Higher Order Functions I , [[5. Environment Diagrams]], and [[6. Higher-Order Functions II]] can be seen as the next section, but I decided to break it up into the first part being conceptual, the second part being visual, and the third part being applicable. Higher Order Functions allow you to make your programs more general -- who needs an add_2 function, when we could have an operator_n function? I could write a summation function, but I can also write a product function -- what if I wrote one function that encapsualtes both? The following will be covered in this chapter: 4.1 Functions as Parameters, Functions as Returns [[4.2 Lambda Functions]]","title":"4. Higher Order Functions I"},{"location":"EECS/CS%2061A/4.%20Higher-Order%20Functions%20I/#4-higher-order-functions-i","text":"These next 3 chapters: 4. Higher Order Functions I , [[5. Environment Diagrams]], and [[6. Higher-Order Functions II]] can be seen as the next section, but I decided to break it up into the first part being conceptual, the second part being visual, and the third part being applicable. Higher Order Functions allow you to make your programs more general -- who needs an add_2 function, when we could have an operator_n function? I could write a summation function, but I can also write a product function -- what if I wrote one function that encapsualtes both? The following will be covered in this chapter: 4.1 Functions as Parameters, Functions as Returns [[4.2 Lambda Functions]]","title":"4. Higher Order Functions I"},{"location":"EECS/CS%2061A/4.1%20Functions%20as%20Parameters%2C%20Functions%20as%20Returns/","text":"","title":"4.1 Functions as Parameters, Functions as Returns"},{"location":"EECS/CS%2061A/toc%20CS61A/","text":"Table of Contents \u00b6 CS 61A: The Structure and Interpretation of Computer Programs \u00b6 This note is a table of contents, for easy navigation to notes in CS 61A. Get back to main toc EECS CS 61A Notes: 0. Introduction to CS 61A 1. Python Interpreter 1.1 Expressions in the Terminal 1.2 Evaluation Procedure 2. Expressions, Variables, and Functions 2.1 Expressions and Variables 2.2 Defining and Using Functions 3. Control 3.1 If, Elif, Else Clauses [[3.2 While Clauses]] [[3.3 Integer Hacking]] [[3.4 Putting it All Together]] 4. Higher Order Functions I 4.1 Functions as Parameters, Functions as Returns [[4.2 Lambda Functions]] [[5. Environment Diagrams]] [[5.1 Variables and Functions]] [[5.2 Higher-Order Functions]] [[5.3 Potpourri of Examples]] [[6. Higher-Order Functions II]] [[6.1 Currying]] [[6.2 Chaining]] [[6.3 Self-Reference]] [[6. Recursion and Tree Recursion]] [[6.1 The Concept and Motivation of Recursion]] [[6.2 Introductory Recusion Examples]] [[6.3 Problem-Solving with Recursion]] [[6.4 Tree Recursion]] [[6.5 Inivolved Recursion Practice]] [[7. Sequences]] [[7.1 Lists, For-Loops, Ranges]] [[7.2 Tuples and Dictionaries]] [[7.3 Recursion Involving Sequences]] [[8. Mutability]] [[8.1 The Concept of Mutability]] [[8.2 List Mutation]] [[8.3 Box-and-Pointer Diagrams]] [[9. Object-Oriented Programming]] [[9.1 The Concept of Objects]] [[9.2 Classes, init , methods]] [[9.3 str and repr ]] [[9.4 Pointer Diagrams with Objects]] [[10. Iterators and Generators]] [[10.1 Creating Iterators]] [[10.2 Creating Generators]] [[11. Trees and Linked Lists]] [[11.1 Linked List Class]] [[11.2 Constructing List Methods with Link Lists]] [[11.3 Destructive and Non-Destructive Functions]] [[11.4 The Tree Class]] [[11.5 Common Tree Problems]] [[11.6 More Involved Practice with Trees and Linked Lists]] [[12. Efficiency]] [[12.1 Time Complexity]] [[12.2 Space Complexity]] [[13. Scheme]] [[13.1. Basic Scheme Syntax]] [[13.2 Scheme Lists]] [[13.3 Quotes and Quasiquotes]] [[13.4 Scheme Data Abstraction]] [[13.5 Tail Recursion]] [[14. Interpreters]] [[14.1 REPL]] [[15. Regex and BNF]] [[15.1 Declarative Programming]] [[15.2 Regex Groups, Sets]] [[15.3 Regex Quantifiers]] [[15.4 Regex Practice]] [[15.5 Creating Grammar with BNF]] [[15.6 BNF Quantifiers]] [[15.7 BNF Parse Trees]] [[16. SQL]] [[16.1 Data Tables]] [[16. SQL Basic Queries: SELECT, FROM, WHERE, ORDER BY, LIMIT]] [[16.3 SQL Agreggates and Aliasing: HAVING, GROUP BY]] [[16.4 SQL Queries]] [[A. Problem-Solving Strategy]] [[B. Exam Preparation]]","title":"Table of Contents"},{"location":"EECS/CS%2061A/toc%20CS61A/#table-of-contents","text":"","title":"Table of Contents"},{"location":"EECS/CS%2061A/toc%20CS61A/#cs-61a-the-structure-and-interpretation-of-computer-programs","text":"This note is a table of contents, for easy navigation to notes in CS 61A. Get back to main toc EECS CS 61A Notes: 0. Introduction to CS 61A 1. Python Interpreter 1.1 Expressions in the Terminal 1.2 Evaluation Procedure 2. Expressions, Variables, and Functions 2.1 Expressions and Variables 2.2 Defining and Using Functions 3. Control 3.1 If, Elif, Else Clauses [[3.2 While Clauses]] [[3.3 Integer Hacking]] [[3.4 Putting it All Together]] 4. Higher Order Functions I 4.1 Functions as Parameters, Functions as Returns [[4.2 Lambda Functions]] [[5. Environment Diagrams]] [[5.1 Variables and Functions]] [[5.2 Higher-Order Functions]] [[5.3 Potpourri of Examples]] [[6. Higher-Order Functions II]] [[6.1 Currying]] [[6.2 Chaining]] [[6.3 Self-Reference]] [[6. Recursion and Tree Recursion]] [[6.1 The Concept and Motivation of Recursion]] [[6.2 Introductory Recusion Examples]] [[6.3 Problem-Solving with Recursion]] [[6.4 Tree Recursion]] [[6.5 Inivolved Recursion Practice]] [[7. Sequences]] [[7.1 Lists, For-Loops, Ranges]] [[7.2 Tuples and Dictionaries]] [[7.3 Recursion Involving Sequences]] [[8. Mutability]] [[8.1 The Concept of Mutability]] [[8.2 List Mutation]] [[8.3 Box-and-Pointer Diagrams]] [[9. Object-Oriented Programming]] [[9.1 The Concept of Objects]] [[9.2 Classes, init , methods]] [[9.3 str and repr ]] [[9.4 Pointer Diagrams with Objects]] [[10. Iterators and Generators]] [[10.1 Creating Iterators]] [[10.2 Creating Generators]] [[11. Trees and Linked Lists]] [[11.1 Linked List Class]] [[11.2 Constructing List Methods with Link Lists]] [[11.3 Destructive and Non-Destructive Functions]] [[11.4 The Tree Class]] [[11.5 Common Tree Problems]] [[11.6 More Involved Practice with Trees and Linked Lists]] [[12. Efficiency]] [[12.1 Time Complexity]] [[12.2 Space Complexity]] [[13. Scheme]] [[13.1. Basic Scheme Syntax]] [[13.2 Scheme Lists]] [[13.3 Quotes and Quasiquotes]] [[13.4 Scheme Data Abstraction]] [[13.5 Tail Recursion]] [[14. Interpreters]] [[14.1 REPL]] [[15. Regex and BNF]] [[15.1 Declarative Programming]] [[15.2 Regex Groups, Sets]] [[15.3 Regex Quantifiers]] [[15.4 Regex Practice]] [[15.5 Creating Grammar with BNF]] [[15.6 BNF Quantifiers]] [[15.7 BNF Parse Trees]] [[16. SQL]] [[16.1 Data Tables]] [[16. SQL Basic Queries: SELECT, FROM, WHERE, ORDER BY, LIMIT]] [[16.3 SQL Agreggates and Aliasing: HAVING, GROUP BY]] [[16.4 SQL Queries]] [[A. Problem-Solving Strategy]] [[B. Exam Preparation]]","title":"CS 61A: The Structure and Interpretation of Computer Programs"},{"location":"EECS/CS%2061B/toc%20CS61B/","text":"Table of Contents \u00b6 CS 61A: Data Structures \u00b6 This note is a table of contents, for easy navigation to other notes. Get back to main toc EECS","title":"Table of Contents"},{"location":"EECS/CS%2061B/toc%20CS61B/#table-of-contents","text":"","title":"Table of Contents"},{"location":"EECS/CS%2061B/toc%20CS61B/#cs-61a-data-structures","text":"This note is a table of contents, for easy navigation to other notes. Get back to main toc EECS","title":"CS 61A: Data Structures"},{"location":"EECS/CS%2061C/toc%20CS61C/","text":"Table of Contents \u00b6 CS 61C: Great Ideas in Computer Architecture \u00b6 This note is a table of contents, for easy navigation to notes in CS 61C. Get back to main toc EECS CS 61C Notes: 0. Introduction to CS 61C 1. Number Representation 1.1 Decmial, Binary, and Hexadecimal Number Systems 1.2 Signed Representations 1.3 Floating Point Representation 2. C Programming 2.1 C Similarity to Java Syntax 2.2 Memory Allocation 2.3 Pointers and Arrays 2.4 Stack, Heap, Static, Code 3. Memory 3.1 Sizes of Types, Casting 3.2 Memory Alignment 3.3 Endianness 4. More C Programming - 4.1 Higher-Order Functions in C - 4.2 Structs and Unions - 4.3 Defines - 4.4 Programming in C 5. RISC-V Programming 6. RISC-V Calling Convention 7. RISC-V Instruction Formats 8. Compiler, Assembler, Linker, Loader (CALL) 9. Combinatorial Logic, Boolean Algebra 10. Synchonous Digital Systems (SDS) 11. Finite State Machines 12. RISC-V Datapath and Control Logic 13. Datapath Performance and Pipelining 14. Operating Systems (OS) 15. Data and Thread Level Parallelism 16. Caches 17. Cache Coherency 18. Virtual Memory 19. Dependability","title":"Table of Contents"},{"location":"EECS/CS%2061C/toc%20CS61C/#table-of-contents","text":"","title":"Table of Contents"},{"location":"EECS/CS%2061C/toc%20CS61C/#cs-61c-great-ideas-in-computer-architecture","text":"This note is a table of contents, for easy navigation to notes in CS 61C. Get back to main toc EECS CS 61C Notes: 0. Introduction to CS 61C 1. Number Representation 1.1 Decmial, Binary, and Hexadecimal Number Systems 1.2 Signed Representations 1.3 Floating Point Representation 2. C Programming 2.1 C Similarity to Java Syntax 2.2 Memory Allocation 2.3 Pointers and Arrays 2.4 Stack, Heap, Static, Code 3. Memory 3.1 Sizes of Types, Casting 3.2 Memory Alignment 3.3 Endianness 4. More C Programming - 4.1 Higher-Order Functions in C - 4.2 Structs and Unions - 4.3 Defines - 4.4 Programming in C 5. RISC-V Programming 6. RISC-V Calling Convention 7. RISC-V Instruction Formats 8. Compiler, Assembler, Linker, Loader (CALL) 9. Combinatorial Logic, Boolean Algebra 10. Synchonous Digital Systems (SDS) 11. Finite State Machines 12. RISC-V Datapath and Control Logic 13. Datapath Performance and Pipelining 14. Operating Systems (OS) 15. Data and Thread Level Parallelism 16. Caches 17. Cache Coherency 18. Virtual Memory 19. Dependability","title":"CS 61C: Great Ideas in Computer Architecture"},{"location":"EECS/CS%2061C/0.%20Introduction%20to%20CS%2061C/0.%20Introduction%20to%20CS%2061C/","text":"0. Introduction \u00b6 This note is an introduction to CS 61C. Get back to toc CS61C . Welcome \u00b6 Welcome to CS 61C! My name is Matthew Dharmawan, the author of these notes. I took this class in Summer 2022, and I really enjoyed learning the subject. Unlike CS 61A and 61B, this class focuses on low-level concepts; the things you took for granted in 61A and 61B are now something you need to understand and learn why it works. This down to the detail of \"how can you read data from an array? Well you have to look at the address it is in, and look in the cache. You designate these bits for specifying blocks in the cache, and those bits for what part of the block you want...\" You get the idea. The way that I want to approach this is starting from a high level, and understanding tools that allow us to get lower and lower. Overview \u00b6 I always like to give a preview on what is to come to see why we learn certain things to help set up for important concepts. Number Representation: The first major tool we will understand is number representation: your bits, bytes, twos-complement, hexadecimal, bias, floating point representations. These will be extremely useful and you'll see it throughout the rest of the course. When we talk about RISC-V Instruction Formats, Datapath, Caching, Virtual Memory, Dependability -- you can see number representation will seep into a lot of concepts we will talk about. C Programming: After that, we start from a very high-level: C (C is a low-level language, so it is not really high, but high-level relative to the rest of the concepts we will cover). If it is your first time looking at C, you'll see the syntax is very similar to Java. However, there are major differences that is taken for granted in Java that you don't have in C. For example, you have to request memory before you use it. In Java, the memory request is done under-the-hood for you, but in C, you have to explicitly use calls like malloc , calloc , and realloc , as well as specify how many bytes of data you want to allocate based on the situation given. What is even more detailed is that you also have to be your own garbage collector and free these allocated parts of memory, otherwise you'll be left with memory leaks, and that is bad. Memory: Then we will take a brief sidestep from C and look into stack, heap, static, and data. We will see when data is stored on the stack vs. the heap vs. static vs. data, and why it should be like this. Afterwards, we will talk about how data gets aligned in memory based on its size to make for easier accessing. More C Programming: Ok, now we go back to C programming and wrap-up things we didn't really talk about - structs and unions. We will finish off with doig a few exercises in C combining everything, then we won't touch C until nearing the end of the course. RISC-V Programming: Now it is time to go one level deeper. We know C is a compiled language, but what does it mean to be complied? C will get converted to an assembly language. In our case, that assembly language is RISC-V! RISC-V is a reduced instruction set computer, meaning that all operations are as simple as possible; if there is such an operation that could be broken down into two simpler instructions, then we don't include that more complicated one. Here, we will learn how to deal with managing register data, and using addresses (pointers) to access and store data. Programming in RISC-V can feel a bit tedious, but it is right above the step of programming in bits (and you don't want to program in bits). Assembly Calling Convention: Because of the nature of the 32 registers in RISC-V, we will need to establish some sort of calling convention. How can we organize registers such that each main category can do a specific thing? How do we deal with registers once we call a function? You can think of registers as \"global variables\" so if you call a function that alters s8, it will alter s8 in the function that originally called it, so hopefully you don't use it again! However, we can bypass this problem with a calling convention. RISC-V Instructions and Bits: Ok, now let's go another step lower. Let's convert RISC-V instructions into bits. Don't worry, you won't be coding loops and conditionals with bits, it's more like understanding how to categorize RISC-V instructions and represent them in 32 bits (or 64 bits, depending on architecture). CALL: If we were to go another step lower, we would learn about linkers and loaders. After learning about RISC-V, we will take a moment to talk about the entire process, from Compiler to Assembler to Linker to Loader. What do each step do such that a program can run on your machine? Boolean Logic and Synchronous Digital Systems: Now we will begin preparing some prerequisite knowledge to build your own CPU that can understand and execute all the RISC-V base-set instructions. To do that, we will have to look into boolean logic (for learning about gates like AND, OR, XOR, MUX), and Synchronous Digital Systems (for learning about registers and clocks.) Finite State Machines: After learning about SDS, another topic that deals with determining state are Finite-State Machines, which tell you how to proceed with inputs and outputs. You can create FSMs that tell you about the bits, such as if a 1 appears 3 times in a row, output a 1, otherwise, output a 0. We will look into several important examples of FSMs here. FSMs are important for visualizing cache coherency. Datapath: Okay, now we have a lot of prerequisite knowledge. Let's combine it all together and talk about datapath, which is the sequence and combination of logic that will help us interpret RISC-V code. We will talk about control logic, and how each part of the control logic allows us to determine how to proceed with the instruction given, such as if we want to write or read, use an immediate or not, how to handle branching, etc. We will come to understand the following diagram. Operating Systems: Let's take another sidestep and learn about the Operating System, the program responsible for making sure your computer doesn't crash when there is one error. Understanding how OS is able to keep track of several processes at once and manage memory is an important topic throughout the course, as we have seen. Pipelining: It takes a while for one single instruction to run on our CPU. How about we pipeline the datapath? Pipelining is the idea where we can run instructons somewhat at the same time, such as when an instruction is being decoded, at the same time, the next instruction is being fetched. When an instruction is executed, another will be decoded, and another will be fetched. However, pipelining introduces structural, data, and control hazards, but we will see how to work around that given what we already have. Data and Thread Level Parallelism: With the introduction of pipelining, we introduced a huge idea in computer architecture - parallelism: The idea of running several things at once rather than in sequence. Here, we will take a look at both Data-Level Parallelism (DLP) using vectorization and SIMD instructions, then look at Thread-Level Parallelism (TLP) using OpenMP to introduce threads that run simultaneously. Caches: Now, it is time to introduce a huge topic in this course that takes advantage of a lot of what we have been building up to: Caches. Caches are the idea of making accessing memory quicker by bringing in blocks of data from disk into a cache. The idea is if you took data from this block, it is highly likely you might take a look at that access again, or at the very least data around that initial access. Of course, accessing data this fast can be quite expensive, so we will have to take a look at how a cache is able to evict blocks when it is full, and learn about the several different tyeps of caches (Fully Associative, Direct-Mapped, N-Way Associative). We will also see how exactly we can bring blocks in data using T/I/O bits, and figure out what type of miss or hit will occur based on the state of the cache and the request bits of TIO. In addition, we will introduce the idea of multi-level caching, and how that might help us do more with caches. Cache Coherency: This is where FSMs make a return, now in combination with parallelism and caches! Virtual Memory: Another huge topic is the idea of virtual memory. Dependability: Now that we all have these systems in place, there is a very small chance that a bit will flip due to a cosmic ray hitting the device and flipping a bit. Now if there is no system in place to detect that bit, the whole disk could fail, which is terrible. How can we go about knowing if a sequence of bit has an error? This is where Error Correcting Codes come into the scene, allowing us to pinpoint exactly when a bit should not be in its current state. How might we do that? Let's look at parity, the number of 1's in a bitstring. If we can group specific combinations of bits and represent its parity with another bit, it seems like if we are creative enough, we can tell which bit in the bitstring is flipped (including the parity bits themselves). Afterwards, we will look into RAID (redundant array of inexpensive disks), and how different types of RAIDs might affect the system we have. Certain RAID types have its own advantages and disadvantages.","title":"0. Introduction"},{"location":"EECS/CS%2061C/0.%20Introduction%20to%20CS%2061C/0.%20Introduction%20to%20CS%2061C/#0-introduction","text":"This note is an introduction to CS 61C. Get back to toc CS61C .","title":"0. Introduction"},{"location":"EECS/CS%2061C/0.%20Introduction%20to%20CS%2061C/0.%20Introduction%20to%20CS%2061C/#welcome","text":"Welcome to CS 61C! My name is Matthew Dharmawan, the author of these notes. I took this class in Summer 2022, and I really enjoyed learning the subject. Unlike CS 61A and 61B, this class focuses on low-level concepts; the things you took for granted in 61A and 61B are now something you need to understand and learn why it works. This down to the detail of \"how can you read data from an array? Well you have to look at the address it is in, and look in the cache. You designate these bits for specifying blocks in the cache, and those bits for what part of the block you want...\" You get the idea. The way that I want to approach this is starting from a high level, and understanding tools that allow us to get lower and lower.","title":"Welcome"},{"location":"EECS/CS%2061C/0.%20Introduction%20to%20CS%2061C/0.%20Introduction%20to%20CS%2061C/#overview","text":"I always like to give a preview on what is to come to see why we learn certain things to help set up for important concepts. Number Representation: The first major tool we will understand is number representation: your bits, bytes, twos-complement, hexadecimal, bias, floating point representations. These will be extremely useful and you'll see it throughout the rest of the course. When we talk about RISC-V Instruction Formats, Datapath, Caching, Virtual Memory, Dependability -- you can see number representation will seep into a lot of concepts we will talk about. C Programming: After that, we start from a very high-level: C (C is a low-level language, so it is not really high, but high-level relative to the rest of the concepts we will cover). If it is your first time looking at C, you'll see the syntax is very similar to Java. However, there are major differences that is taken for granted in Java that you don't have in C. For example, you have to request memory before you use it. In Java, the memory request is done under-the-hood for you, but in C, you have to explicitly use calls like malloc , calloc , and realloc , as well as specify how many bytes of data you want to allocate based on the situation given. What is even more detailed is that you also have to be your own garbage collector and free these allocated parts of memory, otherwise you'll be left with memory leaks, and that is bad. Memory: Then we will take a brief sidestep from C and look into stack, heap, static, and data. We will see when data is stored on the stack vs. the heap vs. static vs. data, and why it should be like this. Afterwards, we will talk about how data gets aligned in memory based on its size to make for easier accessing. More C Programming: Ok, now we go back to C programming and wrap-up things we didn't really talk about - structs and unions. We will finish off with doig a few exercises in C combining everything, then we won't touch C until nearing the end of the course. RISC-V Programming: Now it is time to go one level deeper. We know C is a compiled language, but what does it mean to be complied? C will get converted to an assembly language. In our case, that assembly language is RISC-V! RISC-V is a reduced instruction set computer, meaning that all operations are as simple as possible; if there is such an operation that could be broken down into two simpler instructions, then we don't include that more complicated one. Here, we will learn how to deal with managing register data, and using addresses (pointers) to access and store data. Programming in RISC-V can feel a bit tedious, but it is right above the step of programming in bits (and you don't want to program in bits). Assembly Calling Convention: Because of the nature of the 32 registers in RISC-V, we will need to establish some sort of calling convention. How can we organize registers such that each main category can do a specific thing? How do we deal with registers once we call a function? You can think of registers as \"global variables\" so if you call a function that alters s8, it will alter s8 in the function that originally called it, so hopefully you don't use it again! However, we can bypass this problem with a calling convention. RISC-V Instructions and Bits: Ok, now let's go another step lower. Let's convert RISC-V instructions into bits. Don't worry, you won't be coding loops and conditionals with bits, it's more like understanding how to categorize RISC-V instructions and represent them in 32 bits (or 64 bits, depending on architecture). CALL: If we were to go another step lower, we would learn about linkers and loaders. After learning about RISC-V, we will take a moment to talk about the entire process, from Compiler to Assembler to Linker to Loader. What do each step do such that a program can run on your machine? Boolean Logic and Synchronous Digital Systems: Now we will begin preparing some prerequisite knowledge to build your own CPU that can understand and execute all the RISC-V base-set instructions. To do that, we will have to look into boolean logic (for learning about gates like AND, OR, XOR, MUX), and Synchronous Digital Systems (for learning about registers and clocks.) Finite State Machines: After learning about SDS, another topic that deals with determining state are Finite-State Machines, which tell you how to proceed with inputs and outputs. You can create FSMs that tell you about the bits, such as if a 1 appears 3 times in a row, output a 1, otherwise, output a 0. We will look into several important examples of FSMs here. FSMs are important for visualizing cache coherency. Datapath: Okay, now we have a lot of prerequisite knowledge. Let's combine it all together and talk about datapath, which is the sequence and combination of logic that will help us interpret RISC-V code. We will talk about control logic, and how each part of the control logic allows us to determine how to proceed with the instruction given, such as if we want to write or read, use an immediate or not, how to handle branching, etc. We will come to understand the following diagram. Operating Systems: Let's take another sidestep and learn about the Operating System, the program responsible for making sure your computer doesn't crash when there is one error. Understanding how OS is able to keep track of several processes at once and manage memory is an important topic throughout the course, as we have seen. Pipelining: It takes a while for one single instruction to run on our CPU. How about we pipeline the datapath? Pipelining is the idea where we can run instructons somewhat at the same time, such as when an instruction is being decoded, at the same time, the next instruction is being fetched. When an instruction is executed, another will be decoded, and another will be fetched. However, pipelining introduces structural, data, and control hazards, but we will see how to work around that given what we already have. Data and Thread Level Parallelism: With the introduction of pipelining, we introduced a huge idea in computer architecture - parallelism: The idea of running several things at once rather than in sequence. Here, we will take a look at both Data-Level Parallelism (DLP) using vectorization and SIMD instructions, then look at Thread-Level Parallelism (TLP) using OpenMP to introduce threads that run simultaneously. Caches: Now, it is time to introduce a huge topic in this course that takes advantage of a lot of what we have been building up to: Caches. Caches are the idea of making accessing memory quicker by bringing in blocks of data from disk into a cache. The idea is if you took data from this block, it is highly likely you might take a look at that access again, or at the very least data around that initial access. Of course, accessing data this fast can be quite expensive, so we will have to take a look at how a cache is able to evict blocks when it is full, and learn about the several different tyeps of caches (Fully Associative, Direct-Mapped, N-Way Associative). We will also see how exactly we can bring blocks in data using T/I/O bits, and figure out what type of miss or hit will occur based on the state of the cache and the request bits of TIO. In addition, we will introduce the idea of multi-level caching, and how that might help us do more with caches. Cache Coherency: This is where FSMs make a return, now in combination with parallelism and caches! Virtual Memory: Another huge topic is the idea of virtual memory. Dependability: Now that we all have these systems in place, there is a very small chance that a bit will flip due to a cosmic ray hitting the device and flipping a bit. Now if there is no system in place to detect that bit, the whole disk could fail, which is terrible. How can we go about knowing if a sequence of bit has an error? This is where Error Correcting Codes come into the scene, allowing us to pinpoint exactly when a bit should not be in its current state. How might we do that? Let's look at parity, the number of 1's in a bitstring. If we can group specific combinations of bits and represent its parity with another bit, it seems like if we are creative enough, we can tell which bit in the bitstring is flipped (including the parity bits themselves). Afterwards, we will look into RAID (redundant array of inexpensive disks), and how different types of RAIDs might affect the system we have. Certain RAID types have its own advantages and disadvantages.","title":"Overview"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.%20Number%20Representation/","text":"1. Number Representation \u00b6 This note is all about how to represent numbers with different counting systems, as well as representing floating point numbers. Get back to toc CS61C . Overview of Section \u00b6 We will talk about these items: - 1.1 Decmial, Binary, and Hexadecimal Number Systems - 1.2 Signed Representations - 1.3 Floating Point Representation","title":"1. Number Representation"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.%20Number%20Representation/#1-number-representation","text":"This note is all about how to represent numbers with different counting systems, as well as representing floating point numbers. Get back to toc CS61C .","title":"1. Number Representation"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.%20Number%20Representation/#overview-of-section","text":"We will talk about these items: - 1.1 Decmial, Binary, and Hexadecimal Number Systems - 1.2 Signed Representations - 1.3 Floating Point Representation","title":"Overview of Section"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.1%20Decmial%2C%20Binary%2C%20and%20Hexadecimal%20Number%20Systems/","text":"1.1 Decimal, Binary, and Hexadecmial Number Systems \u00b6 This note talks about how to convert between number systems, paying particular focus on the decimal, binary, and hexademical number systems. Get back to toc CS61C or 1. Number Representation Decimal Number System \u00b6 The system you choose to count is kind of arbitrary. Like, we have 10 symbols in our counting, where once we reach the last symbol, we create a new place value that increses by one value. But the amount of symbols we have is arbitrary. It is likely chosen because we have 10 fingers on both our hands, and thus have 10 symbols, but I could choose a number system that is 12 (called the dozenal number system) and can do math that way. Nevertheless, it is good to frame our decimal number system in terms of how we will analyze other number systems. Namely, let's talk about place value and expanded notation. A number like 123 can be broken down into place values: we have 3 ones, 2 tens, and 1 hundreds. We can therefore write it as \\(1*10^2 + 2 * 10^1 + 3 * 10^0\\) Where we can read it from right to left, increasing the power of ten by 1 whenever we go up a place value. With 3 locations to place a number we have a total of \\(10^3\\) unique values, however, we can only count from \\([0, 10^3 - 1]\\) . More generally, given \\(n\\) locations to write a number, we have \\(10^n\\) unique values, and our range is from \\([0, 10^n - 1]\\) . That is really all there is to our number system, some sequence of numbers based on how many symbols we have, a way to write bigger numbers with place values. We can also indicate how many possible values we might have, as well as the range we span across. Binary Number System \u00b6 The binary number system is no different, except we only have 2 symbols in our counting. A b inary dig it (also called a bit) is one such symbol. We can chain together 8 bits into a byte. Starting from \\(0\\) with eight bits, we count up just like we do in decimal: once we run out of symbols, increment the next place value by 1, and put all previous place values back to 0. With 4 bits, the sequence may start like \\(0b0000\\) , \\(0b0001\\) , \\(0b0010\\) , \\(0b0011\\) , \\(0b0100\\) , \\(0b0101, 0b0110\\) , \\(0b0111\\) , \\(0b1000\\) , Where these are the numbers from 0 to 8. One thing to note is that I will denote binary numbers with a \\(0b\\) prefix, but decimal numbers I will write them without any prefix. Similarly given a certain number a bits, such as \\(4\\) , there are only \\(2^4\\) unique values that can be represented, and since we start with \\(0\\) , we can count up to \\(2^4 - 1 = 15\\) . More generally, give an \\(n\\) bit number in unsigned represenation (we will learn other representations in 1.2 Signed Representations ), we can uniquely represent \\(2^n\\) values, with range \\([0, 2^n-1]\\) . Again, just like decimal numbers, we can break down a binary number by looking at powers of 2. For example: \\(0b10101 = 1 * 2^4 + 0 * 2^3 + 1*2^2 + 0*2^1 + 1*2^0\\) . Binary <-> Decimal \u00b6 To switch from binary to decimal is actually quite simple. If you can break the binary number down just like how we did above, then compute the value, The number above yields \\( \\(0b10101 = 1 * 2^4 + 0 * 2^3 + 1*2^2 + 0*2^1 + 1*2^0 = 16 + 4 + 1 = 21\\) \\) I would highly recommend remembering the first couple powers of 2, though you'll probably memorize it along the way since it is used so much in this course. I'd say up to \\(2048\\) would be good enough, so you could represent numbers from \\([0, 4096 - 1]\\) easily (or equivalently write any 12 bit number). $$ \\begin{align } 2^0 = 1 && 2^1 = 2 && 2^2 = 4 && 2^3 = 8\\ 2^4 = 16 && 2^5 = 32 && 2^6 = 64 && 2^7 = 128\\ 2^8 = 256 && 2^9 = 512 && 2^{10} = 1024 && 2^{11} = 2048 \\end{align } $$ Decimal to binary number involves a lot of subtracting, but here is a general procedure 1. Find the highest power of 2 that does not exceed the decimal number. 2. Subtract it by that value. At the same time, you know that the bit at that place value will contain a 1. Any power of 2 that you skip will have that bit place value be 0. 3. Continue this all the way until you reach \\(2^0 = 1\\) . For example, writing \\(100\\) in binary makes me do the following process: 100 - 64 = 36. 36 - 32 = 4, 4 - 4 = 0. I used bits at \\(2^6, 2^5, 2^2\\) , so the binary number is \\(0b1100100\\) . I can double check by ensuring \\(0b1100100 = 2^6 + 2^5 + 2^2 = 64 + 32 + 4 = 100\\) . As you can see, knowing the powers of two helps you do these problems a bit faster than having to recall or write down the powers of two everytime. You will do this quite frequently, so I'd get used to the procedure while you can. Binary to Hexadecmial \u00b6 Hexadecimal is a number system that uses 16 symbols for counting (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F). To represent hex values, we place a \\(0x\\) as a prefix, just like we do \\(0b\\) for binary. It is actually easier to convert binary to hex and hex to binary than it is using the decimal system with conversions. Why? Let's notice the following fact. Every group of 4 bits can be characterized by a single hex symbol. For example \\(0xC = 0b1100\\) , and \\(0xAB = 0b 1010\\;1011\\) . I'd recommend you remember all the hex to binary conversions. $$ \\begin{align } 0x0 = 0b0000 && 0x1 = 0b0001 && 0x2 = 0b0010 && 0x3 = 0b0011\\ 0x4 = 0b0100 && 0x5 = 0b0101 && 0x6 = 0b0110 && 0x7 = 0b0111\\ 0x8 = 0b1000 && 0x9 = 0b1001 && 0xA = 0b1010 && 0xB = 0b1011\\ 0xC = 0b1100 && 0xD = 0b1101 && 0xE = 0b1110 && 0xF = 0b1111 \\end{align } $$ Just so you understand the importance of Hex and Binary conversions, Binary to Hex and vice versa conversions will be used on the following ways in the rest of this course: 1. When talking about the address of something in memory 2. Translating RISC-V code to 32-bit instructions 3. Debugging your CPU Project 4. Caching 5. Virtual Memory By the end of the course, you will hopefully be proficient in doing binary-hex conversions because you'll end up doing it so much. So here is a quick example of doing such a conversion. You'll learn that that xor is a RISC-V instruction, and inputting something like xor t0, t1, t2 has the hex \\(0x007342B3\\) Translate this into binary. All I would do is just use the binary-hex translations for each hex character and concatenate all of them together. \\( \\(0b 0000\\;0000\\;0111\\;0011\\;0100\\;0010\\;1011\\;0011\\) \\) Just to preview what is to come, \\(t0 = 0b00101, t1 = 0b00110, t2 = 0b00111\\) . You might see these segments hidden in the 32-bit number we just wrote out. All the other bits are meant to indicate that xor was the operation that was used. Another example, translating \\(0b1110101010101111101011101\\) to hex. I would first separate them into groups of 4, like so \\( \\(0b1\\; 1101\\; 0101\\; 0101\\; 1111\\; 0101\\; 1101\\) \\) One thing to note is that we start the groupings from the right to left. Then convert all groups of 4 into its corresponding hex. The 1 at the beginning can be thought of as 1 with padded 0s at the front. Therefore, I get $$ 0x 1D55F5D $$ Hex <-> Decimal Conversions \u00b6 The process is just the same for Binary <-> Decimal. From Hex to Decimal, represent each digit as a power of 16, but first convert each symbol into base 10. A number like \\(0xCF3\\) is just \\( \\(0xCF3 = 12 * 16^2 + 15*16^1 + 3 * 16^0\\) \\) And you can do the same analysis from decimal to hex if you know your powers of 16 times some number. A number like \\(300\\) would be like \\(300 - 1 * 16^2 = 300 - 256 = 44. 44 - 2 * 16^2 = 44 - 32 = 12. 12 - 12 * 16^0 = 0\\) . The hex number is \\(0x12C\\) . As you can see it is far easier to translate from decimal to hex and vice versa using the binary system as an intermediate step.","title":"1.1 Decimal, Binary, and Hexadecmial Number Systems"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.1%20Decmial%2C%20Binary%2C%20and%20Hexadecimal%20Number%20Systems/#11-decimal-binary-and-hexadecmial-number-systems","text":"This note talks about how to convert between number systems, paying particular focus on the decimal, binary, and hexademical number systems. Get back to toc CS61C or 1. Number Representation","title":"1.1 Decimal, Binary, and Hexadecmial Number Systems"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.1%20Decmial%2C%20Binary%2C%20and%20Hexadecimal%20Number%20Systems/#decimal-number-system","text":"The system you choose to count is kind of arbitrary. Like, we have 10 symbols in our counting, where once we reach the last symbol, we create a new place value that increses by one value. But the amount of symbols we have is arbitrary. It is likely chosen because we have 10 fingers on both our hands, and thus have 10 symbols, but I could choose a number system that is 12 (called the dozenal number system) and can do math that way. Nevertheless, it is good to frame our decimal number system in terms of how we will analyze other number systems. Namely, let's talk about place value and expanded notation. A number like 123 can be broken down into place values: we have 3 ones, 2 tens, and 1 hundreds. We can therefore write it as \\(1*10^2 + 2 * 10^1 + 3 * 10^0\\) Where we can read it from right to left, increasing the power of ten by 1 whenever we go up a place value. With 3 locations to place a number we have a total of \\(10^3\\) unique values, however, we can only count from \\([0, 10^3 - 1]\\) . More generally, given \\(n\\) locations to write a number, we have \\(10^n\\) unique values, and our range is from \\([0, 10^n - 1]\\) . That is really all there is to our number system, some sequence of numbers based on how many symbols we have, a way to write bigger numbers with place values. We can also indicate how many possible values we might have, as well as the range we span across.","title":"Decimal Number System"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.1%20Decmial%2C%20Binary%2C%20and%20Hexadecimal%20Number%20Systems/#binary-number-system","text":"The binary number system is no different, except we only have 2 symbols in our counting. A b inary dig it (also called a bit) is one such symbol. We can chain together 8 bits into a byte. Starting from \\(0\\) with eight bits, we count up just like we do in decimal: once we run out of symbols, increment the next place value by 1, and put all previous place values back to 0. With 4 bits, the sequence may start like \\(0b0000\\) , \\(0b0001\\) , \\(0b0010\\) , \\(0b0011\\) , \\(0b0100\\) , \\(0b0101, 0b0110\\) , \\(0b0111\\) , \\(0b1000\\) , Where these are the numbers from 0 to 8. One thing to note is that I will denote binary numbers with a \\(0b\\) prefix, but decimal numbers I will write them without any prefix. Similarly given a certain number a bits, such as \\(4\\) , there are only \\(2^4\\) unique values that can be represented, and since we start with \\(0\\) , we can count up to \\(2^4 - 1 = 15\\) . More generally, give an \\(n\\) bit number in unsigned represenation (we will learn other representations in 1.2 Signed Representations ), we can uniquely represent \\(2^n\\) values, with range \\([0, 2^n-1]\\) . Again, just like decimal numbers, we can break down a binary number by looking at powers of 2. For example: \\(0b10101 = 1 * 2^4 + 0 * 2^3 + 1*2^2 + 0*2^1 + 1*2^0\\) .","title":"Binary Number System"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.1%20Decmial%2C%20Binary%2C%20and%20Hexadecimal%20Number%20Systems/#binary-decimal","text":"To switch from binary to decimal is actually quite simple. If you can break the binary number down just like how we did above, then compute the value, The number above yields \\( \\(0b10101 = 1 * 2^4 + 0 * 2^3 + 1*2^2 + 0*2^1 + 1*2^0 = 16 + 4 + 1 = 21\\) \\) I would highly recommend remembering the first couple powers of 2, though you'll probably memorize it along the way since it is used so much in this course. I'd say up to \\(2048\\) would be good enough, so you could represent numbers from \\([0, 4096 - 1]\\) easily (or equivalently write any 12 bit number). $$ \\begin{align } 2^0 = 1 && 2^1 = 2 && 2^2 = 4 && 2^3 = 8\\ 2^4 = 16 && 2^5 = 32 && 2^6 = 64 && 2^7 = 128\\ 2^8 = 256 && 2^9 = 512 && 2^{10} = 1024 && 2^{11} = 2048 \\end{align } $$ Decimal to binary number involves a lot of subtracting, but here is a general procedure 1. Find the highest power of 2 that does not exceed the decimal number. 2. Subtract it by that value. At the same time, you know that the bit at that place value will contain a 1. Any power of 2 that you skip will have that bit place value be 0. 3. Continue this all the way until you reach \\(2^0 = 1\\) . For example, writing \\(100\\) in binary makes me do the following process: 100 - 64 = 36. 36 - 32 = 4, 4 - 4 = 0. I used bits at \\(2^6, 2^5, 2^2\\) , so the binary number is \\(0b1100100\\) . I can double check by ensuring \\(0b1100100 = 2^6 + 2^5 + 2^2 = 64 + 32 + 4 = 100\\) . As you can see, knowing the powers of two helps you do these problems a bit faster than having to recall or write down the powers of two everytime. You will do this quite frequently, so I'd get used to the procedure while you can.","title":"Binary &lt;-&gt; Decimal"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.1%20Decmial%2C%20Binary%2C%20and%20Hexadecimal%20Number%20Systems/#binary-to-hexadecmial","text":"Hexadecimal is a number system that uses 16 symbols for counting (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F). To represent hex values, we place a \\(0x\\) as a prefix, just like we do \\(0b\\) for binary. It is actually easier to convert binary to hex and hex to binary than it is using the decimal system with conversions. Why? Let's notice the following fact. Every group of 4 bits can be characterized by a single hex symbol. For example \\(0xC = 0b1100\\) , and \\(0xAB = 0b 1010\\;1011\\) . I'd recommend you remember all the hex to binary conversions. $$ \\begin{align } 0x0 = 0b0000 && 0x1 = 0b0001 && 0x2 = 0b0010 && 0x3 = 0b0011\\ 0x4 = 0b0100 && 0x5 = 0b0101 && 0x6 = 0b0110 && 0x7 = 0b0111\\ 0x8 = 0b1000 && 0x9 = 0b1001 && 0xA = 0b1010 && 0xB = 0b1011\\ 0xC = 0b1100 && 0xD = 0b1101 && 0xE = 0b1110 && 0xF = 0b1111 \\end{align } $$ Just so you understand the importance of Hex and Binary conversions, Binary to Hex and vice versa conversions will be used on the following ways in the rest of this course: 1. When talking about the address of something in memory 2. Translating RISC-V code to 32-bit instructions 3. Debugging your CPU Project 4. Caching 5. Virtual Memory By the end of the course, you will hopefully be proficient in doing binary-hex conversions because you'll end up doing it so much. So here is a quick example of doing such a conversion. You'll learn that that xor is a RISC-V instruction, and inputting something like xor t0, t1, t2 has the hex \\(0x007342B3\\) Translate this into binary. All I would do is just use the binary-hex translations for each hex character and concatenate all of them together. \\( \\(0b 0000\\;0000\\;0111\\;0011\\;0100\\;0010\\;1011\\;0011\\) \\) Just to preview what is to come, \\(t0 = 0b00101, t1 = 0b00110, t2 = 0b00111\\) . You might see these segments hidden in the 32-bit number we just wrote out. All the other bits are meant to indicate that xor was the operation that was used. Another example, translating \\(0b1110101010101111101011101\\) to hex. I would first separate them into groups of 4, like so \\( \\(0b1\\; 1101\\; 0101\\; 0101\\; 1111\\; 0101\\; 1101\\) \\) One thing to note is that we start the groupings from the right to left. Then convert all groups of 4 into its corresponding hex. The 1 at the beginning can be thought of as 1 with padded 0s at the front. Therefore, I get $$ 0x 1D55F5D $$","title":"Binary to Hexadecmial"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.1%20Decmial%2C%20Binary%2C%20and%20Hexadecimal%20Number%20Systems/#hex-decimal-conversions","text":"The process is just the same for Binary <-> Decimal. From Hex to Decimal, represent each digit as a power of 16, but first convert each symbol into base 10. A number like \\(0xCF3\\) is just \\( \\(0xCF3 = 12 * 16^2 + 15*16^1 + 3 * 16^0\\) \\) And you can do the same analysis from decimal to hex if you know your powers of 16 times some number. A number like \\(300\\) would be like \\(300 - 1 * 16^2 = 300 - 256 = 44. 44 - 2 * 16^2 = 44 - 32 = 12. 12 - 12 * 16^0 = 0\\) . The hex number is \\(0x12C\\) . As you can see it is far easier to translate from decimal to hex and vice versa using the binary system as an intermediate step.","title":"Hex &lt;-&gt; Decimal Conversions"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.2%20Signed%20Representations/","text":"1.2 Signed Representations \u00b6 This note focuses more on how to represent more types of numbers using signed representations, in particular, sign-magnitude, twos-complement, and biased representations. We will be paying particular focus of signed representations with respect to binary and hexadecimal number systems. Get back to toc CS61C or 1. Number Representation Other Number Representations \u00b6 So far, we only know how to describe positive numbers in range \\([0, 2^n-1]\\) . However, we need to expand into trying to represent other numbers, like negative numbers, or even numbers competely in different ranges. There are three representations we will look at, and for each, we will discuss how they succeed in answering the following questions. 1. How many unique values are represented by this system? 2. What is the range that the numbers can represent? 3. How easy is it to do math with? Sign-Magnitude Representation \u00b6 In our decimal number system, we simply tack on a negative sign in front of our decimal number to indicate its sign. However, computers cannot recognize a negative sign, they only can interpret a 0 or 1. Therefore, it feels natural to let the most significant bit (MSB) to indicate sign, where bit 0 indicates positive, and 1 indicates negative. Therefore, to convert a possibly negative decimal number into sign-magnitude binary representation, the procedure would look like 1. Disregard the sign in front for now. Convert the magnitude of the number to binary 2. If the decimal number was negative, concatenate with a 1 on the left side. If it was positive, concatenate a 0 to the left side And the procedure the other way around would look like 1. Disregard the MSB, convert the rest of the number into decimal. 2. If MSB was 1 put a negative sign in front. If MSB was 0 , put a positive sign in front. For example, a 2-bit number like 0b01 would be 1 in decimal, but 0b11 is -1. Now let's analyze this number system with the three questions: Question 1: How many unique values are represented by sign-magnitude? Well it might seem like there are \\(2^n\\) possible values, but notice that the decimal number \\(0\\) has two representations. In 8-bit, \\(0b0000\\;0000\\) and \\(0b1000\\;0000\\) . So in all, given an n-bit number, there are \\(2^n - 1\\) unique values. That is alright, but doesn't use all the bits to the fullest extent. Question 2: What is the range? The highest value we can represent in 8-bit is \\(0b0111\\;1111\\) , and the lowest is \\(0b1111\\;1111\\) . In general, we can represent numbers from \\([-2^{n-1}, 2^{n-1}]\\) . Question 3: How easy is it to do math with? It's alright. You'll have to tell the computer extra instructions to do operations with negative numbers like \\(20 - 40 = -20\\) where if the second number is greater than the first, you make it negative, etc. It's not great, but it feels pretty good. Two's Complement Representation \u00b6 In this representation, we can consider negative numbers in a creative way: let's encode the most significant bit (MSB) to be some negative and the rest of the numbers positive. For example, in 4-bit systems, \\(0b1000\\) is just \\(-8\\) . The way I can see this is that the MSB is a 1, and if a 1 were in that spot regularly, it would be \\(8\\) , but since it is MSB, it is the negative of it. Then for numbers like \\(0b1100\\) , we would see that it is \\(-8 + 4 = -4\\) , and for \\(0b1110\\) , it would be \\(-8 + 4 + 2 = -2\\) . Here is a general rule for Two's Complement: for a n-bit number with bits \\(d_nd_{n-1}\\dots d_1d_0\\) , two's complement says that the value is $$ \\begin{align } -d_{n-1} * 2^{n-1} + d_{n-2} 2^{n-2} + \\cdots d_1 * 2^1 + d_0 * 2^0 \\end{align*} $$ Through this, we see that only the MSB can encode the negative part, along with some size based on what is defined to be the MSB. For example, in 8-bit systems, the binary number \\(0b1000\\;1011\\) in two's complement representation is \\(-2^7 + 2^3 + 2^1 + 2^0 = -128 + 8 + 2 + 1 = -117\\) . This way of figuring out the value is a bit annoying if you try out a couple of examples, you have to work with negative numbers and adding them with positive numbers. There is actually a better way of finding the value. No matter what the number is, you can find the two's complement of that binary number, and the complement is just multiplying by \\(-1\\) . That rule, you'll know well: \\( \\(\\text{Flip the bits and add 1}\\) \\) So, given a negative number, you can find the two's complement (the positive number) and then you know that the number is just the negative of that number. The same example above gives \\(0b1000\\;1011 \\rightarrow 0b0111\\;0100 + 1 = 0b0111\\;0101 = 2^6 + 2^5 + 2^4 + 2^2 = 64 + 32 + 16 + 4 + 1 = 117\\) , so it represents \\(-117\\) . This rule also works the other way. Here a positive number in 8-bit, two's complement: \\(0b0001\\;1010\\) . If I wanted to find the negative value associated with it, it is simply \\(0b1110\\;0101 + 1 = 0b1110\\;0110\\) . Again, let's analyze this number system: Question 1: Unique values. We can actually use all the \\(2^n\\) unique values, no binary number represents two different numbers in two's complement Question 2: Range. The most negative number is \\(0b1000\\dots\\) . and the most positive number is \\(0b0111\\dots\\) . That means the range is \\([-2^{n-1}, 2^{n-1} - 1]\\) . Notice the minus 1 at the end of the positive side, while the end of the negative side doesn't have that. Question 3: Math? Let's see. In 4-bit, two's complement, a negative number plus a positive number is always the trickiest example to come up with: \\(0b1010 + 0b0111\\) . In decimal, it is \\(-6 + 7 = 1\\) . In binary, let's naively add them together: \\(0b1010 + 0b0111 = 0b0001\\) . One thing to notice is that we overflowed to the fifth bit, but since we are only adding two 4-bit numbers together, we need to disregard that carry bit at the end, but we do get the correct value at the end. This is true for all two's complement arithmetic. This means arithmetic with two's complement is just the simple binary addition, unlike how in sign-magnitude we need extra instructions to determine sign. Two's Complement Hex \u00b6 Only the MSB encodes negative information. In hex, it is not the symbol that encodes the negative information. Two's complement hex is just binary two's complement once you convert it into binary. It is not the most significant hex that encodes the negative information, only the most significant bit of the hex that encodes it. Therefore, a hex number like \\(0xFFFF\\;FFFA\\) is \\(0x1111\\;1111\\;1111\\;1111\\;1111\\;1111\\;1111\\;1010\\) , which has the decimal value \\[ \\begin{align*} 0b0000\\;0000\\;0000\\;0000\\;0000\\;&0000\\;0000\\;0101 + 1 \\\\\\qquad\\qquad &= 0b0000\\;0000\\;0000\\;0000\\;0000\\;0000\\;0000\\;0110 \\\\&= 6 \\rightarrow -6 \\end{align*} \\] Bias Representation \u00b6 So far, we have discussed number systems that are somewhat centered around 0. But what happens if we wanted to represent numbers such as the temperature in Kelvin in the world around us, where \\(0\\) represent something that we probably won't see in our lifetime? This is where bias representation comes in. To write a number in bias representation, we must know what the bias is. Let's denote the bias to be \\(B\\) .","title":"1.2 Signed Representations"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.2%20Signed%20Representations/#12-signed-representations","text":"This note focuses more on how to represent more types of numbers using signed representations, in particular, sign-magnitude, twos-complement, and biased representations. We will be paying particular focus of signed representations with respect to binary and hexadecimal number systems. Get back to toc CS61C or 1. Number Representation","title":"1.2 Signed Representations"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.2%20Signed%20Representations/#other-number-representations","text":"So far, we only know how to describe positive numbers in range \\([0, 2^n-1]\\) . However, we need to expand into trying to represent other numbers, like negative numbers, or even numbers competely in different ranges. There are three representations we will look at, and for each, we will discuss how they succeed in answering the following questions. 1. How many unique values are represented by this system? 2. What is the range that the numbers can represent? 3. How easy is it to do math with?","title":"Other Number Representations"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.2%20Signed%20Representations/#sign-magnitude-representation","text":"In our decimal number system, we simply tack on a negative sign in front of our decimal number to indicate its sign. However, computers cannot recognize a negative sign, they only can interpret a 0 or 1. Therefore, it feels natural to let the most significant bit (MSB) to indicate sign, where bit 0 indicates positive, and 1 indicates negative. Therefore, to convert a possibly negative decimal number into sign-magnitude binary representation, the procedure would look like 1. Disregard the sign in front for now. Convert the magnitude of the number to binary 2. If the decimal number was negative, concatenate with a 1 on the left side. If it was positive, concatenate a 0 to the left side And the procedure the other way around would look like 1. Disregard the MSB, convert the rest of the number into decimal. 2. If MSB was 1 put a negative sign in front. If MSB was 0 , put a positive sign in front. For example, a 2-bit number like 0b01 would be 1 in decimal, but 0b11 is -1. Now let's analyze this number system with the three questions: Question 1: How many unique values are represented by sign-magnitude? Well it might seem like there are \\(2^n\\) possible values, but notice that the decimal number \\(0\\) has two representations. In 8-bit, \\(0b0000\\;0000\\) and \\(0b1000\\;0000\\) . So in all, given an n-bit number, there are \\(2^n - 1\\) unique values. That is alright, but doesn't use all the bits to the fullest extent. Question 2: What is the range? The highest value we can represent in 8-bit is \\(0b0111\\;1111\\) , and the lowest is \\(0b1111\\;1111\\) . In general, we can represent numbers from \\([-2^{n-1}, 2^{n-1}]\\) . Question 3: How easy is it to do math with? It's alright. You'll have to tell the computer extra instructions to do operations with negative numbers like \\(20 - 40 = -20\\) where if the second number is greater than the first, you make it negative, etc. It's not great, but it feels pretty good.","title":"Sign-Magnitude Representation"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.2%20Signed%20Representations/#twos-complement-representation","text":"In this representation, we can consider negative numbers in a creative way: let's encode the most significant bit (MSB) to be some negative and the rest of the numbers positive. For example, in 4-bit systems, \\(0b1000\\) is just \\(-8\\) . The way I can see this is that the MSB is a 1, and if a 1 were in that spot regularly, it would be \\(8\\) , but since it is MSB, it is the negative of it. Then for numbers like \\(0b1100\\) , we would see that it is \\(-8 + 4 = -4\\) , and for \\(0b1110\\) , it would be \\(-8 + 4 + 2 = -2\\) . Here is a general rule for Two's Complement: for a n-bit number with bits \\(d_nd_{n-1}\\dots d_1d_0\\) , two's complement says that the value is $$ \\begin{align } -d_{n-1} * 2^{n-1} + d_{n-2} 2^{n-2} + \\cdots d_1 * 2^1 + d_0 * 2^0 \\end{align*} $$ Through this, we see that only the MSB can encode the negative part, along with some size based on what is defined to be the MSB. For example, in 8-bit systems, the binary number \\(0b1000\\;1011\\) in two's complement representation is \\(-2^7 + 2^3 + 2^1 + 2^0 = -128 + 8 + 2 + 1 = -117\\) . This way of figuring out the value is a bit annoying if you try out a couple of examples, you have to work with negative numbers and adding them with positive numbers. There is actually a better way of finding the value. No matter what the number is, you can find the two's complement of that binary number, and the complement is just multiplying by \\(-1\\) . That rule, you'll know well: \\( \\(\\text{Flip the bits and add 1}\\) \\) So, given a negative number, you can find the two's complement (the positive number) and then you know that the number is just the negative of that number. The same example above gives \\(0b1000\\;1011 \\rightarrow 0b0111\\;0100 + 1 = 0b0111\\;0101 = 2^6 + 2^5 + 2^4 + 2^2 = 64 + 32 + 16 + 4 + 1 = 117\\) , so it represents \\(-117\\) . This rule also works the other way. Here a positive number in 8-bit, two's complement: \\(0b0001\\;1010\\) . If I wanted to find the negative value associated with it, it is simply \\(0b1110\\;0101 + 1 = 0b1110\\;0110\\) . Again, let's analyze this number system: Question 1: Unique values. We can actually use all the \\(2^n\\) unique values, no binary number represents two different numbers in two's complement Question 2: Range. The most negative number is \\(0b1000\\dots\\) . and the most positive number is \\(0b0111\\dots\\) . That means the range is \\([-2^{n-1}, 2^{n-1} - 1]\\) . Notice the minus 1 at the end of the positive side, while the end of the negative side doesn't have that. Question 3: Math? Let's see. In 4-bit, two's complement, a negative number plus a positive number is always the trickiest example to come up with: \\(0b1010 + 0b0111\\) . In decimal, it is \\(-6 + 7 = 1\\) . In binary, let's naively add them together: \\(0b1010 + 0b0111 = 0b0001\\) . One thing to notice is that we overflowed to the fifth bit, but since we are only adding two 4-bit numbers together, we need to disregard that carry bit at the end, but we do get the correct value at the end. This is true for all two's complement arithmetic. This means arithmetic with two's complement is just the simple binary addition, unlike how in sign-magnitude we need extra instructions to determine sign.","title":"Two's Complement Representation"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.2%20Signed%20Representations/#twos-complement-hex","text":"Only the MSB encodes negative information. In hex, it is not the symbol that encodes the negative information. Two's complement hex is just binary two's complement once you convert it into binary. It is not the most significant hex that encodes the negative information, only the most significant bit of the hex that encodes it. Therefore, a hex number like \\(0xFFFF\\;FFFA\\) is \\(0x1111\\;1111\\;1111\\;1111\\;1111\\;1111\\;1111\\;1010\\) , which has the decimal value \\[ \\begin{align*} 0b0000\\;0000\\;0000\\;0000\\;0000\\;&0000\\;0000\\;0101 + 1 \\\\\\qquad\\qquad &= 0b0000\\;0000\\;0000\\;0000\\;0000\\;0000\\;0000\\;0110 \\\\&= 6 \\rightarrow -6 \\end{align*} \\]","title":"Two's Complement Hex"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.2%20Signed%20Representations/#bias-representation","text":"So far, we have discussed number systems that are somewhat centered around 0. But what happens if we wanted to represent numbers such as the temperature in Kelvin in the world around us, where \\(0\\) represent something that we probably won't see in our lifetime? This is where bias representation comes in. To write a number in bias representation, we must know what the bias is. Let's denote the bias to be \\(B\\) .","title":"Bias Representation"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.3%20Floating%20Point%20Representation/","text":"1.3 Floating Point Representation \u00b6 This note explains how one might go about expressing floats in binary or hexadecimal systems using IEEE representation of floating point numbers. Get back to toc CS61C or 1. Number Representation Floats \u00b6 Now we are tasked with finding some sort of representation for numbers that lie between two other binary numbers. We want to accomplish two main goals with our representation: Represent huge numbers as well as little numbers Represent signed numbers Rather than doing something like writing the dot between the binary number to have whole numbers and part numbers, such as \\(0b011.1 = 3 + 0.5 = 3.5\\) . We want to take advantage of the scientific notation for binary numbers as well as the binary that appears after the binary point (is it called binary point... you know, like decimal point. I'll call it the binary point). To do this, we split any floating point number into three distinct parts: Sign: We will encode a 0 to be positive, and 1 to be negative Exponent: Will encode the scientific notation power for binary numbers Mantissa: The numbers after the binary point in scientific notation The number of bits we dedicate to each part depends on the precision, but the sign bit will always be 1 bit. ``","title":"1.3 Floating Point Representation"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.3%20Floating%20Point%20Representation/#13-floating-point-representation","text":"This note explains how one might go about expressing floats in binary or hexadecimal systems using IEEE representation of floating point numbers. Get back to toc CS61C or 1. Number Representation","title":"1.3 Floating Point Representation"},{"location":"EECS/CS%2061C/1.%20Number%20Representation/1.3%20Floating%20Point%20Representation/#floats","text":"Now we are tasked with finding some sort of representation for numbers that lie between two other binary numbers. We want to accomplish two main goals with our representation: Represent huge numbers as well as little numbers Represent signed numbers Rather than doing something like writing the dot between the binary number to have whole numbers and part numbers, such as \\(0b011.1 = 3 + 0.5 = 3.5\\) . We want to take advantage of the scientific notation for binary numbers as well as the binary that appears after the binary point (is it called binary point... you know, like decimal point. I'll call it the binary point). To do this, we split any floating point number into three distinct parts: Sign: We will encode a 0 to be positive, and 1 to be negative Exponent: Will encode the scientific notation power for binary numbers Mantissa: The numbers after the binary point in scientific notation The number of bits we dedicate to each part depends on the precision, but the sign bit will always be 1 bit. ``","title":"Floats"},{"location":"EECS/CS%2061C/10.%20Synchronous%20Digital%20Systems%20%28SDS%29/10.%20Synchonous%20Digital%20Systems%20%28SDS%29/","text":"","title":"10. Synchonous Digital Systems (SDS)"},{"location":"EECS/CS%2061C/11.%20Finite%20State%20Machines%20%28FSMs%29/11.%20Finite%20State%20Machines/","text":"","title":"11. Finite State Machines"},{"location":"EECS/CS%2061C/12.%20RISC-V%20Datapath%20and%20Control%20Logic/12.%20RISC-V%20Datapath%20and%20Control%20Logic/","text":"","title":"12. RISC V Datapath and Control Logic"},{"location":"EECS/CS%2061C/13.%20Datapath%20Performance%20and%20Pipelining/13.%20Datapath%20Performance%20and%20Pipelining/","text":"","title":"13. Datapath Performance and Pipelining"},{"location":"EECS/CS%2061C/14.%20Operating%20Systems/14.%20Operating%20Systems%20%28OS%29/","text":"","title":"14. Operating Systems (OS)"},{"location":"EECS/CS%2061C/15.%20Data%20and%20Thread%20Level%20Parallelism/15.%20Data%20and%20Thread%20Level%20Parallelism/","text":"","title":"15. Data and Thread Level Parallelism"},{"location":"EECS/CS%2061C/16.%20Caches/16.%20Caches/","text":"","title":"16. Caches"},{"location":"EECS/CS%2061C/17.%20Cache%20Coherency/17.%20Cache%20Coherency/","text":"","title":"17. Cache Coherency"},{"location":"EECS/CS%2061C/18.%20Virtual%20Memory/18.%20Virtual%20Memory/","text":"","title":"18. Virtual Memory"},{"location":"EECS/CS%2061C/19.%20Dependability/19.%20Dependability/","text":"","title":"19. Dependability"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.%20C%20Programming/","text":"2. C Programming \u00b6 This note is all about the basics of C programming. The first part of the notes talks about familiar syntax that appears in Java, but then the second part deals with things that Java doesn't do -- pointers and arrays, allocating and freeing, etc. Get back to toc CS61C . Overview of Section \u00b6 We will talk about these items: 2.1 C Similarity to Java Syntax 2.2 Memory Allocation 2.3 Pointers and Arrays 2.4 Stack, Heap, Static, Code","title":"2. C Programming"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.%20C%20Programming/#2-c-programming","text":"This note is all about the basics of C programming. The first part of the notes talks about familiar syntax that appears in Java, but then the second part deals with things that Java doesn't do -- pointers and arrays, allocating and freeing, etc. Get back to toc CS61C .","title":"2. C Programming"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.%20C%20Programming/#overview-of-section","text":"We will talk about these items: 2.1 C Similarity to Java Syntax 2.2 Memory Allocation 2.3 Pointers and Arrays 2.4 Stack, Heap, Static, Code","title":"Overview of Section"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.1%20C%20Similarity%20to%20Java%20Syntax/","text":"2.1 C Similarity to Java Syntax \u00b6 This note serves to show the similarities between C and Java, meant to give the reader an understanding of C syntax from prior knowledge. Get back to toc CS61C or 2. C Programming C Programs \u00b6 C programs inspired the syntax of Java, so if you do find some intuitiveness in C, then this is the reason why. Here, we will look at familiar syntax that will get you started with programming in C, however, you'll need to understand these next three chapters - 2. C Programming , 3. Memory , and 4. More C Programming - to get used to C programs in general. It is much lower level than Java, so things like where memory is stored ( 2.4 Stack, Heap, Static, Code ), dedicating memory and freeing it is also important to know ( 2.2 Memory Allocation and 2.3 Pointers and Arrays ). C programs are compiled into assembly code, you'll learn more about assembly in 5. RISC-V Programming . From Assembly, we will go through two more 3 more processes to get it into something you can run on your device, covered in Variable Declarations, Strings \u00b6 Like in Java, one must declare the type of the variable and the name it will be referenced by. One can either just declare the type, or declare and assign a value. For example, int x = 4; # declaration of a variable and value int y; # declaration of variable y = 1; # assignment of value We can also announce arrays in this syntax, which is slightly different from Java: int arr[] = {1, 2, 3}; # Compiler will infer the size of the array int arr2[2]; # Explicit declaration of array size arr2[0] = 1; # Assignment of values in array. arr2[1] = 3 There are other types you might have seen, bool , double , float , long , etc. Strings are weird in C, there is no such thing as a String type, like in Java. Instead a string in C is thought of as an array of char types. One can create the equivalent of a string in many ways, but so far, there are two ways to make it based on the knowlegde we know right now. char str[] = {'h', 'e', 'l', 'l', '0', '\\0'}; char str2[] = \"hello\"; First off, char types are delimited by single quotes, and strings are delimited by double quotes. Secondly, we have to end the char array with a null terminator: \\0 . The reason why is because when we invoke function calls like determining the string length, C needs to know when it ends. When you declare a string like we did in str2 , the null terminator is tacked on by C when you compile it. However, an array must include a null terminator. The null terminator is a part of the char array size that you declare, so something like char three[4] {'d', 'o', 'g', '\\0'}; has a length of three even though we had to instantiate an array with length 4. The function to determine the size of a char array is strlen(<char array>); There actually is not really any other way to get the size of an array, there is no arr.length like there is in Java. If you ever want to iterate through something like an int array, you probably also need to know the size and pass it in as a parameter to a function. Because of that fact, this brings me up to something that is notorious in C: it doesn't have any checks on if you go out of bounds in an array. Doing something like int bad[] = {1, 2, 3}; bad[4] = 5; is possible to accidentally do. You might be able to get away with this in C, but Java and Python has error checking for this type of stuff. Maybe, you might get lucky, and the compiler will produce a segmentation fault (also known as seg fault). Another point to bring up. C is not really great at telling you what you did wrong. When you code in C, the answer you might get once it gets past a compiler is segmentation fault. We will learn where this happens when we talk about Operating Systems, but essentially, you just attempted to access a restricted area of memory that the Operating System knows about. Unfortunately, sometimes the access you make is out of bounds, but is not restricted, so you won't receive an error. This is what makes programming in C a bit annoying. Function Signatures and Control \u00b6 The classic java syntax for the main function public static void main(String[] args) { <code> } is heavily simplified in C functions. First off, we won't be worried too much about the public and static parts of C functions too much, we still keep track of the return type and the parameter types. The C main function therefore looks a bit more simpler: int main() { <code> return 0; } we have to return 0 at the end. There are things you can include at the C header to have stuff like command-line arguments, like String[] args in Java, but I won't include much detail here; you can jsut look it up if you want to. Other functions are just like this main function: note the return type, indicate the name of the function, indicate the types and names of the parameters of the function. For example, a simple recursive factorial function might look like int factorial(int n) { if (n == 0) { return 1; } else { return n * factorial(n-1); } } You can also see, control is just like Java; there the syntax is exactly the same for while , for , if/else if/else . You might see incrementation as i++ or ++i , or i += 1 . Decrementation is the exact same way: i-- , --i , i -= 1 . Summary \u00b6 So these are the building blocks of C programs, but now it is time to get into all the details of a low-level programming language like C. We won't really get into programming in C so much as we did in Java or Python, since the skills of coding carry over from language to language. We are more focused on the concepts and using C as the vehicle to play around with the concepts. So in the next section, we will be looking at things you take for granted in languages like Java or Python. Go to next section 2.2 Memory Allocation","title":"2.1 C Similarity to Java Syntax"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.1%20C%20Similarity%20to%20Java%20Syntax/#21-c-similarity-to-java-syntax","text":"This note serves to show the similarities between C and Java, meant to give the reader an understanding of C syntax from prior knowledge. Get back to toc CS61C or 2. C Programming","title":"2.1 C Similarity to Java Syntax"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.1%20C%20Similarity%20to%20Java%20Syntax/#c-programs","text":"C programs inspired the syntax of Java, so if you do find some intuitiveness in C, then this is the reason why. Here, we will look at familiar syntax that will get you started with programming in C, however, you'll need to understand these next three chapters - 2. C Programming , 3. Memory , and 4. More C Programming - to get used to C programs in general. It is much lower level than Java, so things like where memory is stored ( 2.4 Stack, Heap, Static, Code ), dedicating memory and freeing it is also important to know ( 2.2 Memory Allocation and 2.3 Pointers and Arrays ). C programs are compiled into assembly code, you'll learn more about assembly in 5. RISC-V Programming . From Assembly, we will go through two more 3 more processes to get it into something you can run on your device, covered in","title":"C Programs"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.1%20C%20Similarity%20to%20Java%20Syntax/#variable-declarations-strings","text":"Like in Java, one must declare the type of the variable and the name it will be referenced by. One can either just declare the type, or declare and assign a value. For example, int x = 4; # declaration of a variable and value int y; # declaration of variable y = 1; # assignment of value We can also announce arrays in this syntax, which is slightly different from Java: int arr[] = {1, 2, 3}; # Compiler will infer the size of the array int arr2[2]; # Explicit declaration of array size arr2[0] = 1; # Assignment of values in array. arr2[1] = 3 There are other types you might have seen, bool , double , float , long , etc. Strings are weird in C, there is no such thing as a String type, like in Java. Instead a string in C is thought of as an array of char types. One can create the equivalent of a string in many ways, but so far, there are two ways to make it based on the knowlegde we know right now. char str[] = {'h', 'e', 'l', 'l', '0', '\\0'}; char str2[] = \"hello\"; First off, char types are delimited by single quotes, and strings are delimited by double quotes. Secondly, we have to end the char array with a null terminator: \\0 . The reason why is because when we invoke function calls like determining the string length, C needs to know when it ends. When you declare a string like we did in str2 , the null terminator is tacked on by C when you compile it. However, an array must include a null terminator. The null terminator is a part of the char array size that you declare, so something like char three[4] {'d', 'o', 'g', '\\0'}; has a length of three even though we had to instantiate an array with length 4. The function to determine the size of a char array is strlen(<char array>); There actually is not really any other way to get the size of an array, there is no arr.length like there is in Java. If you ever want to iterate through something like an int array, you probably also need to know the size and pass it in as a parameter to a function. Because of that fact, this brings me up to something that is notorious in C: it doesn't have any checks on if you go out of bounds in an array. Doing something like int bad[] = {1, 2, 3}; bad[4] = 5; is possible to accidentally do. You might be able to get away with this in C, but Java and Python has error checking for this type of stuff. Maybe, you might get lucky, and the compiler will produce a segmentation fault (also known as seg fault). Another point to bring up. C is not really great at telling you what you did wrong. When you code in C, the answer you might get once it gets past a compiler is segmentation fault. We will learn where this happens when we talk about Operating Systems, but essentially, you just attempted to access a restricted area of memory that the Operating System knows about. Unfortunately, sometimes the access you make is out of bounds, but is not restricted, so you won't receive an error. This is what makes programming in C a bit annoying.","title":"Variable Declarations, Strings"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.1%20C%20Similarity%20to%20Java%20Syntax/#function-signatures-and-control","text":"The classic java syntax for the main function public static void main(String[] args) { <code> } is heavily simplified in C functions. First off, we won't be worried too much about the public and static parts of C functions too much, we still keep track of the return type and the parameter types. The C main function therefore looks a bit more simpler: int main() { <code> return 0; } we have to return 0 at the end. There are things you can include at the C header to have stuff like command-line arguments, like String[] args in Java, but I won't include much detail here; you can jsut look it up if you want to. Other functions are just like this main function: note the return type, indicate the name of the function, indicate the types and names of the parameters of the function. For example, a simple recursive factorial function might look like int factorial(int n) { if (n == 0) { return 1; } else { return n * factorial(n-1); } } You can also see, control is just like Java; there the syntax is exactly the same for while , for , if/else if/else . You might see incrementation as i++ or ++i , or i += 1 . Decrementation is the exact same way: i-- , --i , i -= 1 .","title":"Function Signatures and Control"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.1%20C%20Similarity%20to%20Java%20Syntax/#summary","text":"So these are the building blocks of C programs, but now it is time to get into all the details of a low-level programming language like C. We won't really get into programming in C so much as we did in Java or Python, since the skills of coding carry over from language to language. We are more focused on the concepts and using C as the vehicle to play around with the concepts. So in the next section, we will be looking at things you take for granted in languages like Java or Python. Go to next section 2.2 Memory Allocation","title":"Summary"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.2%20Memory%20Allocation/","text":"2.2 Memory Allocation \u00b6 In this note, we talk about memory allocation using calls to malloc , calloc , and realloc and also talking about freeing this memory allocation using free . First, we will talk about pointers and addresses. Get back to toc CS61C or 2. C Programming . Introduction to Pointers and Addresses \u00b6 These are probably not new terms to you, but its use is probably new. Like in CS61A, we used pointers to represent the location where things like lists, objects, functions are stored. In Python, when we did something like x = [1, 2, 3] we create a box and pointer diagram where x really contains the address of the list in memory, but then it is visually represented as a pointer. Pointers and addresses conceptually are just the same idea in C, but now we will have to explicitly use them. I can declare a pointer type with the asterisk * . For example, a pointer to an integer can be declared as int* pint = 5; and it can be accessed by dereferencing the pointer, also using the asterisk: int* pint = 5; *pint = *pint + 1; # Says that the dereference of pint plus 1 is assigned to the dereference of pint. In other words, the value 6 is stores at where pint points to. You can specify the address of something with the ampersand symbol & . For example, if I declare an integer x , I can assign the address of x to be assigned to a integer pointer y : int x = 1; int* y = &x; int t = *y + x; # t stores the value 2. You can kind of see it be a little bit confusing, using both the asterisk as a sort of variable type and dereferencing operator. Allocation \u00b6 Let's take a sidestep to Java and Python really quickly. Remember when you make objects, you need to call a constructor. What really happens is that Java or Python automatically creates the necessary space based on the type you tell it to be, and then gives you a pointer to the object to which then you can assign to a variable name. C makes this process a bit more explicit with the malloc , calloc , and realloc . Let's look at the syntax of these allocation methods: - malloc: returns a pointer to the allocated memory or NULL if the request fails. It requries the size of the memory block. It's syntax is void *malloc(size_t size) . All memory here is uninitialized and unknown, but you can assign parts of this allocated memory to make the memory have defined behavior later. - calloc: returns a pointer to the allocated memory or NULL if the request fails. It differs from malloc in that calloc will set the allocated memory to zero. Its syntax is also a little bit different: void *calloc(size_t nitems, size_t size) which specifies how many items of what size you want. - realloc: Attempts to resize the memory block pointed to by ptr that was previously allocated with a call to malloc or calloc , or NULL if this reallocation request fails.. Its syntax is void *realloc(void *ptr, size_t size) . Now let's get used these requests to allocate memory. I think the main point of confusion right now if you haven't seen it before is the size field of the function. Now, you'll learn so much about sizes of types throughout this class, and more about it in 3. Memory , but as of now you just need to know a few sizes: - An int is 4 bytes of memory - A short is 2 bytes of memory - A long is 8 bytes of memory - A char is 1 byte of memory - Any pointer's size depends on the system. You'll face a 32-bit system more often, which designates a pointer to have a size of 4 bytes, but you may see 64-bit systems, which designates 8 bytes for a pointer. We will also learn more types along the way, such as sizes of more complicated data structures in 4. More C Programming . So, if you wanted to allocate a piece of memory that can contain 2 integer types, you might want to try int *pint = malloc(8); # alternatively, we can use the sizeof(<type>) function, which tells you the size of a type: int *pint2 = malloc(2 * sizeof(int)); Now we have two pointers of allocated memory. We can assign values to it just like an array. The relative spacing of the allocated memory is automatically known when you index. For int pointers every index has 4-byte spacing, and for char pointers, every index has 1-byte spacing. For example, we can do pint[1] = 2; # Another way to write memory is through dereferencing. This syntax is a bit old-fashioned, but it exists *(pint + 1) = 3; # assigns 3 to the index 1 of this allocated memory block. We will take a deep dive into pointers and arrays in the next section 2.3 Pointers and Arrays , but right now an introduction is good to know. Memory Leaks and Free \u00b6 What is different from this type of memory that has been allocated is that we have to tell our system to free memory. If we do not free the memory that has been allocated, you'll have memory leaks. Memory leaks are gradual deterioration of system performance that occurs when there is a failure to free memory segments allocated to RAM. Maybe you've heard of the idea of restarting your computer to maintain performance. This is exactly the reason why: you need to restart your system so that all the memory leaks get fixed when your system boots up. What is unfortunate is that C will not tell you if you are leaking memory. You need to use other programs like Valgrind to tell you if you are leaking memory. So, to free memory, you simply have to call free over the variable name. int *ptr = calloc(4, sizeof(int)); #allocates 4 integers to ptr, each set to 0. free(ptr) # frees the memory allocated to ptr int *nofree = malloc(3 * sizeof(char)); # we might do stuff with nofree, but if we do not free it by the end of the program, it is a memory leak (like I am going to do right now). When you do stuff like pointers to pointer (yes those are things, such as matrices or lists of pointers), you cannot simply free the list and expect it to free everything that is contained in it. You have to free every single pointer allocated, so that means going through your matrix, and freeing every pointer to integer arrays, then free your matrix pointer. Again, C will not tell you if you leaked memory, but if you don't free your memory, You cannot simply free memory ever once your program finishes running, and so your system will slow down if you leak too much. You can restart your system to free this memory. Summary \u00b6 So now, you are getting into the intricacies of C programming. It's definitely annoying that C won't tell you if you are wrong all the time, but that is what low-level programming is all about. When performance matters, you wish you can have control of everything, from control to allocation and freeing memory. Languages like Java and Python have garbage collectors that do the freeing of memory for you, but it is at the expense of being a slower language. Go to next section: 2.3 Pointers and Arrays","title":"2.2 Memory Allocation"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.2%20Memory%20Allocation/#22-memory-allocation","text":"In this note, we talk about memory allocation using calls to malloc , calloc , and realloc and also talking about freeing this memory allocation using free . First, we will talk about pointers and addresses. Get back to toc CS61C or 2. C Programming .","title":"2.2 Memory Allocation"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.2%20Memory%20Allocation/#introduction-to-pointers-and-addresses","text":"These are probably not new terms to you, but its use is probably new. Like in CS61A, we used pointers to represent the location where things like lists, objects, functions are stored. In Python, when we did something like x = [1, 2, 3] we create a box and pointer diagram where x really contains the address of the list in memory, but then it is visually represented as a pointer. Pointers and addresses conceptually are just the same idea in C, but now we will have to explicitly use them. I can declare a pointer type with the asterisk * . For example, a pointer to an integer can be declared as int* pint = 5; and it can be accessed by dereferencing the pointer, also using the asterisk: int* pint = 5; *pint = *pint + 1; # Says that the dereference of pint plus 1 is assigned to the dereference of pint. In other words, the value 6 is stores at where pint points to. You can specify the address of something with the ampersand symbol & . For example, if I declare an integer x , I can assign the address of x to be assigned to a integer pointer y : int x = 1; int* y = &x; int t = *y + x; # t stores the value 2. You can kind of see it be a little bit confusing, using both the asterisk as a sort of variable type and dereferencing operator.","title":"Introduction to Pointers and Addresses"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.2%20Memory%20Allocation/#allocation","text":"Let's take a sidestep to Java and Python really quickly. Remember when you make objects, you need to call a constructor. What really happens is that Java or Python automatically creates the necessary space based on the type you tell it to be, and then gives you a pointer to the object to which then you can assign to a variable name. C makes this process a bit more explicit with the malloc , calloc , and realloc . Let's look at the syntax of these allocation methods: - malloc: returns a pointer to the allocated memory or NULL if the request fails. It requries the size of the memory block. It's syntax is void *malloc(size_t size) . All memory here is uninitialized and unknown, but you can assign parts of this allocated memory to make the memory have defined behavior later. - calloc: returns a pointer to the allocated memory or NULL if the request fails. It differs from malloc in that calloc will set the allocated memory to zero. Its syntax is also a little bit different: void *calloc(size_t nitems, size_t size) which specifies how many items of what size you want. - realloc: Attempts to resize the memory block pointed to by ptr that was previously allocated with a call to malloc or calloc , or NULL if this reallocation request fails.. Its syntax is void *realloc(void *ptr, size_t size) . Now let's get used these requests to allocate memory. I think the main point of confusion right now if you haven't seen it before is the size field of the function. Now, you'll learn so much about sizes of types throughout this class, and more about it in 3. Memory , but as of now you just need to know a few sizes: - An int is 4 bytes of memory - A short is 2 bytes of memory - A long is 8 bytes of memory - A char is 1 byte of memory - Any pointer's size depends on the system. You'll face a 32-bit system more often, which designates a pointer to have a size of 4 bytes, but you may see 64-bit systems, which designates 8 bytes for a pointer. We will also learn more types along the way, such as sizes of more complicated data structures in 4. More C Programming . So, if you wanted to allocate a piece of memory that can contain 2 integer types, you might want to try int *pint = malloc(8); # alternatively, we can use the sizeof(<type>) function, which tells you the size of a type: int *pint2 = malloc(2 * sizeof(int)); Now we have two pointers of allocated memory. We can assign values to it just like an array. The relative spacing of the allocated memory is automatically known when you index. For int pointers every index has 4-byte spacing, and for char pointers, every index has 1-byte spacing. For example, we can do pint[1] = 2; # Another way to write memory is through dereferencing. This syntax is a bit old-fashioned, but it exists *(pint + 1) = 3; # assigns 3 to the index 1 of this allocated memory block. We will take a deep dive into pointers and arrays in the next section 2.3 Pointers and Arrays , but right now an introduction is good to know.","title":"Allocation"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.2%20Memory%20Allocation/#memory-leaks-and-free","text":"What is different from this type of memory that has been allocated is that we have to tell our system to free memory. If we do not free the memory that has been allocated, you'll have memory leaks. Memory leaks are gradual deterioration of system performance that occurs when there is a failure to free memory segments allocated to RAM. Maybe you've heard of the idea of restarting your computer to maintain performance. This is exactly the reason why: you need to restart your system so that all the memory leaks get fixed when your system boots up. What is unfortunate is that C will not tell you if you are leaking memory. You need to use other programs like Valgrind to tell you if you are leaking memory. So, to free memory, you simply have to call free over the variable name. int *ptr = calloc(4, sizeof(int)); #allocates 4 integers to ptr, each set to 0. free(ptr) # frees the memory allocated to ptr int *nofree = malloc(3 * sizeof(char)); # we might do stuff with nofree, but if we do not free it by the end of the program, it is a memory leak (like I am going to do right now). When you do stuff like pointers to pointer (yes those are things, such as matrices or lists of pointers), you cannot simply free the list and expect it to free everything that is contained in it. You have to free every single pointer allocated, so that means going through your matrix, and freeing every pointer to integer arrays, then free your matrix pointer. Again, C will not tell you if you leaked memory, but if you don't free your memory, You cannot simply free memory ever once your program finishes running, and so your system will slow down if you leak too much. You can restart your system to free this memory.","title":"Memory Leaks and Free"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.2%20Memory%20Allocation/#summary","text":"So now, you are getting into the intricacies of C programming. It's definitely annoying that C won't tell you if you are wrong all the time, but that is what low-level programming is all about. When performance matters, you wish you can have control of everything, from control to allocation and freeing memory. Languages like Java and Python have garbage collectors that do the freeing of memory for you, but it is at the expense of being a slower language. Go to next section: 2.3 Pointers and Arrays","title":"Summary"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.3%20Pointers%20and%20Arrays/","text":"2.4 Pointers and Arrays \u00b6 Now we will look into understanding C pointers and arrays, taking several different looks at the concept and getting used to how it works. Get back to toc CS61C or 2. C Programming","title":"2.4 Pointers and Arrays"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.3%20Pointers%20and%20Arrays/#24-pointers-and-arrays","text":"Now we will look into understanding C pointers and arrays, taking several different looks at the concept and getting used to how it works. Get back to toc CS61C or 2. C Programming","title":"2.4 Pointers and Arrays"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.4%20Stack%2C%20Heap%2C%20Static%2C%20Code/","text":"2.2 Stack, Heap, Static, Code \u00b6 This note serves the purpose of explaining how memory can be modeled as an array, where specific segments of the array mean something different. This will be important when talking about memory allocation [2.3 Memory Allocation] as well as pointers and arrays 2.3 Pointers and Arrays , Get back to toc CS61C or 2. C Programming Memory \u00b6 Our model of memory is an array. You can access elements of an array, but this time, the indexes are the addresses, and the elements are the actual data inside. In this class, we will use a bottom-up model, which you will understand in a bit. Here is a diagram to see this memory array. Now, if we were to simply put memory where ever we wanted to, that would be a bit disorganized. Code that you write should also be in this memory array, so it might make sense to group the code segments nearby each other. How about variable declarations? When you open up functions, where should its location be stored? It seems like we need to group data together based on a couple of features. That leads us to Stack, Heap, Static, and Code: I'll first write a basic definition, and then write up a more complete definition at the bottom of this note. Stack: local variables inside functions, located at the top of the stack, grows downwards Heap: space requested for dynamic data via malloc or calloc. Resizes dynamically, grows upwards Static/Data: variables declared outside functions, does not grow. Loaded when the program starts, though can be modified Code: loaded when program starts. It is literally code. One thing to note is that the stack grows down, and the heap grows up. We place the heap right above static/data (which is above code), and the stack begins at the very top. Here is a diagram showing relatively where memory would live. Remember that memory is simply just stored in an array, with the addresses being the indices of this array. When you ask for the address of x using &x , you are saying \"what index of this memory array is x stored at.\" Dereferencing a pointer to x is equivalent in saying \"what value is stored at the address of x , or dereferencing_pointer = memory[address] . That is one way to interpret it. Therefore, a statement like int x = *ptr; is like saying int x = memory(ptr_address); .","title":"2.2 Stack, Heap, Static, Code"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.4%20Stack%2C%20Heap%2C%20Static%2C%20Code/#22-stack-heap-static-code","text":"This note serves the purpose of explaining how memory can be modeled as an array, where specific segments of the array mean something different. This will be important when talking about memory allocation [2.3 Memory Allocation] as well as pointers and arrays 2.3 Pointers and Arrays , Get back to toc CS61C or 2. C Programming","title":"2.2 Stack, Heap, Static, Code"},{"location":"EECS/CS%2061C/2.%20C%20Programming/2.4%20Stack%2C%20Heap%2C%20Static%2C%20Code/#memory","text":"Our model of memory is an array. You can access elements of an array, but this time, the indexes are the addresses, and the elements are the actual data inside. In this class, we will use a bottom-up model, which you will understand in a bit. Here is a diagram to see this memory array. Now, if we were to simply put memory where ever we wanted to, that would be a bit disorganized. Code that you write should also be in this memory array, so it might make sense to group the code segments nearby each other. How about variable declarations? When you open up functions, where should its location be stored? It seems like we need to group data together based on a couple of features. That leads us to Stack, Heap, Static, and Code: I'll first write a basic definition, and then write up a more complete definition at the bottom of this note. Stack: local variables inside functions, located at the top of the stack, grows downwards Heap: space requested for dynamic data via malloc or calloc. Resizes dynamically, grows upwards Static/Data: variables declared outside functions, does not grow. Loaded when the program starts, though can be modified Code: loaded when program starts. It is literally code. One thing to note is that the stack grows down, and the heap grows up. We place the heap right above static/data (which is above code), and the stack begins at the very top. Here is a diagram showing relatively where memory would live. Remember that memory is simply just stored in an array, with the addresses being the indices of this array. When you ask for the address of x using &x , you are saying \"what index of this memory array is x stored at.\" Dereferencing a pointer to x is equivalent in saying \"what value is stored at the address of x , or dereferencing_pointer = memory[address] . That is one way to interpret it. Therefore, a statement like int x = *ptr; is like saying int x = memory(ptr_address); .","title":"Memory"},{"location":"EECS/CS%2061C/3.%20Memory/3.%20Memory/","text":"3. Memory \u00b6 This note is taking a sidestep into understanding how memory is stored. We will talk about things like sizes of types, memory alignment, and endianness. Get back to toc CS61C . Overview of Section \u00b6 We will talk about these items: - 3.1 Sizes of Types, Casting - 3.2 Memory Alignment - 3.3 Endianness","title":"3. Memory"},{"location":"EECS/CS%2061C/3.%20Memory/3.%20Memory/#3-memory","text":"This note is taking a sidestep into understanding how memory is stored. We will talk about things like sizes of types, memory alignment, and endianness. Get back to toc CS61C .","title":"3. Memory"},{"location":"EECS/CS%2061C/3.%20Memory/3.%20Memory/#overview-of-section","text":"We will talk about these items: - 3.1 Sizes of Types, Casting - 3.2 Memory Alignment - 3.3 Endianness","title":"Overview of Section"},{"location":"EECS/CS%2061C/3.%20Memory/3.1%20Sizes%20of%20Types%2C%20Casting/","text":"","title":"3.1 Sizes of Types, Casting"},{"location":"EECS/CS%2061C/3.%20Memory/3.2%20Memory%20Alignment/","text":"","title":"3.2 Memory Alignment"},{"location":"EECS/CS%2061C/3.%20Memory/3.3%20Endianness/","text":"","title":"3.3 Endianness"},{"location":"EECS/CS%2061C/4.%20More%20C%20Programming/4.%20More%20C%20Programming/","text":"4. More C Programming \u00b6 Now that we have further knowledge on memory stuff, in these notes, let's return back to C programming and get through some more quirks of the language. Get back to toc CS61C . Overview of Section \u00b6 We will talk about these items: - 4.1 Higher-Order Functions in C - 4.2 Structs and Unions - 4.3 Defines - 4.4 Programming in C","title":"4. More C Programming"},{"location":"EECS/CS%2061C/4.%20More%20C%20Programming/4.%20More%20C%20Programming/#4-more-c-programming","text":"Now that we have further knowledge on memory stuff, in these notes, let's return back to C programming and get through some more quirks of the language. Get back to toc CS61C .","title":"4. More C Programming"},{"location":"EECS/CS%2061C/4.%20More%20C%20Programming/4.%20More%20C%20Programming/#overview-of-section","text":"We will talk about these items: - 4.1 Higher-Order Functions in C - 4.2 Structs and Unions - 4.3 Defines - 4.4 Programming in C","title":"Overview of Section"},{"location":"EECS/CS%2061C/4.%20More%20C%20Programming/4.1%20Higher-Order%20Functions%20in%20C/","text":"","title":"4.1 Higher Order Functions in C"},{"location":"EECS/CS%2061C/4.%20More%20C%20Programming/4.2%20Structs%20and%20Unions/","text":"","title":"4.2 Structs and Unions"},{"location":"EECS/CS%2061C/4.%20More%20C%20Programming/4.3%20Defines/","text":"","title":"4.3 Defines"},{"location":"EECS/CS%2061C/4.%20More%20C%20Programming/4.4%20Programming%20in%20C/","text":"","title":"4.4 Programming in C"},{"location":"EECS/CS%2061C/5.%20RISC-V%20Programming/5.%20RISC-V%20Programming/","text":"5. RISC-V Programming \u00b6 These notes will talk about the basics of prorgramming in RISC-V, an assembly language. Get back to toc CS61C . Overview of Section \u00b6 We will talk about these items: 5.1 RISC-V Registers 5.2 Arithmetic and Bitwise Operators 5.3 Branching 5.4 Loads and Stores 5.5 Other RISC-V Instructions","title":"5. RISC-V Programming"},{"location":"EECS/CS%2061C/5.%20RISC-V%20Programming/5.%20RISC-V%20Programming/#5-risc-v-programming","text":"These notes will talk about the basics of prorgramming in RISC-V, an assembly language. Get back to toc CS61C .","title":"5. RISC-V Programming"},{"location":"EECS/CS%2061C/5.%20RISC-V%20Programming/5.%20RISC-V%20Programming/#overview-of-section","text":"We will talk about these items: 5.1 RISC-V Registers 5.2 Arithmetic and Bitwise Operators 5.3 Branching 5.4 Loads and Stores 5.5 Other RISC-V Instructions","title":"Overview of Section"},{"location":"EECS/CS%2061C/5.%20RISC-V%20Programming/5.1%20RISC-V%20Registers/","text":"","title":"5.1 RISC V Registers"},{"location":"EECS/CS%2061C/5.%20RISC-V%20Programming/5.2%20Arithmetic%20and%20Bitwise%20Operators/","text":"","title":"5.2 Arithmetic and Bitwise Operators"},{"location":"EECS/CS%2061C/5.%20RISC-V%20Programming/5.3%20Branching/","text":"","title":"5.3 Branching"},{"location":"EECS/CS%2061C/5.%20RISC-V%20Programming/5.4%20Loads%20and%20Stores/","text":"","title":"5.4 Loads and Stores"},{"location":"EECS/CS%2061C/5.%20RISC-V%20Programming/5.5%20Other%20RISC-V%20Instructions/","text":"","title":"5.5 Other RISC V Instructions"},{"location":"EECS/CS%2061C/6.%20RISC-V%20Calling%20Convention/6.%20RISC-V%20Calling%20Convention/","text":"6. RISC-V Calling Convention \u00b6 Now that we understand how RISC-V programs are made, let's see how we might use this knowledge to implement bigger projects using assembly code. To do this, we need to introduce a calling convention because functions that you implement may accidentally overwrite data in another function because registers are in the scope of all functions. How might we deal with that? Calling Convention is the answer. Get back to toc CS61C . Overview of Section \u00b6 We will talk about these items: 6.1 RISC-V Register Names 6.2 The Stack Pointer, Callee, Caller Conventions 6.3 An Example RISC-V Code with Calling Convention 6.4 Recursive Functions in RISC-V","title":"6. RISC-V Calling Convention"},{"location":"EECS/CS%2061C/6.%20RISC-V%20Calling%20Convention/6.%20RISC-V%20Calling%20Convention/#6-risc-v-calling-convention","text":"Now that we understand how RISC-V programs are made, let's see how we might use this knowledge to implement bigger projects using assembly code. To do this, we need to introduce a calling convention because functions that you implement may accidentally overwrite data in another function because registers are in the scope of all functions. How might we deal with that? Calling Convention is the answer. Get back to toc CS61C .","title":"6. RISC-V Calling Convention"},{"location":"EECS/CS%2061C/6.%20RISC-V%20Calling%20Convention/6.%20RISC-V%20Calling%20Convention/#overview-of-section","text":"We will talk about these items: 6.1 RISC-V Register Names 6.2 The Stack Pointer, Callee, Caller Conventions 6.3 An Example RISC-V Code with Calling Convention 6.4 Recursive Functions in RISC-V","title":"Overview of Section"},{"location":"EECS/CS%2061C/6.%20RISC-V%20Calling%20Convention/6.1%20RISC-V%20Register%20Names/","text":"","title":"6.1 RISC V Register Names"},{"location":"EECS/CS%2061C/6.%20RISC-V%20Calling%20Convention/6.2%20The%20Stack%20Pointer%2C%20Callee%2C%20Caller%20Conventions/","text":"","title":"6.2 The Stack Pointer, Callee, Caller Conventions"},{"location":"EECS/CS%2061C/6.%20RISC-V%20Calling%20Convention/6.3%20An%20Example%20RISC-V%20Code%20with%20Calling%20Convention/","text":"","title":"6.3 An Example RISC V Code with Calling Convention"},{"location":"EECS/CS%2061C/6.%20RISC-V%20Calling%20Convention/6.4%20Recursive%20Functions%20in%20RISC-V/","text":"","title":"6.4 Recursive Functions in RISC V"},{"location":"EECS/CS%2061C/7.%20RISC-V%20Instruction%20Formats/7.%20RISC-V%20Instruction%20Formats/","text":"7. RISC-V Instruction Formats \u00b6 Let's get one level lower and actually now get into the bits being the instructions. We won't be programming in bits, though, just see how to translate the main types of instructions: arithmetic, branching, jumps, calls to other functions. One reason why we need to understand this is when we get another level lower and talk about logic gates, where it will culminate into wiring up a CPU to handle all the RISC-V instructions. Get back to toc CS61C . Overview of Section \u00b6 We will talk about these items: [[7.1 Anatomy of a RISC-V instruction]] [[7.2 R and I Types]] [[7.3 B and S Types]] [[7.4 J and U Types]] 7.5 Self-Modifying Code","title":"7. RISC-V Instruction Formats"},{"location":"EECS/CS%2061C/7.%20RISC-V%20Instruction%20Formats/7.%20RISC-V%20Instruction%20Formats/#7-risc-v-instruction-formats","text":"Let's get one level lower and actually now get into the bits being the instructions. We won't be programming in bits, though, just see how to translate the main types of instructions: arithmetic, branching, jumps, calls to other functions. One reason why we need to understand this is when we get another level lower and talk about logic gates, where it will culminate into wiring up a CPU to handle all the RISC-V instructions. Get back to toc CS61C .","title":"7. RISC-V Instruction Formats"},{"location":"EECS/CS%2061C/7.%20RISC-V%20Instruction%20Formats/7.%20RISC-V%20Instruction%20Formats/#overview-of-section","text":"We will talk about these items: [[7.1 Anatomy of a RISC-V instruction]] [[7.2 R and I Types]] [[7.3 B and S Types]] [[7.4 J and U Types]] 7.5 Self-Modifying Code","title":"Overview of Section"},{"location":"EECS/CS%2061C/7.%20RISC-V%20Instruction%20Formats/7.5%20Self-Modifying%20Code/","text":"7.5 Self-Modifying Code \u00b6 In this note, I will talk about the legendary question I had on my 61C Final, where only 2% of the people got a non-zero score (I was part of the 98% that got 0 points). However, I think knowing this concept is a super interesting one, because it relies on understanding the instruction formats and changing the instructions themselves through bit manipulation. The Problem On Summer 22 Final \u00b6 Here is the problem. RISC-V Instructions \u00b6 Here is the basic idea. You know that instructions are represented as bits, and you should know how to convert a RISC-V instruction into bits. If we so happened to change the bits like the funct3 or funct7 of an instruction, it changes the instruction to a different instruction. Let's take advantage of this fact.","title":"7.5 Self-Modifying Code"},{"location":"EECS/CS%2061C/7.%20RISC-V%20Instruction%20Formats/7.5%20Self-Modifying%20Code/#75-self-modifying-code","text":"In this note, I will talk about the legendary question I had on my 61C Final, where only 2% of the people got a non-zero score (I was part of the 98% that got 0 points). However, I think knowing this concept is a super interesting one, because it relies on understanding the instruction formats and changing the instructions themselves through bit manipulation.","title":"7.5 Self-Modifying Code"},{"location":"EECS/CS%2061C/7.%20RISC-V%20Instruction%20Formats/7.5%20Self-Modifying%20Code/#the-problem-on-summer-22-final","text":"Here is the problem.","title":"The Problem On Summer 22 Final"},{"location":"EECS/CS%2061C/7.%20RISC-V%20Instruction%20Formats/7.5%20Self-Modifying%20Code/#risc-v-instructions","text":"Here is the basic idea. You know that instructions are represented as bits, and you should know how to convert a RISC-V instruction into bits. If we so happened to change the bits like the funct3 or funct7 of an instruction, it changes the instruction to a different instruction. Let's take advantage of this fact.","title":"RISC-V Instructions"},{"location":"EECS/CS%2061C/8.%20Compiler%2C%20Assembler%2C%20Linker%2C%20Loader%20%28CALL%29/8.%20Compiler%2C%20Assembler%2C%20Linker%2C%20Loader%20%28CALL%29/","text":"","title":"8. Compiler, Assembler, Linker, Loader (CALL)"},{"location":"EECS/CS%2061C/9.%20Combinatorial%20Logic%2C%20Boolean%20Algebra/9.%20Combinatorial%20Logic%2C%20Boolean%20Algebra/","text":"","title":"9. Combinatorial Logic, Boolean Algebra"},{"location":"EECS/EECS%20151/toc%20EECS151/","text":"Table of Contents \u00b6 **EECS 151: Introduction to Digital Design and Integrated Circuits \u00b6 This note is a table of contents, for easy navigation to other notes. Get back to main toc EECS 1. Introduction to EECS 151 2. Design Abstraction 3. Metrics and Verilog 4. Verilog II 6. Combinational Logic II 7. Finite State Machines 8. RISC-V Datapath I 9. RISC-V Datapath II A. Verilog","title":"Table of Contents"},{"location":"EECS/EECS%20151/toc%20EECS151/#table-of-contents","text":"","title":"Table of Contents"},{"location":"EECS/EECS%20151/toc%20EECS151/#eecs-151-introduction-to-digital-design-and-integrated-circuits","text":"This note is a table of contents, for easy navigation to other notes. Get back to main toc EECS 1. Introduction to EECS 151 2. Design Abstraction 3. Metrics and Verilog 4. Verilog II 6. Combinational Logic II 7. Finite State Machines 8. RISC-V Datapath I 9. RISC-V Datapath II A. Verilog","title":"**EECS 151: Introduction to Digital Design and Integrated Circuits"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/","text":"1. Introduction to EECS 151 \u00b6 This note is about the first lecture in EECS 151, taught by Professor Sophia Shao. Class Goals \u00b6 Introduction to digital integrated circuit and system engineering. The key concepts needed to be a good digital system designer, and discover your own creativity. Learn abstractions that allow reasoning about design behavior. Manage design complexity through abstraction and understanding of tools. Allow analysis and optimization of the circuit's performance, power, cost, etc. Learn how to make sure your circuit and system works. There are way more ways to mess up a chip than to get it right. Course Focuse \u00b6 Prerequisites \u00b6 CS 61C - C, Boolean Logic, RISC-V ISA Will review combinational and sequential logic and RISC-V datapath, pipelining (but in more depth) EECS 16A/B - Digital gates, RC networks We will review transistor operation and design of CMOS logic Follow-Up Courses \u00b6 CS 61C --> EECS 151 --> CS 152 --> any graduate-level course in architecture/digital systems EECS 151 + EE 140 is a springboard into integrate circuits Tapeout class: EE 194 (special topic course), spring semester class. Bringout class: follow-up to tapeout, where the chip is produced and then we test it. Prerequisites for tapeout and bringout: EECS 151 or EE 140. 152 not required. Divide and conquer approach, so your background will be what you design. RISC-V 32-bit ISA \u00b6 End of EECS 151 \u00b6 You wiill be able to build a complex digital syste Administrativia \u00b6 Lectures: Slides available before lecture, lectures recorded, posted after lecture. Textbooks: Digital Design and Computer Architecture, Digital Integrated Circuits: A Design Perspective, CMOS VLSI Design Discussions: Start next Friday. Review of important concepts from lecture, help with problem sets. Homework: Roughly 10 problem sets. Posted on Thursday, Due Friday, 8 days later Essential to understanding of material Late policy: 7 days for problem sets, 20% point reduction per day after slip day Solutions poster the week after due date Labs: Late policy: 14 slip days for labs, 20% point reduction per day after slip day 6 lab exercises, done solo. Lab report due by next lab session 7 week design project, done with partner. Project demo/interview RRR week, project report due RRR week Both labs: you will learn Verilog. The design component is the same. The tooling is different. Also different in how to interpret report using the different applications and tools. Midterm + Final Midterm: Late October 7-9pm Final: Wed, 12/14, 8-11am No alternative midterm/final. But may allow students to take the final right after the official slot. All exams are closed book with one double sided sheet of notes on midterm, two for the final. Clobber: Override your midterm score with the score on the final if you perform better on the final The reverse is not true - you must take the entire final exam, regardless of your score Class is not curved. Tips on How to Get a Good Grade \u00b6 The lecture material is not the most challenging part of the couse. You should be able to understand everything as we go along. Do not fall behind in lecture and tell yourself you \"will figure it out later from the notes or book\". Slides will be online before the lecture. Study them before class. Ask question in class and stay involved in the class - that will help you understand. Come to OH to check your understanding or to ask question. Complete all the homework. Take labs very seriously. Digital Integrated Circuits and Systems: Past, Present, and Future \u00b6 People tend to think of HW as an independent topic, but it is always interconnected with software. Hardware drives software. There are connections to the entire stack and different markets Moore's Law \u00b6 In 1965, Gordon Moore noted that the number of transistors on a chip doubled every 12 months. He made a prediction that semiconductor technology will double its effectiveness every 12 month. Now it has changed to about every 24 months. How can we reduce the cost to fabricate more transistors? It is still there in that we are getting more transistors, but the cost is not going down. That is where people say it is dying. We look at the density: transistors/unit area. It has been growing consistently. Cost is the biggest challenge to deal with to uphold Moore's law The Other Trends Power! \u00b6 Dennard Scaling (1974) \u00b6 Voltages (and currents) should be scaled proportionally to the dimensions of the transistor. And, in theory, power density constant! How we can make smaller transistors with same power density. The Other Demon: Design Cost \u00b6 Get to next section: 2. Design Abstraction","title":"1. Introduction to EECS 151"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#1-introduction-to-eecs-151","text":"This note is about the first lecture in EECS 151, taught by Professor Sophia Shao.","title":"1. Introduction to EECS 151"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#class-goals","text":"Introduction to digital integrated circuit and system engineering. The key concepts needed to be a good digital system designer, and discover your own creativity. Learn abstractions that allow reasoning about design behavior. Manage design complexity through abstraction and understanding of tools. Allow analysis and optimization of the circuit's performance, power, cost, etc. Learn how to make sure your circuit and system works. There are way more ways to mess up a chip than to get it right.","title":"Class Goals"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#course-focuse","text":"","title":"Course Focuse"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#prerequisites","text":"CS 61C - C, Boolean Logic, RISC-V ISA Will review combinational and sequential logic and RISC-V datapath, pipelining (but in more depth) EECS 16A/B - Digital gates, RC networks We will review transistor operation and design of CMOS logic","title":"Prerequisites"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#follow-up-courses","text":"CS 61C --> EECS 151 --> CS 152 --> any graduate-level course in architecture/digital systems EECS 151 + EE 140 is a springboard into integrate circuits Tapeout class: EE 194 (special topic course), spring semester class. Bringout class: follow-up to tapeout, where the chip is produced and then we test it. Prerequisites for tapeout and bringout: EECS 151 or EE 140. 152 not required. Divide and conquer approach, so your background will be what you design.","title":"Follow-Up Courses"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#risc-v-32-bit-isa","text":"","title":"RISC-V 32-bit ISA"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#end-of-eecs-151","text":"You wiill be able to build a complex digital syste","title":"End of EECS 151"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#administrativia","text":"Lectures: Slides available before lecture, lectures recorded, posted after lecture. Textbooks: Digital Design and Computer Architecture, Digital Integrated Circuits: A Design Perspective, CMOS VLSI Design Discussions: Start next Friday. Review of important concepts from lecture, help with problem sets. Homework: Roughly 10 problem sets. Posted on Thursday, Due Friday, 8 days later Essential to understanding of material Late policy: 7 days for problem sets, 20% point reduction per day after slip day Solutions poster the week after due date Labs: Late policy: 14 slip days for labs, 20% point reduction per day after slip day 6 lab exercises, done solo. Lab report due by next lab session 7 week design project, done with partner. Project demo/interview RRR week, project report due RRR week Both labs: you will learn Verilog. The design component is the same. The tooling is different. Also different in how to interpret report using the different applications and tools. Midterm + Final Midterm: Late October 7-9pm Final: Wed, 12/14, 8-11am No alternative midterm/final. But may allow students to take the final right after the official slot. All exams are closed book with one double sided sheet of notes on midterm, two for the final. Clobber: Override your midterm score with the score on the final if you perform better on the final The reverse is not true - you must take the entire final exam, regardless of your score Class is not curved.","title":"Administrativia"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#tips-on-how-to-get-a-good-grade","text":"The lecture material is not the most challenging part of the couse. You should be able to understand everything as we go along. Do not fall behind in lecture and tell yourself you \"will figure it out later from the notes or book\". Slides will be online before the lecture. Study them before class. Ask question in class and stay involved in the class - that will help you understand. Come to OH to check your understanding or to ask question. Complete all the homework. Take labs very seriously.","title":"Tips on How to Get a Good Grade"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#digital-integrated-circuits-and-systems-past-present-and-future","text":"People tend to think of HW as an independent topic, but it is always interconnected with software. Hardware drives software. There are connections to the entire stack and different markets","title":"Digital Integrated Circuits and Systems: Past, Present, and Future"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#moores-law","text":"In 1965, Gordon Moore noted that the number of transistors on a chip doubled every 12 months. He made a prediction that semiconductor technology will double its effectiveness every 12 month. Now it has changed to about every 24 months. How can we reduce the cost to fabricate more transistors? It is still there in that we are getting more transistors, but the cost is not going down. That is where people say it is dying. We look at the density: transistors/unit area. It has been growing consistently. Cost is the biggest challenge to deal with to uphold Moore's law","title":"Moore's Law"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#the-other-trends-power","text":"","title":"The Other Trends Power!"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#dennard-scaling-1974","text":"Voltages (and currents) should be scaled proportionally to the dimensions of the transistor. And, in theory, power density constant! How we can make smaller transistors with same power density.","title":"Dennard Scaling (1974)"},{"location":"EECS/EECS%20151/1.%20Introduction/1.%20Introduction%20to%20EECS%20151/#the-other-demon-design-cost","text":"Get to next section: 2. Design Abstraction","title":"The Other Demon: Design Cost"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/","text":"2. Design Abstraction \u00b6 Review \u00b6 Moore's law is slowing down. There are continued improvements in technology, but at a slower pace Dennard's scaling ended a decade ago. All designs are now power limited Specialization and customization provides added performance. Under power constraints and stagnant technology Design costs are high. Methodology and better reuse to the rescue! Design Abstraction \u00b6 Design abstractions: design through layers of abstraction, each part works separately Specification: What goals do we have? What parts do we need to make. How do we plan it to work. Functionality? Why we want to do this? Model: Early stage tool to approach the design. Before we design in Verilog, we see if we can understand the hardware in some model like C. Architecture: Where we actually describe what hardware we want to use. How are the different components connected? Details, separation into modules. We will look at the RISC-V 32b architecture RTL Logic Design: implementation of hardware. Writing RTL into modules. Describing hardware through HDL. We will use Verilog (briefly talk about Chisel) Physical Design: Using tools to get the final design. EECS 251B: Spring semester - Added lecture on SystemVerilog. Interested in expanding it into a full lab. Example: RISC-V Design Process \u00b6 Specification: https://riscv.org/specifications/ Model: https://riscv.org/software-statue/#simulators Architecture: https://www.lowrisc.org/docs/tagged-memory-v0.1/rocket-core/ + CS 152 RTL Logic Design: https://riscv.org/risc-v-cores/ Physical Design: ASIC or FPGA Manufactured Part: https://www.sifive.com/boards/higfive-unleashed EECS 151 will focus on Architecture, RTL Logic Design, and Physical Design. RTL --> Physical Design \u00b6 The labs will focus on a process of translating RTL to physical ASIC or FPGA by using industry-standard tools. It eplores the entire design stack Tapeout class gets to the fabrication part of the abstraction. Implementing Digital Systems With Logic Gates \u00b6 Digital systems implement a set of Boolean equations. The logic gates are discussed more in detail in 9. Combinatorial Logic, Boolean Algebra . CMOS gates are always inverting. CMOS is a state of art mechanism. We will talk about the semiconductor industry and see why CMOS is important in fabrication for the smiconductor industry Combinational Logic \u00b6 Output a function only of the current inputs. Truth-table representation of function. Output is explicitly specified for each input combination. In general, CL blocks have more than one output signal, in which case, the truth-table will have multiple output columns. For example, a two bit adder: Slashes mean it is a group of wires but shown as one with simplicitly. We label the number of bits. The result is three wires. The total number of possible truth tables with 4 inputs and 1 output is what? \\(2^{2^4} = 65536\\) . In general, a \\(n\\) input, 1 output scenario has \\(2^{2^n}\\) . 4 inputs which means there are \\(2^4 = 16\\) rows. However, each output can be 0 or 1 for each of those \\(16\\) , Then we get \\(2^16 = 65536\\) . For \\(m\\) outputs, it might be what? Sequential Logic \u00b6 Output is a function of both the current input and the state. State represents the memory. State is a function of previous inputs. In synchronous digital systems, state is updated on each clock tick. We might do a sequential adder design rather than a combinational one, where the state that is remembered is the carry bit. Example: Flip-Flop Synchronous state element transfers its input to the output on a rising clock edge. A sequence of flip-flops is a register. In 61C, we used registers which were 32 flip-flops. Register Transfer Level Abstraction (RTL) \u00b6 Any synchronous digital circuit can be represented with all of the following: Combination Logic Blocks State Elements (registers or memories) Clock orchestrates sequencing of CL operations Verilog is designed to describe synchronous digital circuits. We will use it to describe any combinational and sequential logic. Summary \u00b6 The design proces involves traversing layers of specification, modeling, architecture, RTL design, and physical implementation. Digital systems implement a set of Boolean equations. Get to next section 3. Metrics and Verilog","title":"2. Design Abstraction"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#2-design-abstraction","text":"","title":"2. Design Abstraction"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#review","text":"Moore's law is slowing down. There are continued improvements in technology, but at a slower pace Dennard's scaling ended a decade ago. All designs are now power limited Specialization and customization provides added performance. Under power constraints and stagnant technology Design costs are high. Methodology and better reuse to the rescue!","title":"Review"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#design-abstraction","text":"Design abstractions: design through layers of abstraction, each part works separately Specification: What goals do we have? What parts do we need to make. How do we plan it to work. Functionality? Why we want to do this? Model: Early stage tool to approach the design. Before we design in Verilog, we see if we can understand the hardware in some model like C. Architecture: Where we actually describe what hardware we want to use. How are the different components connected? Details, separation into modules. We will look at the RISC-V 32b architecture RTL Logic Design: implementation of hardware. Writing RTL into modules. Describing hardware through HDL. We will use Verilog (briefly talk about Chisel) Physical Design: Using tools to get the final design. EECS 251B: Spring semester - Added lecture on SystemVerilog. Interested in expanding it into a full lab.","title":"Design Abstraction"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#example-risc-v-design-process","text":"Specification: https://riscv.org/specifications/ Model: https://riscv.org/software-statue/#simulators Architecture: https://www.lowrisc.org/docs/tagged-memory-v0.1/rocket-core/ + CS 152 RTL Logic Design: https://riscv.org/risc-v-cores/ Physical Design: ASIC or FPGA Manufactured Part: https://www.sifive.com/boards/higfive-unleashed EECS 151 will focus on Architecture, RTL Logic Design, and Physical Design.","title":"Example: RISC-V Design Process"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#rtl-physical-design","text":"The labs will focus on a process of translating RTL to physical ASIC or FPGA by using industry-standard tools. It eplores the entire design stack Tapeout class gets to the fabrication part of the abstraction.","title":"RTL --&gt; Physical Design"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#implementing-digital-systems-with-logic-gates","text":"Digital systems implement a set of Boolean equations. The logic gates are discussed more in detail in 9. Combinatorial Logic, Boolean Algebra . CMOS gates are always inverting. CMOS is a state of art mechanism. We will talk about the semiconductor industry and see why CMOS is important in fabrication for the smiconductor industry","title":"Implementing Digital Systems With Logic Gates"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#combinational-logic","text":"Output a function only of the current inputs. Truth-table representation of function. Output is explicitly specified for each input combination. In general, CL blocks have more than one output signal, in which case, the truth-table will have multiple output columns. For example, a two bit adder: Slashes mean it is a group of wires but shown as one with simplicitly. We label the number of bits. The result is three wires. The total number of possible truth tables with 4 inputs and 1 output is what? \\(2^{2^4} = 65536\\) . In general, a \\(n\\) input, 1 output scenario has \\(2^{2^n}\\) . 4 inputs which means there are \\(2^4 = 16\\) rows. However, each output can be 0 or 1 for each of those \\(16\\) , Then we get \\(2^16 = 65536\\) . For \\(m\\) outputs, it might be what?","title":"Combinational Logic"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#sequential-logic","text":"Output is a function of both the current input and the state. State represents the memory. State is a function of previous inputs. In synchronous digital systems, state is updated on each clock tick. We might do a sequential adder design rather than a combinational one, where the state that is remembered is the carry bit. Example: Flip-Flop Synchronous state element transfers its input to the output on a rising clock edge. A sequence of flip-flops is a register. In 61C, we used registers which were 32 flip-flops.","title":"Sequential Logic"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#register-transfer-level-abstraction-rtl","text":"Any synchronous digital circuit can be represented with all of the following: Combination Logic Blocks State Elements (registers or memories) Clock orchestrates sequencing of CL operations Verilog is designed to describe synchronous digital circuits. We will use it to describe any combinational and sequential logic.","title":"Register Transfer Level Abstraction (RTL)"},{"location":"EECS/EECS%20151/2.%20Design%20Abstraction/2.%20Design%20Abstraction/#summary","text":"The design proces involves traversing layers of specification, modeling, architecture, RTL design, and physical implementation. Digital systems implement a set of Boolean equations. Get to next section 3. Metrics and Verilog","title":"Summary"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/","text":"3. Metrics and Verilog \u00b6 This notes explains how we evaluate systems and use Verilog Review \u00b6 From 2. Design Abstraction : The design process involves travresing the layers of specification, modeling, architecture, RTL design, and physical implementation Digital systems implement a set of Boolean equations Metrics \u00b6 The desired functionality can be implemented with different performance, power, or cost targets. We want to measure it across these three dimensions, where we need to consider our goals to figure out which dimension to focus on. Power is important to find ways to make it efficient; carbon footprint considerations; reducing energy in fabrication and usage (low power = phone) Performance is important is a key dimension that a lot of people look at = (high performance = Google TPU) Cost includes design, verification, implementation costs. How can we use a current budget to produce something marketable (low cost = watch, calculator) Cost \u00b6 Non-recurring engineering (NRE) costs Fixed, one-time cost to research, design, and verify a new piece of HW Amortized over all units shipped. For example, $20M in development adds $0.20 to each of 100M units Recurring costs Cost to manufacture, test and package a unit Processed wafer cost is about 10k (around 16nm node) which yields: 1 Cerebras chip, 50-100 large FPGAs or GPUs, 200 laptop CPUs, > 1000 cell phone SoCs Some useful equations for fabrication \\[ \\text{cost per IC} = \\text{variable cost per IC} + \\frac{\\text{fixed cost}}{\\text{volume}} \\] where \\[ \\text{variable cost} = \\frac{\\text{cost of die + cost of die test + cost of packaging}}{\\text{final test yield}} \\] Die Yield equations \\[ \\text{die cost} = \\frac{\\text{wafer cost}}{\\text{dies per wafer}\\times\\text{die yield}} \\] where \\[ \\text{die yield} = \\frac{\\text{number of good chips per wafer}}{\\text{total number of chips per wafer}}\\times 100\\% \\] Performance \u00b6 Throughput Number of tasks performed in a unit of time (operations per second) Watch out for \"op\" definitions -- can be a 1-b ADD or a double-precision FP add (or more complex task) Peak vs. average throughput Latency How does a task take from start to finish E.g. facial recognition on a phone takes 10's of ms Sometime expressed in terms of clock cycles Average vs. \"tail\" latency Digital Logic Delay: Changes at the inputs do no instantaneously appear at the outputs. There are finite resistances and capacitances in each gate. Propagation delay \\(t_p\\) of a logic gate defines how quickly its output responds to a change at its inputs. Defined as 50% transition oints of the input and output waveforms. There is high-to-low and lot-to-high transitions Rise and fall times \\(t_r, t_f\\) are for individual signals. Measures how fast a signal transmits Digital Logic Timing: The longest propagation delay through CL blocks sets the maximum achievable clock frequency. You also need to consider the register in this calculation To increase the clock rate, you need to find the longest path and make it faster. Power and Energy \u00b6 Energy in Joules Needed to perform a task Add two numbers or fetch a datum from memory Active and standby Battery stores certain amount of energy This is what ultility charges for Power in Watts Energy dissipated in time Peak power vs. average power Sets cooling requirements Beneath Digital Abstraction \u00b6 Beneath the digital abstraction includes Logic gates; interpret inputs as 0s and 1s Noise: unwanted variations of voltages and currents in digital circuits Logic levels: mapping a continuous voltage onto a discrete binary logic variable. Low (0): \\([0, V_l]\\) , High (1): \\([V_H, V_{DD}]\\) , where \\(V_L, V_H\\) are nominal voltage levels Noise Margins \u00b6 Measure of the sensitivity of gat to noise Represent the levels of noise that can be sustained when gates are cascaded The amount of noise that could be added to a worst-case output so that the signal can still be interpreted correctly as a valid input Voltage Transfer Characteristic \u00b6 Describes the output voltage as a function of the input voltage To choose logic levels -> slope = -1 -> maximize noise margin Regenerative Property \u00b6 Ensures that a disturbed signal gradually converges back to one of the nonminal voltage levels after passing through a number of logical stages Look for a sharp transition in voltage transfer characteristics CMOS has a regenerative property. Verilog \u00b6 Hardware Description Languages \u00b6 Verilog Simple C-like syntax for structural and behavior hardware constructs Mature set of commercial tools for synthesis and simulation Used in EECS 151 VHDL Semantically very close to Verilog More syntactic overhead Extensive type system for \"synthesis time\" checking System Verilog Enhances Verilog with strong typing along with other additions BlueSpec: Invended by Prof. Arvind at MIT Originally built within the Haskell programming language Now available commercially: bluespec.edu Chisel Developed at UC Berkeley Used in CS 152, 250 Available at: chisel.eecs.berkeley.edu Verilog: Brief History \u00b6 Verilog was originated at Automated Integrated Design Systems (renamed Gateway) in 1985. It was acquired by Cadence in 1989. It was invented as simulation language. Synthesis was an afterthought. Many of the basic techniques for synthesis were developed at Berkeley in the 80s and applied commercially in the 90s. Around the same time as the origin of Verilog, US Department of Defense developed VHDL (VSIC (Very High-Speed Integraded Circuit) HDL). Because it was in public domain, it grew in popularity. Cadence opened Verilog to the public in 1990, afriad of losing market share. Verilog is the language of choice of Silicon Valley companies, initially because of high-quality tool support and its similarity to C-language syntax VHDL is still popular in government, Europe, Japan, some universities Most major CAD frameworks now support both. Logic Synthesis \u00b6 Verilog and VHDL started out as simulation languages but soon programs were written to automatically convert Verilog into low-level circuit descriptions (netlists) Synthesis converts Verilog or other HDL descriptions to an implementation using technology-specific primitives. For FPGA, LUTs, FlipFlops, and BRAMs. For ASICs, standard cells and memory macros Verilog Introduction \u00b6 A module definition describes a component in a circuit. There are two ways to describe module contents: 1. Structural Verilog: list of sub-components and how they are connected. Just like a schematic with text, tedious to write, hard to decode, but you get precise control over circuit details 2. Behavioral Verilog: describe what a component doees, not how it does it. Synthesized into a circuit that has this behavior. Result is only as good as the tools Modules define circuit components. Instantiation defines hierarchy of design. Here is an example of how to make XOR:","title":"3. Metrics and Verilog"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#3-metrics-and-verilog","text":"This notes explains how we evaluate systems and use Verilog","title":"3. Metrics and Verilog"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#review","text":"From 2. Design Abstraction : The design process involves travresing the layers of specification, modeling, architecture, RTL design, and physical implementation Digital systems implement a set of Boolean equations","title":"Review"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#metrics","text":"The desired functionality can be implemented with different performance, power, or cost targets. We want to measure it across these three dimensions, where we need to consider our goals to figure out which dimension to focus on. Power is important to find ways to make it efficient; carbon footprint considerations; reducing energy in fabrication and usage (low power = phone) Performance is important is a key dimension that a lot of people look at = (high performance = Google TPU) Cost includes design, verification, implementation costs. How can we use a current budget to produce something marketable (low cost = watch, calculator)","title":"Metrics"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#cost","text":"Non-recurring engineering (NRE) costs Fixed, one-time cost to research, design, and verify a new piece of HW Amortized over all units shipped. For example, $20M in development adds $0.20 to each of 100M units Recurring costs Cost to manufacture, test and package a unit Processed wafer cost is about 10k (around 16nm node) which yields: 1 Cerebras chip, 50-100 large FPGAs or GPUs, 200 laptop CPUs, > 1000 cell phone SoCs Some useful equations for fabrication \\[ \\text{cost per IC} = \\text{variable cost per IC} + \\frac{\\text{fixed cost}}{\\text{volume}} \\] where \\[ \\text{variable cost} = \\frac{\\text{cost of die + cost of die test + cost of packaging}}{\\text{final test yield}} \\] Die Yield equations \\[ \\text{die cost} = \\frac{\\text{wafer cost}}{\\text{dies per wafer}\\times\\text{die yield}} \\] where \\[ \\text{die yield} = \\frac{\\text{number of good chips per wafer}}{\\text{total number of chips per wafer}}\\times 100\\% \\]","title":"Cost"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#performance","text":"Throughput Number of tasks performed in a unit of time (operations per second) Watch out for \"op\" definitions -- can be a 1-b ADD or a double-precision FP add (or more complex task) Peak vs. average throughput Latency How does a task take from start to finish E.g. facial recognition on a phone takes 10's of ms Sometime expressed in terms of clock cycles Average vs. \"tail\" latency Digital Logic Delay: Changes at the inputs do no instantaneously appear at the outputs. There are finite resistances and capacitances in each gate. Propagation delay \\(t_p\\) of a logic gate defines how quickly its output responds to a change at its inputs. Defined as 50% transition oints of the input and output waveforms. There is high-to-low and lot-to-high transitions Rise and fall times \\(t_r, t_f\\) are for individual signals. Measures how fast a signal transmits Digital Logic Timing: The longest propagation delay through CL blocks sets the maximum achievable clock frequency. You also need to consider the register in this calculation To increase the clock rate, you need to find the longest path and make it faster.","title":"Performance"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#power-and-energy","text":"Energy in Joules Needed to perform a task Add two numbers or fetch a datum from memory Active and standby Battery stores certain amount of energy This is what ultility charges for Power in Watts Energy dissipated in time Peak power vs. average power Sets cooling requirements","title":"Power and Energy"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#beneath-digital-abstraction","text":"Beneath the digital abstraction includes Logic gates; interpret inputs as 0s and 1s Noise: unwanted variations of voltages and currents in digital circuits Logic levels: mapping a continuous voltage onto a discrete binary logic variable. Low (0): \\([0, V_l]\\) , High (1): \\([V_H, V_{DD}]\\) , where \\(V_L, V_H\\) are nominal voltage levels","title":"Beneath Digital Abstraction"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#noise-margins","text":"Measure of the sensitivity of gat to noise Represent the levels of noise that can be sustained when gates are cascaded The amount of noise that could be added to a worst-case output so that the signal can still be interpreted correctly as a valid input","title":"Noise Margins"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#voltage-transfer-characteristic","text":"Describes the output voltage as a function of the input voltage To choose logic levels -> slope = -1 -> maximize noise margin","title":"Voltage Transfer Characteristic"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#regenerative-property","text":"Ensures that a disturbed signal gradually converges back to one of the nonminal voltage levels after passing through a number of logical stages Look for a sharp transition in voltage transfer characteristics CMOS has a regenerative property.","title":"Regenerative Property"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#verilog","text":"","title":"Verilog"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#hardware-description-languages","text":"Verilog Simple C-like syntax for structural and behavior hardware constructs Mature set of commercial tools for synthesis and simulation Used in EECS 151 VHDL Semantically very close to Verilog More syntactic overhead Extensive type system for \"synthesis time\" checking System Verilog Enhances Verilog with strong typing along with other additions BlueSpec: Invended by Prof. Arvind at MIT Originally built within the Haskell programming language Now available commercially: bluespec.edu Chisel Developed at UC Berkeley Used in CS 152, 250 Available at: chisel.eecs.berkeley.edu","title":"Hardware Description Languages"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#verilog-brief-history","text":"Verilog was originated at Automated Integrated Design Systems (renamed Gateway) in 1985. It was acquired by Cadence in 1989. It was invented as simulation language. Synthesis was an afterthought. Many of the basic techniques for synthesis were developed at Berkeley in the 80s and applied commercially in the 90s. Around the same time as the origin of Verilog, US Department of Defense developed VHDL (VSIC (Very High-Speed Integraded Circuit) HDL). Because it was in public domain, it grew in popularity. Cadence opened Verilog to the public in 1990, afriad of losing market share. Verilog is the language of choice of Silicon Valley companies, initially because of high-quality tool support and its similarity to C-language syntax VHDL is still popular in government, Europe, Japan, some universities Most major CAD frameworks now support both.","title":"Verilog: Brief History"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#logic-synthesis","text":"Verilog and VHDL started out as simulation languages but soon programs were written to automatically convert Verilog into low-level circuit descriptions (netlists) Synthesis converts Verilog or other HDL descriptions to an implementation using technology-specific primitives. For FPGA, LUTs, FlipFlops, and BRAMs. For ASICs, standard cells and memory macros","title":"Logic Synthesis"},{"location":"EECS/EECS%20151/3.%20Metrics%20and%20Verilog/3.%20Metrics%20and%20Verilog/#verilog-introduction","text":"A module definition describes a component in a circuit. There are two ways to describe module contents: 1. Structural Verilog: list of sub-components and how they are connected. Just like a schematic with text, tedious to write, hard to decode, but you get precise control over circuit details 2. Behavioral Verilog: describe what a component doees, not how it does it. Synthesized into a circuit that has this behavior. Result is only as good as the tools Modules define circuit components. Instantiation defines hierarchy of design. Here is an example of how to make XOR:","title":"Verilog Introduction"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/","text":"4. Verilog II \u00b6 Review \u00b6 Design metrics: 1. Functionality and robustness 2. Cost 3. Performance 4. Power and Energy Verilog: 1. Hardware Description language 2. Logic synthesis: Verilog -> Gate-level netlists 3. Used in both ASIC and FPGA Verilog Introduction \u00b6 A module definition describes a component in a circuit. There are two ways to describe module contents 1. Structural Verilog List of sub-components and how they are connected Just like schematics, but using text Tedious to write, hard to decode You get precise control over circuit details May be necessary to map to special resources of the FPGA/ASIC Behavioral Verilog Describe what a component does, not how it does it Synthesized into a circuit that has this behavior Result is only as good as the tools The idea is to build up a hierarchy of modules. Top-level module is your entire design (or the environment to test your design) Verilog Modules and Instantiation \u00b6 Modules define circuit components. Instantiation defines hierarchy of design: A module is not a functio in the C sense. Ther eis no call and return mechanism. Think of it more like a hierarchical data structure. Here is an example: XOR Note that the instantiated gates are not executed. They are active always. The xorgate already exists as a built-in (so really no need to define it). Undeclared variables assumed to be wires. Don't let this happen to you! Simple Behavioral Model \u00b6 The assign statement has a bitwise \"and\" gate. The assignment continuously happens, therefore any change on the RHS is reflected in out immediately (except for small delay associated with the implemnetaion of the practical & .) It is not like an assignment in C that takes place when the program counter gets to that place in the program. Instantiation, Signal Array, Named Ports \u00b6 Example: Ripple Adder \u00b6 Verilog Operators \u00b6 Continuous Assignment Examples \u00b6 Assign values whenever there is a change in the RHS. Model combinational logic without specifying an interconnection of gates: Non-Continuous Assignmnets \u00b6 This is a bit unusual from a hardware specification point of view. However it shows that Verilog is a simulation language Always Blocks \u00b6 Always blocks give us some constructs that are impossible or awkward in continuous assignments Simplified Verilog Guidelines \u00b6 For combinational logic: - Continuous assignment: assign a = b & c Always block with @(*) : always @(*) begin a = b & c; // blocking statement end","title":"4. Verilog II"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#4-verilog-ii","text":"","title":"4. Verilog II"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#review","text":"Design metrics: 1. Functionality and robustness 2. Cost 3. Performance 4. Power and Energy Verilog: 1. Hardware Description language 2. Logic synthesis: Verilog -> Gate-level netlists 3. Used in both ASIC and FPGA","title":"Review"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#verilog-introduction","text":"A module definition describes a component in a circuit. There are two ways to describe module contents 1. Structural Verilog List of sub-components and how they are connected Just like schematics, but using text Tedious to write, hard to decode You get precise control over circuit details May be necessary to map to special resources of the FPGA/ASIC Behavioral Verilog Describe what a component does, not how it does it Synthesized into a circuit that has this behavior Result is only as good as the tools The idea is to build up a hierarchy of modules. Top-level module is your entire design (or the environment to test your design)","title":"Verilog Introduction"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#verilog-modules-and-instantiation","text":"Modules define circuit components. Instantiation defines hierarchy of design: A module is not a functio in the C sense. Ther eis no call and return mechanism. Think of it more like a hierarchical data structure. Here is an example: XOR Note that the instantiated gates are not executed. They are active always. The xorgate already exists as a built-in (so really no need to define it). Undeclared variables assumed to be wires. Don't let this happen to you!","title":"Verilog Modules and Instantiation"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#simple-behavioral-model","text":"The assign statement has a bitwise \"and\" gate. The assignment continuously happens, therefore any change on the RHS is reflected in out immediately (except for small delay associated with the implemnetaion of the practical & .) It is not like an assignment in C that takes place when the program counter gets to that place in the program.","title":"Simple Behavioral Model"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#instantiation-signal-array-named-ports","text":"","title":"Instantiation, Signal Array, Named Ports"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#example-ripple-adder","text":"","title":"Example: Ripple Adder"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#verilog-operators","text":"","title":"Verilog Operators"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#continuous-assignment-examples","text":"Assign values whenever there is a change in the RHS. Model combinational logic without specifying an interconnection of gates:","title":"Continuous Assignment Examples"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#non-continuous-assignmnets","text":"This is a bit unusual from a hardware specification point of view. However it shows that Verilog is a simulation language","title":"Non-Continuous Assignmnets"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#always-blocks","text":"Always blocks give us some constructs that are impossible or awkward in continuous assignments","title":"Always Blocks"},{"location":"EECS/EECS%20151/4.%20Verilog%20II/4.%20Verilog%20II/#simplified-verilog-guidelines","text":"For combinational logic: - Continuous assignment: assign a = b & c Always block with @(*) : always @(*) begin a = b & c; // blocking statement end","title":"Simplified Verilog Guidelines"},{"location":"EECS/EECS%20151/5.%20Combinational%20Logic%20I/5.%20Combinational%20Logic%20I/","text":"5. Combinational Logic \u00b6 Introduction \u00b6 In combinational logic, the outputs depend only on the current vlaues of the inputs. It is memoryless: compute the output values using the current inputs. If we change X, then Y will change immediately (or almost). There might be delay in the combinational unit used. We can represent combinational logic in 3 main ways: Boolean Equations, Truth Tables, Gate Representations. Knowing how to translate among all three are important skills. Boolean Algebra \u00b6 Fundamentals \u00b6 There are two elements in our set \\(\\{0, 1\\}\\) . Then we want to use two binary operators and one unary operator (and, or, not). Given two variables \\((x, y)\\) , there are 16 different ways to spit out an output of these inputs. Some of them are of interest, like NOR, NAND, XOR, XNOR. Now, when we have \\(n\\) inputs, we would need \\(2^n\\) rows in our truth table. Decomposition in Digital Design \u00b6 We can construct an adder circuit by its truth table. Since there are carrying bits, we need a 3 input truth table with 2 functions that act on the three inputs. Laws of Boolean Algebra \u00b6 \\[ \\begin{align*} \\text{Identity:} && X + 0 = X, X * 1 + X\\\\ && X + 1 = 1, X * 0 = 0\\\\\\\\ \\text{Idempotence:} && X + X = X, XX = X\\\\\\\\ \\text{Complements:} &&X + X' = 1, XX' = 0\\\\\\\\ \\text{Commutative:} &&X + Y = Y + X, XY = YX\\\\\\\\ \\text{Associative:} &&(X + Y) + Z = X + (Y + Z)\\\\ && (XY)Z = X(YZ)\\\\\\\\ \\text{Distributive:} &&X(Y + Z) = XY + XZ\\\\ &&X + (YZ) = (X + Y)(X + Z)\\\\\\\\ \\text{Absorptive:}&& X + XY = X(1 +Y) = X\\\\ &&X(X + Y) = (X + 0)(X + Y)= X + (0Y) = X\\\\\\\\ \\end{align*} \\] More Laws: \\[ \\text{DeMorgan's Law:} \\qquad (xy)' = x' + y', (x + y)' = x'y' \\] DeMorgan's law is powerful in digital design: 1. A NAND gate is equivalent to an OR gate with inverted inputs 2. A NOR gate is equivalent to an AND gate with inverted inputs 3. Bubble pushing: pusing a bubble from input through the gates. The bubble comes out in the output, and the gate flips from AND to OR or vice versa. Canonical Forms \u00b6 There are two types of canonical forms: 1. Sum of Products (SOP) 2. Product of Sums (POS) Sum of Products is also known as disjunctive normal form with minterm expansion. A minterm is a product (AND) involving all the inputs for the term to be 1. SOP is summing the minterms for which the output is True. We did this in CS 61C Product of Sums is also known as conjunctive normal form with maxterm expansion. A maxterm is a sum (OR) involving all inputs for the term to be 0. POS is the product of maxterms for which the output is False. Can also obtain POSs from applying DeMorgan's law to the SOPs of F (and vice versa). Canonical Forms are usually not minimal, so we will have to use boolean algebra to simplify them. Summary \u00b6 Combinational circuits: The outputs only depend on the current values of the inputs (memoryless) The functional specification of a combinational circuit can be expressed as a truth table or boolean equation Boolean Algebra: Deal with variables that are either True or False Map naturally to hardware logic gates Use theorems of Boolean algebra and Karnaugh maps to simplify equations","title":"5. Combinational Logic"},{"location":"EECS/EECS%20151/5.%20Combinational%20Logic%20I/5.%20Combinational%20Logic%20I/#5-combinational-logic","text":"","title":"5. Combinational Logic"},{"location":"EECS/EECS%20151/5.%20Combinational%20Logic%20I/5.%20Combinational%20Logic%20I/#introduction","text":"In combinational logic, the outputs depend only on the current vlaues of the inputs. It is memoryless: compute the output values using the current inputs. If we change X, then Y will change immediately (or almost). There might be delay in the combinational unit used. We can represent combinational logic in 3 main ways: Boolean Equations, Truth Tables, Gate Representations. Knowing how to translate among all three are important skills.","title":"Introduction"},{"location":"EECS/EECS%20151/5.%20Combinational%20Logic%20I/5.%20Combinational%20Logic%20I/#boolean-algebra","text":"","title":"Boolean Algebra"},{"location":"EECS/EECS%20151/5.%20Combinational%20Logic%20I/5.%20Combinational%20Logic%20I/#fundamentals","text":"There are two elements in our set \\(\\{0, 1\\}\\) . Then we want to use two binary operators and one unary operator (and, or, not). Given two variables \\((x, y)\\) , there are 16 different ways to spit out an output of these inputs. Some of them are of interest, like NOR, NAND, XOR, XNOR. Now, when we have \\(n\\) inputs, we would need \\(2^n\\) rows in our truth table.","title":"Fundamentals"},{"location":"EECS/EECS%20151/5.%20Combinational%20Logic%20I/5.%20Combinational%20Logic%20I/#decomposition-in-digital-design","text":"We can construct an adder circuit by its truth table. Since there are carrying bits, we need a 3 input truth table with 2 functions that act on the three inputs.","title":"Decomposition in Digital Design"},{"location":"EECS/EECS%20151/5.%20Combinational%20Logic%20I/5.%20Combinational%20Logic%20I/#laws-of-boolean-algebra","text":"\\[ \\begin{align*} \\text{Identity:} && X + 0 = X, X * 1 + X\\\\ && X + 1 = 1, X * 0 = 0\\\\\\\\ \\text{Idempotence:} && X + X = X, XX = X\\\\\\\\ \\text{Complements:} &&X + X' = 1, XX' = 0\\\\\\\\ \\text{Commutative:} &&X + Y = Y + X, XY = YX\\\\\\\\ \\text{Associative:} &&(X + Y) + Z = X + (Y + Z)\\\\ && (XY)Z = X(YZ)\\\\\\\\ \\text{Distributive:} &&X(Y + Z) = XY + XZ\\\\ &&X + (YZ) = (X + Y)(X + Z)\\\\\\\\ \\text{Absorptive:}&& X + XY = X(1 +Y) = X\\\\ &&X(X + Y) = (X + 0)(X + Y)= X + (0Y) = X\\\\\\\\ \\end{align*} \\] More Laws: \\[ \\text{DeMorgan's Law:} \\qquad (xy)' = x' + y', (x + y)' = x'y' \\] DeMorgan's law is powerful in digital design: 1. A NAND gate is equivalent to an OR gate with inverted inputs 2. A NOR gate is equivalent to an AND gate with inverted inputs 3. Bubble pushing: pusing a bubble from input through the gates. The bubble comes out in the output, and the gate flips from AND to OR or vice versa.","title":"Laws of Boolean Algebra"},{"location":"EECS/EECS%20151/5.%20Combinational%20Logic%20I/5.%20Combinational%20Logic%20I/#canonical-forms","text":"There are two types of canonical forms: 1. Sum of Products (SOP) 2. Product of Sums (POS) Sum of Products is also known as disjunctive normal form with minterm expansion. A minterm is a product (AND) involving all the inputs for the term to be 1. SOP is summing the minterms for which the output is True. We did this in CS 61C Product of Sums is also known as conjunctive normal form with maxterm expansion. A maxterm is a sum (OR) involving all inputs for the term to be 0. POS is the product of maxterms for which the output is False. Can also obtain POSs from applying DeMorgan's law to the SOPs of F (and vice versa). Canonical Forms are usually not minimal, so we will have to use boolean algebra to simplify them.","title":"Canonical Forms"},{"location":"EECS/EECS%20151/5.%20Combinational%20Logic%20I/5.%20Combinational%20Logic%20I/#summary","text":"Combinational circuits: The outputs only depend on the current values of the inputs (memoryless) The functional specification of a combinational circuit can be expressed as a truth table or boolean equation Boolean Algebra: Deal with variables that are either True or False Map naturally to hardware logic gates Use theorems of Boolean algebra and Karnaugh maps to simplify equations","title":"Summary"},{"location":"EECS/EECS%20151/6.%20Combinational%20Logic%20II/6.%20Combinational%20Logic%20II/","text":"6. Combinational Logic II and FSM I \u00b6 Boolean Simplification \u00b6 Why Logic Simplification? \u00b6 We do logic simplificationbecause we want to minimize the number of gates in a circuit. Gates take area, and wasting area with more gates than usual is bad. Also we want to minimize the amount of wiring in the circuit. Wiring also takes space and is difficult to route. Physical gates have limited number of inputs. Practical Methods for Boolean Simplification \u00b6 The Uniting Theorem: \\[ xy' + xy = x(y' + y) = x(1) = x \\] Karnaugh Map Method \u00b6 After working through several minimizations of Boolean quations using Boolean algebra, you realize that you sometimes end up with a completely different equation instead of a simplified quation. Karnaugh maps are a graphical method for simplifying Boolean equations. There is a method to represent the truth table and to help visualize the adjacencies. Here is the process: 1. Draw K-map of the appropriate number of variables 2. Fill in map with function values from truth table 3. Form groups of 1's. Dimensions of groups must be even powers of two (1x1, 1x2, 1x4, ... , 2x2, 2x4, ...) Form as large as possible groups and as few as groups possible Groups can overlap (this helps make larger groups) Remember K-map is periodical in all dimensions (groups can cross over edges of map and continue on other side) For each group write a product term The term includes the constant variables (use the uncomplemented variable for a constant 1 and complemented variable for constant 0) Form Boolean expression as sum-of-products Each circle on the K-map represents an implicant. The largest possible circles are prime implicants. Rules for finding a minimized equation from a K-map are: 1. Use the fewest circles to cover all the 1s 2. All the squares in each circle must contain 1's 3. Each circle must span a rectangular block that is a power of 2 in each direction 4. Each circle should be as large as possible 5. A circle may wrap around the edges of the K-mmap 6. A 1 in a K-map may be circled miultiple times if doing so allows fewer circles to be used. There are such things as higher-dimensional K-maps, but they are harder to draw out. There is also a POS version, where you form groups of 0's instead of 1's, and for each group write a sum term. Sequential Logic \u00b6 Moore vs. Mealy FSM \u00b6","title":"6. Combinational Logic II and FSM I"},{"location":"EECS/EECS%20151/6.%20Combinational%20Logic%20II/6.%20Combinational%20Logic%20II/#6-combinational-logic-ii-and-fsm-i","text":"","title":"6. Combinational Logic II and FSM I"},{"location":"EECS/EECS%20151/6.%20Combinational%20Logic%20II/6.%20Combinational%20Logic%20II/#boolean-simplification","text":"","title":"Boolean Simplification"},{"location":"EECS/EECS%20151/6.%20Combinational%20Logic%20II/6.%20Combinational%20Logic%20II/#why-logic-simplification","text":"We do logic simplificationbecause we want to minimize the number of gates in a circuit. Gates take area, and wasting area with more gates than usual is bad. Also we want to minimize the amount of wiring in the circuit. Wiring also takes space and is difficult to route. Physical gates have limited number of inputs.","title":"Why Logic Simplification?"},{"location":"EECS/EECS%20151/6.%20Combinational%20Logic%20II/6.%20Combinational%20Logic%20II/#practical-methods-for-boolean-simplification","text":"The Uniting Theorem: \\[ xy' + xy = x(y' + y) = x(1) = x \\]","title":"Practical Methods for Boolean Simplification"},{"location":"EECS/EECS%20151/6.%20Combinational%20Logic%20II/6.%20Combinational%20Logic%20II/#karnaugh-map-method","text":"After working through several minimizations of Boolean quations using Boolean algebra, you realize that you sometimes end up with a completely different equation instead of a simplified quation. Karnaugh maps are a graphical method for simplifying Boolean equations. There is a method to represent the truth table and to help visualize the adjacencies. Here is the process: 1. Draw K-map of the appropriate number of variables 2. Fill in map with function values from truth table 3. Form groups of 1's. Dimensions of groups must be even powers of two (1x1, 1x2, 1x4, ... , 2x2, 2x4, ...) Form as large as possible groups and as few as groups possible Groups can overlap (this helps make larger groups) Remember K-map is periodical in all dimensions (groups can cross over edges of map and continue on other side) For each group write a product term The term includes the constant variables (use the uncomplemented variable for a constant 1 and complemented variable for constant 0) Form Boolean expression as sum-of-products Each circle on the K-map represents an implicant. The largest possible circles are prime implicants. Rules for finding a minimized equation from a K-map are: 1. Use the fewest circles to cover all the 1s 2. All the squares in each circle must contain 1's 3. Each circle must span a rectangular block that is a power of 2 in each direction 4. Each circle should be as large as possible 5. A circle may wrap around the edges of the K-mmap 6. A 1 in a K-map may be circled miultiple times if doing so allows fewer circles to be used. There are such things as higher-dimensional K-maps, but they are harder to draw out. There is also a POS version, where you form groups of 0's instead of 1's, and for each group write a sum term.","title":"Karnaugh Map Method"},{"location":"EECS/EECS%20151/6.%20Combinational%20Logic%20II/6.%20Combinational%20Logic%20II/#sequential-logic","text":"","title":"Sequential Logic"},{"location":"EECS/EECS%20151/6.%20Combinational%20Logic%20II/6.%20Combinational%20Logic%20II/#moore-vs-mealy-fsm","text":"","title":"Moore vs. Mealy FSM"},{"location":"EECS/EECS%20151/7.%20Finite%20State%20Machines/7.%20Finite%20State%20Machines/","text":"7. Finite State Machines \u00b6 Sequential Logic \u00b6 Combinational logic is memoryless: the outputs only depend on the current inputs. Sequential logic: Memory: outputs depend on both current and previous values of the inputs. Distills the prior inputs into a smaller amount of information i.e., states. State: the information about a circuit. Influences the circuit's future behavior, stored in flip-flops and latches. FSMs: useful representation for designing sequential circuits. Output depends on present and past inputs Finite State Machines \u00b6 FSMs are sequential circuits which has 1. External inputs 2. Externally visible outputs 3. Internal states Consists of: 1. State register: stores current state, loads previously calculated next state. Number of states <= 2^(number of FFs) 2. Combinational logic: computes the next states and the outputs. FSM Gate Representation \u00b6 FSM Design Process \u00b6 Specify the circuit function Draw state transition diagram Write down symbolic state transition table Write down encoded state transition table Derive logic equations Derive circuit diagram: register to hold state; combinational logic for next state and outputs. Moore vs. Mealy FSMs \u00b6 Although the next state is always determined by the current state and inputs, they may differ in output logic Moore FSM: outputs depend only on current state Mealy FSM: outputs depend on current state and inputs FSMs in Verilog \u00b6 Specify circuit function Draw state transition diagram Write down symbolic state transition table Assign encodings (bit patterns) to symbolic states Code as Verilog behavioral description Use parameters to represent encoded states Use separate always blocks for register assignment and combinational logic block Use case statement for combinational logic. Within each case section (state), assign outputs and next state based on inputs.","title":"7. Finite State Machines"},{"location":"EECS/EECS%20151/7.%20Finite%20State%20Machines/7.%20Finite%20State%20Machines/#7-finite-state-machines","text":"","title":"7. Finite State Machines"},{"location":"EECS/EECS%20151/7.%20Finite%20State%20Machines/7.%20Finite%20State%20Machines/#sequential-logic","text":"Combinational logic is memoryless: the outputs only depend on the current inputs. Sequential logic: Memory: outputs depend on both current and previous values of the inputs. Distills the prior inputs into a smaller amount of information i.e., states. State: the information about a circuit. Influences the circuit's future behavior, stored in flip-flops and latches. FSMs: useful representation for designing sequential circuits. Output depends on present and past inputs","title":"Sequential Logic"},{"location":"EECS/EECS%20151/7.%20Finite%20State%20Machines/7.%20Finite%20State%20Machines/#finite-state-machines","text":"FSMs are sequential circuits which has 1. External inputs 2. Externally visible outputs 3. Internal states Consists of: 1. State register: stores current state, loads previously calculated next state. Number of states <= 2^(number of FFs) 2. Combinational logic: computes the next states and the outputs.","title":"Finite State Machines"},{"location":"EECS/EECS%20151/7.%20Finite%20State%20Machines/7.%20Finite%20State%20Machines/#fsm-gate-representation","text":"","title":"FSM Gate Representation"},{"location":"EECS/EECS%20151/7.%20Finite%20State%20Machines/7.%20Finite%20State%20Machines/#fsm-design-process","text":"Specify the circuit function Draw state transition diagram Write down symbolic state transition table Write down encoded state transition table Derive logic equations Derive circuit diagram: register to hold state; combinational logic for next state and outputs.","title":"FSM Design Process"},{"location":"EECS/EECS%20151/7.%20Finite%20State%20Machines/7.%20Finite%20State%20Machines/#moore-vs-mealy-fsms","text":"Although the next state is always determined by the current state and inputs, they may differ in output logic Moore FSM: outputs depend only on current state Mealy FSM: outputs depend on current state and inputs","title":"Moore vs. Mealy FSMs"},{"location":"EECS/EECS%20151/7.%20Finite%20State%20Machines/7.%20Finite%20State%20Machines/#fsms-in-verilog","text":"Specify circuit function Draw state transition diagram Write down symbolic state transition table Assign encodings (bit patterns) to symbolic states Code as Verilog behavioral description Use parameters to represent encoded states Use separate always blocks for register assignment and combinational logic block Use case statement for combinational logic. Within each case section (state), assign outputs and next state based on inputs.","title":"FSMs in Verilog"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/","text":"9. RISC-V Datapath I \u00b6 Stages of Datapath \u00b6 A single CL block that executes an instruction is too bulky and inefficient. The solution is to break up the process of executing an instruction into stages, and then connect the stages to create the whole datapath. There are 5 stages of the datapath: 1. Instruction Fetch (IF) 2. Instruction Decode (ID) 3. Execute (EX) 4. Memory Access (MEM) 5. Write Back to Register (WB) State and Sequencing \u00b6 Memory: One input bus: data in. One output bus: data out Memory word is found by: Read: address selects the word to put on data out Write: set write enable = 1. Address selects the memory word to be written via the data in bus Clock Only a factor during write operation During read operation, behaves as a combinational logic block: address valid --> data out valid after \"access time\" RISC-V Datapath & Control \u00b6 Every instruction is 32-bits divided into fields of varying numbers each. opcode: specifies what instruction it is May have funct7 & funct3: fields describe what operation to perform. R-Format Instruction Layout \u00b6 rs1, rs2, rd: three registers that can be expressed in 5 bits. The instruction will operate on rs1 , rs2 and store its result in rd . $$ \\text{ rd, rs1, rs2} $$ R-type instructions usually makes two changes to machine's state. 1. Modify the rd register with the inputs rs1 , rs2 . Done in the ALU. 2. PC = PC + 4 . Here is also a timing diagram for add . Increment the PC to get ready for next instruction asynchronously Read the instruction asynchronously We read the registers asynchronously Then it goes into ALU and after some combinational delay it is ready Now perform the write operation, which is a synchronous write. See how reg[1] matches the rising edge of clk . Here are some more R-Type instructions Notice how decoding the funct3 and funct7 fields tell us which ALU function we want. I-Format Instruction Layout \u00b6 Only one field is different from R-format, rs2 and func7 replaced by a 12-bit signed immediate, imm[11:0] . Here are the I-format instructions Not operation is not in the ISA, but xori can do this. xori rd, rs1, -1 . The shift operations. They only use the lower 5 bits of the immediate value for shift amount (because 5 bits can already shift out the 0-31 bits positions) The same Inst[30] immediate bit is used to distinguish \"shift right logical\" from \"shift right arithmetic\" An addi instruction datapath might look like This also supports R-type instructions. Just alter the image so that the ALUSel can pick out all the operations as needed. Load instructions are also I-type. Its form is generally Reg[rd] = Mem[Reg[rs1] + offset] The 12-bit signed immediate is added to the base address in register rs1 to form the memory address The value loaded from memory is stored in register rd . In our DMEM block we need to add some datapath to support lw . See that there is a WBSel control logic that will perform memory operations that support lw . There are also other load instructions lbu : load unsigned byte; lh : load halfword (word = 32 bits) Supporting the narrower loads requires additional logic to extract the correct byte/halfword from the value loaded from memory, and sign or zero extend the result to 32 bits S-Format Instruction Layout \u00b6 General format Mem[Reg[rs1] + offset] = Reg[rs2] Store needs to read two registers, rs1 for base memory address, and rs2 for data to be stored, as well as immediate offset Note stores don't write value to register file Immediates broken into two parts Can't have both rs2 and immediate in same place as other instructions RISC-V design decision is move low 5 bits of immediate to where rd field was in other instructions. We can then keep rs1 and rs2 in the same place. The register names are more critical than immediate bits in hardware design To store in in our datapath, we have some place to create some store in our DMEM Here are all the store instructions: Note that both I and S type use some immediate. Just need a 5-bit mux to select between two positions where low five bits of immediate can reside in instruction Other bits in immediate are wired to fixed positions in instruction. B-Format Instruction Layout \u00b6 <Branch Op> rs1, rs2, label Branches read two registers but don't write a register. PC is being changed on branch. Now we need to represent labels and now instruction offsets. B-format is similar to S-format, with two register sources and a 12-bit immediate The 12 immediate bits encode 13-bit signed byte offsets. Notice how it is broken in to segments, but also they are not in order. It is to maintain consistency. The immediate represents values \\(\\in\\left[-2^{12}, 2^{12}\\right]\\) in two byte increments See how the imm[0] is not represented -- it is always 0 . We can always ignore the LSb since every instruction is 4 bytes. We actually could skip the 2 LSb's, but we don't because there are 16-bit instructions. This is the compressed extension, where instructions are 16 bits. To support compressed formats, we need the imm[1] . The immediate generator would look like this for each I, S, B instruction To change this in our datapath, we need to tap into the PC counter and add some immediate to it. Running the branch instruction changes the state as follows: PC = PC + 4 branch not taken PC = PC + imm branch taken The branch comparator only outputs two things in the control logic. \\(BrEq = 1\\) if \\(A = B\\) , \\(BrLT = 1\\) if \\(A < B\\) The input is either finding a signed or unsigned comparison, and \\(BrUN = 1\\) if it is unsigned. From this all branch instructions are possible, for example A >= B is simply the result of not (A < B) . PCSel will tell if the branch is taken or not taken, and then add the appropriate value ( 4 or the imm ). There is also an input to the Immediate Generator to indicate how to generate the immediate correctly. ALU really determines the target instruction. J-Format Instruction Layout \u00b6 We don't do a comparison, we just jump there. First, let's look at a kinda J-type instruction: jalr It is really an I-type instruction. jalr rd, rs, imm R[rd] = PC + 4; RC = Reg[rs1] + imm : writes PC + 4 to rd and sets PC = rs1 + imm . Uses same immediates as arithmetic and loads. No multiplication by 2 bytes, which is in contrast to branches and jal. Here is the addition of the datapath with jalr Note how the WBSel control has to have another option to simply have a choice to add 4 to PC. Now here is a regular J-format instruction For jal we apply the rule of R[rd] = PC + 4; PC = PC + imm This saves PC + 4 in register rd Then set PC = PC + offset . The target is somewhere within \\(\\pm 2^{19}\\) locations, with 2 bytes apart (20 bit is sign). Immediate encoding is optimized similarly to branch instruction to reduce hardware cost. There is a j pseudo instruction, which uses jal but sets rd = x0 to discard return address. Here is datapath with jal Notice the Immediate Generator must know how to create J immediates U-Format Instruction Layout \u00b6 The U-format has a 20-bit immediate in upper 20 bits of 32-bit instruction word. There is one destination register Used for two instructions: lui : load upper immediate: reg[rd] = {imm, 12b'0} auipc : add upper immediate to PC : reg[rd] = PC + {imm, 12'b0} To implement lui and auipc we can just adjust the ImmSel to indicate we want U immediates. Complete RV32I \u00b6 Datapath: ISA: Summary \u00b6 Implementation of the base ISA for RV32I Instruction types: R, I, S, B, J, U types. Here are the formats in a summary Implementation is straightforward, but single-cycle is slow --> pipeline it.","title":"9. RISC-V Datapath I"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#9-risc-v-datapath-i","text":"","title":"9. RISC-V Datapath I"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#stages-of-datapath","text":"A single CL block that executes an instruction is too bulky and inefficient. The solution is to break up the process of executing an instruction into stages, and then connect the stages to create the whole datapath. There are 5 stages of the datapath: 1. Instruction Fetch (IF) 2. Instruction Decode (ID) 3. Execute (EX) 4. Memory Access (MEM) 5. Write Back to Register (WB)","title":"Stages of Datapath"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#state-and-sequencing","text":"Memory: One input bus: data in. One output bus: data out Memory word is found by: Read: address selects the word to put on data out Write: set write enable = 1. Address selects the memory word to be written via the data in bus Clock Only a factor during write operation During read operation, behaves as a combinational logic block: address valid --> data out valid after \"access time\"","title":"State and Sequencing"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#risc-v-datapath-control","text":"Every instruction is 32-bits divided into fields of varying numbers each. opcode: specifies what instruction it is May have funct7 & funct3: fields describe what operation to perform.","title":"RISC-V Datapath &amp; Control"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#r-format-instruction-layout","text":"rs1, rs2, rd: three registers that can be expressed in 5 bits. The instruction will operate on rs1 , rs2 and store its result in rd . $$ \\text{ rd, rs1, rs2} $$ R-type instructions usually makes two changes to machine's state. 1. Modify the rd register with the inputs rs1 , rs2 . Done in the ALU. 2. PC = PC + 4 . Here is also a timing diagram for add . Increment the PC to get ready for next instruction asynchronously Read the instruction asynchronously We read the registers asynchronously Then it goes into ALU and after some combinational delay it is ready Now perform the write operation, which is a synchronous write. See how reg[1] matches the rising edge of clk . Here are some more R-Type instructions Notice how decoding the funct3 and funct7 fields tell us which ALU function we want.","title":"R-Format Instruction Layout"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#i-format-instruction-layout","text":"Only one field is different from R-format, rs2 and func7 replaced by a 12-bit signed immediate, imm[11:0] . Here are the I-format instructions Not operation is not in the ISA, but xori can do this. xori rd, rs1, -1 . The shift operations. They only use the lower 5 bits of the immediate value for shift amount (because 5 bits can already shift out the 0-31 bits positions) The same Inst[30] immediate bit is used to distinguish \"shift right logical\" from \"shift right arithmetic\" An addi instruction datapath might look like This also supports R-type instructions. Just alter the image so that the ALUSel can pick out all the operations as needed. Load instructions are also I-type. Its form is generally Reg[rd] = Mem[Reg[rs1] + offset] The 12-bit signed immediate is added to the base address in register rs1 to form the memory address The value loaded from memory is stored in register rd . In our DMEM block we need to add some datapath to support lw . See that there is a WBSel control logic that will perform memory operations that support lw . There are also other load instructions lbu : load unsigned byte; lh : load halfword (word = 32 bits) Supporting the narrower loads requires additional logic to extract the correct byte/halfword from the value loaded from memory, and sign or zero extend the result to 32 bits","title":"I-Format Instruction Layout"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#s-format-instruction-layout","text":"General format Mem[Reg[rs1] + offset] = Reg[rs2] Store needs to read two registers, rs1 for base memory address, and rs2 for data to be stored, as well as immediate offset Note stores don't write value to register file Immediates broken into two parts Can't have both rs2 and immediate in same place as other instructions RISC-V design decision is move low 5 bits of immediate to where rd field was in other instructions. We can then keep rs1 and rs2 in the same place. The register names are more critical than immediate bits in hardware design To store in in our datapath, we have some place to create some store in our DMEM Here are all the store instructions: Note that both I and S type use some immediate. Just need a 5-bit mux to select between two positions where low five bits of immediate can reside in instruction Other bits in immediate are wired to fixed positions in instruction.","title":"S-Format Instruction Layout"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#b-format-instruction-layout","text":"<Branch Op> rs1, rs2, label Branches read two registers but don't write a register. PC is being changed on branch. Now we need to represent labels and now instruction offsets. B-format is similar to S-format, with two register sources and a 12-bit immediate The 12 immediate bits encode 13-bit signed byte offsets. Notice how it is broken in to segments, but also they are not in order. It is to maintain consistency. The immediate represents values \\(\\in\\left[-2^{12}, 2^{12}\\right]\\) in two byte increments See how the imm[0] is not represented -- it is always 0 . We can always ignore the LSb since every instruction is 4 bytes. We actually could skip the 2 LSb's, but we don't because there are 16-bit instructions. This is the compressed extension, where instructions are 16 bits. To support compressed formats, we need the imm[1] . The immediate generator would look like this for each I, S, B instruction To change this in our datapath, we need to tap into the PC counter and add some immediate to it. Running the branch instruction changes the state as follows: PC = PC + 4 branch not taken PC = PC + imm branch taken The branch comparator only outputs two things in the control logic. \\(BrEq = 1\\) if \\(A = B\\) , \\(BrLT = 1\\) if \\(A < B\\) The input is either finding a signed or unsigned comparison, and \\(BrUN = 1\\) if it is unsigned. From this all branch instructions are possible, for example A >= B is simply the result of not (A < B) . PCSel will tell if the branch is taken or not taken, and then add the appropriate value ( 4 or the imm ). There is also an input to the Immediate Generator to indicate how to generate the immediate correctly. ALU really determines the target instruction.","title":"B-Format Instruction Layout"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#j-format-instruction-layout","text":"We don't do a comparison, we just jump there. First, let's look at a kinda J-type instruction: jalr It is really an I-type instruction. jalr rd, rs, imm R[rd] = PC + 4; RC = Reg[rs1] + imm : writes PC + 4 to rd and sets PC = rs1 + imm . Uses same immediates as arithmetic and loads. No multiplication by 2 bytes, which is in contrast to branches and jal. Here is the addition of the datapath with jalr Note how the WBSel control has to have another option to simply have a choice to add 4 to PC. Now here is a regular J-format instruction For jal we apply the rule of R[rd] = PC + 4; PC = PC + imm This saves PC + 4 in register rd Then set PC = PC + offset . The target is somewhere within \\(\\pm 2^{19}\\) locations, with 2 bytes apart (20 bit is sign). Immediate encoding is optimized similarly to branch instruction to reduce hardware cost. There is a j pseudo instruction, which uses jal but sets rd = x0 to discard return address. Here is datapath with jal Notice the Immediate Generator must know how to create J immediates","title":"J-Format Instruction Layout"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#u-format-instruction-layout","text":"The U-format has a 20-bit immediate in upper 20 bits of 32-bit instruction word. There is one destination register Used for two instructions: lui : load upper immediate: reg[rd] = {imm, 12b'0} auipc : add upper immediate to PC : reg[rd] = PC + {imm, 12'b0} To implement lui and auipc we can just adjust the ImmSel to indicate we want U immediates.","title":"U-Format Instruction Layout"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#complete-rv32i","text":"Datapath: ISA:","title":"Complete RV32I"},{"location":"EECS/EECS%20151/8.%20RISC-V%20Datapath%20I/8.%20RISC-V%20Datapath%20I/#summary","text":"Implementation of the base ISA for RV32I Instruction types: R, I, S, B, J, U types. Here are the formats in a summary Implementation is straightforward, but single-cycle is slow --> pipeline it.","title":"Summary"},{"location":"EECS/EECS%20151/9.%20RISC-V%20Datapath%20II/9.%20RISC-V%20Datapath%20II/","text":"9. RISC-V Datapath II \u00b6 RV32I Datapath with Control \u00b6 Datapath: Control Logic Truth Table Finally, notice how the instruction types are encoded using only 9 bits:","title":"9. RISC-V Datapath II"},{"location":"EECS/EECS%20151/9.%20RISC-V%20Datapath%20II/9.%20RISC-V%20Datapath%20II/#9-risc-v-datapath-ii","text":"","title":"9. RISC-V Datapath II"},{"location":"EECS/EECS%20151/9.%20RISC-V%20Datapath%20II/9.%20RISC-V%20Datapath%20II/#rv32i-datapath-with-control","text":"Datapath: Control Logic Truth Table Finally, notice how the instruction types are encoded using only 9 bits:","title":"RV32I Datapath with Control"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/","text":"A. Verilog \u00b6 This note is just practice with the syntax of Verilog with explanations on syntax and other things. A Verilog Primer \u00b6 Verilog is a HDL that can describe digital circuits with C-like syntax. It defines circuits at the RTL of abstraction. Modules are the building blocks of Verilog designs. They are a means of abstraction and encapsulation for your design. Consists of a port declaration and Verilog code to implement the desired functionality Modules are created in Verilog file (.v) where the filename matches the module name. Ports allow communication between a module and its environment. Each port has a name and a type Input Output Inout Ports for a module are declared in the port declaration module full_adder (input x, input y, input cin, output s, output cout); // Verilog code here has access to inputs // Verilog code here has access to outputs endmodule Every Verilog design has a top-level module which sits at the highest level of the design hierarchy. The top-level module defines the I/O for the entire digital system. All the modules in your design reside inside the top-level module. Verilog Module Instantiation \u00b6 Modules can be instantiated inside other modules. The syntax used is <module_name> <instance_name> (.port0(wire), .port1(wire), ...) For example, module top_level (input switch0, input switch1, input switch2, output LED0, output LED1); full_adder add ( .x(switch0), .y(switch1), .cin(switch2), .s(LED0), .cout(LED1) ); endmodule Wire Nets \u00b6 Wires are analogous to wires in a circuit you build by hand; they are used to transmit values between inputs and outputs. Declare wires before they are used. Wires can be scalar (1 bit), or they can be vectors // 1-bit declaration a and b wire a; wire b; wire [7:0] d; // 8-bit wire declaration wire [31:0] e; // 32-bit wire declaration We can declare signals that are more than 1 bit wide in Verilog with this general syntax: [MSB bit index : LSB bit index] now we can imagine how it deals with type annotations: module two_bit_adder (input [1:0] x, input [1:0] y, output [2:0] sum); wire [1:0] partial_sum; wire carry_out; endmodule Gate Primitives \u00b6 The following gate primitives exist in Verilog: and, or, xor, not, nand, nor, xnor. In general, the syntax is <operator> (output, input1, input2) // two input gate <operator> (output, input); // for not gate For example, if we want to implement the Boolean equation \\(f = a + b\\) : wire a, b, f; or (f, a, b); Example: Full Adder \u00b6 Here is a gate-level circuit schematic In Verilog: module full_adder (input a, input b, input cin, output s, output cout); xor(s, a, b, cin); wire xor_a_b; wire cin_and; wire and_a_b; xor(xor_a_b, a, b); and(cin_and, cin, xor_a_b); and(and_a_b, a, b); or(cout, and_a_b, cin_and); endmodule Behavioral Verilog \u00b6 The full adder using structural Verilog can be a pain to write, but you will never have to write it that way. Behavioral Verilog constructs allow you to describe what you want a circuit to do at the RTL level of abstraction. Assign Statements \u00b6 Wires can be assigned to logic equations, other wires, or operations performed on wires. This is accomplished using assign statement. The left argument of the assign statement must be a wire, and cannot be an input wire. The right argument of the assign statement can be any expression created from Verilog operators and wires module copy (input a, output b); assign b = a; endmodule Verilog contains operators that can be used to perform arithmetic, form logic expressions, perform reductions/shifts, and check equality between signals So a behavioral Verilog version of the full adder might look like module full_adder (input x, input y, input cin, output s, output cout); assign s = x ^ y ^ cin; assign cout = (a && b) || (cin && (a ^ b)); endmodule It gets even better wire operand1 [31:0]; wire operand2 [31:0]; wire result [32:0]; assign result = operand1 + operand2 which described the 32-bit adder, but didn't specify the architecture or logic. The Verilog synthesizer wil turn the generalized addder into a FPGA specific netlist or an ASIC gate-level netlist. Conditional Operator ? \u00b6 The conditional operator allows us to define if-else logic in an assign statement <condition> ? <expr_if_true> : <expr_if_false> assign out = a > 10 ? 10 : a; Example: output 0 if the two inputs are equal, output 1 if input a is less than input b , and output 2 if input a is greater than input a : module equality_checker(input a [31:0], input b[31:0], output c [1:0]); assign c = a == B ? 2'd0 : (a < b ? 2'd1 : 2'd2); endmodule Verilog Literals \u00b6 Verilog defines a particular way of specifying literals: [bit width]'[radix][literal] Radix can be d (decimal), h (hex), o (octal), b (binary). It is critical to always match bit widths for operators and module connections, do not ignore these warnings from the tools 2'd1 16'hAD14 8'b01011010 Macros \u00b6 Macros are similar to those in C. `include is a preprocessor command to inject a Verilog source file at its location; often used to bring in a Verilog header file (.vh) `define <Constant Name> is used to declare a synthesis-time constant; use these instead of putting \"magic values\" in RTL `define <Macro function name>(ARGS) <Function body> is used to define a macro function that can generate RTL based on ARGS `ifndef <NAME>, `define <NAME>, `endif is an include guard Here is an example. In constants.vh: `ifndef CONSTANTS // guard prevents header file from being included more than once `define CONSTANTS `define ADDR_BITS 16 `define NUM_WORDS 32 `define LOG2(x) \\ (x <= 2) ? 1 : \\ (x <= 4) ? 2 : \\ (x <= 8) ? 3 : \\ (x <= 16) ? 4 : \\ (x <= 32) ? 5 : \\ (x <= 64) ? 6 : \\ -1 `endif Then in design.v: `include \"constants.vh\" module memory (input [`ADDR_BITS - 1:0] address, output [`LOG2(`NUM_WORDS) - 1:0] data); //implementation endmodule Reg Nets \u00b6 There are two types of nets: wire and reg Reg nets are required whenever a net must preserve state (i.e. in an always block). Wires are used for structural verilog (to connect inputs to outputs) and for continuous assignmnet: reg x;","title":"A. Verilog"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#a-verilog","text":"This note is just practice with the syntax of Verilog with explanations on syntax and other things.","title":"A. Verilog"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#a-verilog-primer","text":"Verilog is a HDL that can describe digital circuits with C-like syntax. It defines circuits at the RTL of abstraction. Modules are the building blocks of Verilog designs. They are a means of abstraction and encapsulation for your design. Consists of a port declaration and Verilog code to implement the desired functionality Modules are created in Verilog file (.v) where the filename matches the module name. Ports allow communication between a module and its environment. Each port has a name and a type Input Output Inout Ports for a module are declared in the port declaration module full_adder (input x, input y, input cin, output s, output cout); // Verilog code here has access to inputs // Verilog code here has access to outputs endmodule Every Verilog design has a top-level module which sits at the highest level of the design hierarchy. The top-level module defines the I/O for the entire digital system. All the modules in your design reside inside the top-level module.","title":"A Verilog Primer"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#verilog-module-instantiation","text":"Modules can be instantiated inside other modules. The syntax used is <module_name> <instance_name> (.port0(wire), .port1(wire), ...) For example, module top_level (input switch0, input switch1, input switch2, output LED0, output LED1); full_adder add ( .x(switch0), .y(switch1), .cin(switch2), .s(LED0), .cout(LED1) ); endmodule","title":"Verilog Module Instantiation"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#wire-nets","text":"Wires are analogous to wires in a circuit you build by hand; they are used to transmit values between inputs and outputs. Declare wires before they are used. Wires can be scalar (1 bit), or they can be vectors // 1-bit declaration a and b wire a; wire b; wire [7:0] d; // 8-bit wire declaration wire [31:0] e; // 32-bit wire declaration We can declare signals that are more than 1 bit wide in Verilog with this general syntax: [MSB bit index : LSB bit index] now we can imagine how it deals with type annotations: module two_bit_adder (input [1:0] x, input [1:0] y, output [2:0] sum); wire [1:0] partial_sum; wire carry_out; endmodule","title":"Wire Nets"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#gate-primitives","text":"The following gate primitives exist in Verilog: and, or, xor, not, nand, nor, xnor. In general, the syntax is <operator> (output, input1, input2) // two input gate <operator> (output, input); // for not gate For example, if we want to implement the Boolean equation \\(f = a + b\\) : wire a, b, f; or (f, a, b);","title":"Gate Primitives"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#example-full-adder","text":"Here is a gate-level circuit schematic In Verilog: module full_adder (input a, input b, input cin, output s, output cout); xor(s, a, b, cin); wire xor_a_b; wire cin_and; wire and_a_b; xor(xor_a_b, a, b); and(cin_and, cin, xor_a_b); and(and_a_b, a, b); or(cout, and_a_b, cin_and); endmodule","title":"Example: Full Adder"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#behavioral-verilog","text":"The full adder using structural Verilog can be a pain to write, but you will never have to write it that way. Behavioral Verilog constructs allow you to describe what you want a circuit to do at the RTL level of abstraction.","title":"Behavioral Verilog"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#assign-statements","text":"Wires can be assigned to logic equations, other wires, or operations performed on wires. This is accomplished using assign statement. The left argument of the assign statement must be a wire, and cannot be an input wire. The right argument of the assign statement can be any expression created from Verilog operators and wires module copy (input a, output b); assign b = a; endmodule Verilog contains operators that can be used to perform arithmetic, form logic expressions, perform reductions/shifts, and check equality between signals So a behavioral Verilog version of the full adder might look like module full_adder (input x, input y, input cin, output s, output cout); assign s = x ^ y ^ cin; assign cout = (a && b) || (cin && (a ^ b)); endmodule It gets even better wire operand1 [31:0]; wire operand2 [31:0]; wire result [32:0]; assign result = operand1 + operand2 which described the 32-bit adder, but didn't specify the architecture or logic. The Verilog synthesizer wil turn the generalized addder into a FPGA specific netlist or an ASIC gate-level netlist.","title":"Assign Statements"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#conditional-operator","text":"The conditional operator allows us to define if-else logic in an assign statement <condition> ? <expr_if_true> : <expr_if_false> assign out = a > 10 ? 10 : a; Example: output 0 if the two inputs are equal, output 1 if input a is less than input b , and output 2 if input a is greater than input a : module equality_checker(input a [31:0], input b[31:0], output c [1:0]); assign c = a == B ? 2'd0 : (a < b ? 2'd1 : 2'd2); endmodule","title":"Conditional Operator ?"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#verilog-literals","text":"Verilog defines a particular way of specifying literals: [bit width]'[radix][literal] Radix can be d (decimal), h (hex), o (octal), b (binary). It is critical to always match bit widths for operators and module connections, do not ignore these warnings from the tools 2'd1 16'hAD14 8'b01011010","title":"Verilog Literals"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#macros","text":"Macros are similar to those in C. `include is a preprocessor command to inject a Verilog source file at its location; often used to bring in a Verilog header file (.vh) `define <Constant Name> is used to declare a synthesis-time constant; use these instead of putting \"magic values\" in RTL `define <Macro function name>(ARGS) <Function body> is used to define a macro function that can generate RTL based on ARGS `ifndef <NAME>, `define <NAME>, `endif is an include guard Here is an example. In constants.vh: `ifndef CONSTANTS // guard prevents header file from being included more than once `define CONSTANTS `define ADDR_BITS 16 `define NUM_WORDS 32 `define LOG2(x) \\ (x <= 2) ? 1 : \\ (x <= 4) ? 2 : \\ (x <= 8) ? 3 : \\ (x <= 16) ? 4 : \\ (x <= 32) ? 5 : \\ (x <= 64) ? 6 : \\ -1 `endif Then in design.v: `include \"constants.vh\" module memory (input [`ADDR_BITS - 1:0] address, output [`LOG2(`NUM_WORDS) - 1:0] data); //implementation endmodule","title":"Macros"},{"location":"EECS/EECS%20151/A.%20.Verilog/A.%20Verilog/#reg-nets","text":"There are two types of nets: wire and reg Reg nets are required whenever a net must preserve state (i.e. in an always block). Wires are used for structural verilog (to connect inputs to outputs) and for continuous assignmnet: reg x;","title":"Reg Nets"},{"location":"EECS/EECS%2016A/0.%20Introduction%20to%20EECS%2016A/","text":"0. Introduction \u00b6 Hi, my name is Matthew, and took this class in the Summer 2022 semester, though I have seen the subject of linear algebra 3 times before (Linear Algebra at a Community College, Physics 89, and Math 110), and the subject of circuits 2 times before (AP Physics 1/C, Physics 5B/5BL). I wanted to create a set of notes that try to summarize the course content in a very intuitive and concise way, while also allowing depth into the subject o linear algebra. This course comes in two main parts: linear algebra and circuits. As of how the course is run in 2022, it feels like it is broken into three parts, but the last module (that being correlation and trilateration) is simply an application of linear algebra. One thing that I wished for when I took this class was a deeper understanding of linear algebra. It definitely felt at some times the linear algebra felt procedural rather than intuitive: in my opinion linear algebra needs to be intuitive, seeing how it works visually, computationally, and abstractly. I hope to encapsulate linear algebra concepts through this manner, which does mean I will be reordering the topics as they appear in the class as it is now to the way I find the most logical. The second part of the course, circuits, can get complicated really quickly. I personally find the circuits part really interesting, especially the applications of the devices we will analyze. The way I will approach it will be like 16A will, but go through a bunch of examples. You understand circuits better by first understanding the principles, but then doing a bunch of examples. Overview \u00b6 WIth all my notes, I like to give a quick overview of what will be covered, and why we need to even learn it in the first place. [[1. Matrices and Vectors]]: Matrices and vectors are just like numbers you learned in arithmetic: you can add them, subtract them, multiply them, but you cannot divide them. You can think of vectors as multidimensional numbers, and you can think of matrices as multiple vectors. We will get a good grasp on how to handle algebra dealing with matrices and vectors. [[2. Linear Systems and Gaussian Elimination]]: With our newfound knowledge of matrices and vectors, we will see how to use them to solve systems of linear equations in a systematic way. You'll see how row operations on augmented matrices will lead you to the solution, and how to row reduce all the way until you know if a solution has no solutions, one solution, or infinitely many solutions. We will also see how to write a linear system in matrix-vector form. [[3. Invertibility and Determinants]]: Now we will see what unique solutions to linear equations might mean for us, and how one can transition this thought into the topic of invertibility. If you know a matrix is invertible, you'll know so much about the linear system. Afterwards, we will look into determinants, and find ways to compute \\(n\\times n\\) determinants fairly quickly. Then we will see how to solve a system with inverses, and then solve systems using determinants. Finally, I will show that determinants and inverses are related to each other. [[4. Vector Spaces]]: Vector spaces is a specific type of mathematical structure that you've probably have used before, but never really knew you were using it. It hinges on the idea of vector addition and scalar multiplication, as well as commutative, associate, distributive, identity, inverse properties. The vector as a magnitude-direction object creates a vector space, but now it is time see how this definition might apply to other mathematical objects. in fact, you'll see polynomials are vectors, matrices are vectors, and more. You can actually create your own object and as long as it satisfies the definition of a vector space, you can call the object a vector. [[5. Linear Independence, Span, Bases]]: One can characterize a vector space through a set of vectors that can reach every vector in a vector space. For example, is it always true you can find such a set where this happens? If you do have a list of vectors that do this can you find the minimum amount that does the same thing? Is the minimum amount necessarily unique? This is what this section will talk about [[6. Matrices as Linear Transformations]]: Now we have the tools to talk about linear transformations, and we will use matrices to visually see these transformations. [[7. Eigenvalues and Eigenvectors]]:","title":"0. Introduction"},{"location":"EECS/EECS%2016A/0.%20Introduction%20to%20EECS%2016A/#0-introduction","text":"Hi, my name is Matthew, and took this class in the Summer 2022 semester, though I have seen the subject of linear algebra 3 times before (Linear Algebra at a Community College, Physics 89, and Math 110), and the subject of circuits 2 times before (AP Physics 1/C, Physics 5B/5BL). I wanted to create a set of notes that try to summarize the course content in a very intuitive and concise way, while also allowing depth into the subject o linear algebra. This course comes in two main parts: linear algebra and circuits. As of how the course is run in 2022, it feels like it is broken into three parts, but the last module (that being correlation and trilateration) is simply an application of linear algebra. One thing that I wished for when I took this class was a deeper understanding of linear algebra. It definitely felt at some times the linear algebra felt procedural rather than intuitive: in my opinion linear algebra needs to be intuitive, seeing how it works visually, computationally, and abstractly. I hope to encapsulate linear algebra concepts through this manner, which does mean I will be reordering the topics as they appear in the class as it is now to the way I find the most logical. The second part of the course, circuits, can get complicated really quickly. I personally find the circuits part really interesting, especially the applications of the devices we will analyze. The way I will approach it will be like 16A will, but go through a bunch of examples. You understand circuits better by first understanding the principles, but then doing a bunch of examples.","title":"0. Introduction"},{"location":"EECS/EECS%2016A/0.%20Introduction%20to%20EECS%2016A/#overview","text":"WIth all my notes, I like to give a quick overview of what will be covered, and why we need to even learn it in the first place. [[1. Matrices and Vectors]]: Matrices and vectors are just like numbers you learned in arithmetic: you can add them, subtract them, multiply them, but you cannot divide them. You can think of vectors as multidimensional numbers, and you can think of matrices as multiple vectors. We will get a good grasp on how to handle algebra dealing with matrices and vectors. [[2. Linear Systems and Gaussian Elimination]]: With our newfound knowledge of matrices and vectors, we will see how to use them to solve systems of linear equations in a systematic way. You'll see how row operations on augmented matrices will lead you to the solution, and how to row reduce all the way until you know if a solution has no solutions, one solution, or infinitely many solutions. We will also see how to write a linear system in matrix-vector form. [[3. Invertibility and Determinants]]: Now we will see what unique solutions to linear equations might mean for us, and how one can transition this thought into the topic of invertibility. If you know a matrix is invertible, you'll know so much about the linear system. Afterwards, we will look into determinants, and find ways to compute \\(n\\times n\\) determinants fairly quickly. Then we will see how to solve a system with inverses, and then solve systems using determinants. Finally, I will show that determinants and inverses are related to each other. [[4. Vector Spaces]]: Vector spaces is a specific type of mathematical structure that you've probably have used before, but never really knew you were using it. It hinges on the idea of vector addition and scalar multiplication, as well as commutative, associate, distributive, identity, inverse properties. The vector as a magnitude-direction object creates a vector space, but now it is time see how this definition might apply to other mathematical objects. in fact, you'll see polynomials are vectors, matrices are vectors, and more. You can actually create your own object and as long as it satisfies the definition of a vector space, you can call the object a vector. [[5. Linear Independence, Span, Bases]]: One can characterize a vector space through a set of vectors that can reach every vector in a vector space. For example, is it always true you can find such a set where this happens? If you do have a list of vectors that do this can you find the minimum amount that does the same thing? Is the minimum amount necessarily unique? This is what this section will talk about [[6. Matrices as Linear Transformations]]: Now we have the tools to talk about linear transformations, and we will use matrices to visually see these transformations. [[7. Eigenvalues and Eigenvectors]]:","title":"Overview"},{"location":"EECS/EECS%2016A/toc%20EECS%2016A/","text":"Table of Contents \u00b6 EECS 16A: Designing Information Devices and Systems \u00b6 This note is a table of contents, for easy navigation to notes in EECS 16A. Get back to main toc EECS EECS 16A Notes 0. Introduction to EECS 16A [[1. Vectors and Matrix Algebra]] [[2. Linear Systems and Gaussian Elimination]] [[3. Invertibility and Determinants]] [[4. Vector Spaces]] [[5. Linear Independence, Span, Bases]] [[6. Matrices as Linear Transformations]] [[7. Eigenvalues and Eigenvectors]] [[8. Inner Products and Orthogonality]] [[9. Physics of Circuits]] [[10. Node Voltage Analysis and Superposition]] [[11. Special Circuits]] [[12. Thevenin and Norton Equivalence]] [[13. Physics of Capacitors]] [[14. Capacitors in Circuits]] [[15. Operational Amplifiers]] [[16. Circuit Design]] [[17. Trilateration and Correlation]]","title":"Table of Contents"},{"location":"EECS/EECS%2016A/toc%20EECS%2016A/#table-of-contents","text":"","title":"Table of Contents"},{"location":"EECS/EECS%2016A/toc%20EECS%2016A/#eecs-16a-designing-information-devices-and-systems","text":"This note is a table of contents, for easy navigation to notes in EECS 16A. Get back to main toc EECS EECS 16A Notes 0. Introduction to EECS 16A [[1. Vectors and Matrix Algebra]] [[2. Linear Systems and Gaussian Elimination]] [[3. Invertibility and Determinants]] [[4. Vector Spaces]] [[5. Linear Independence, Span, Bases]] [[6. Matrices as Linear Transformations]] [[7. Eigenvalues and Eigenvectors]] [[8. Inner Products and Orthogonality]] [[9. Physics of Circuits]] [[10. Node Voltage Analysis and Superposition]] [[11. Special Circuits]] [[12. Thevenin and Norton Equivalence]] [[13. Physics of Capacitors]] [[14. Capacitors in Circuits]] [[15. Operational Amplifiers]] [[16. Circuit Design]] [[17. Trilateration and Correlation]]","title":"EECS 16A: Designing Information Devices and Systems"},{"location":"Physics/toc%20Physics/","text":"Table of Contents \u00b6 This note serves as the Physics toc. Get back to mastertoc . Navigate to the toc of a specific class: [[toc Physics 5A]] Introduction to Mechanics and Relativity [[toc Physics 5B]] Introduction to Electricity and Magnetism, Waves, and Optics [[toc Physics 5C]] Introduction to Thermodynamics and Quantum Mechanics [[toc Physics 89]] Introduction to Mathematical Physics toc Physics 137A Quantum Mechanics","title":"Table of Contents"},{"location":"Physics/toc%20Physics/#table-of-contents","text":"This note serves as the Physics toc. Get back to mastertoc . Navigate to the toc of a specific class: [[toc Physics 5A]] Introduction to Mechanics and Relativity [[toc Physics 5B]] Introduction to Electricity and Magnetism, Waves, and Optics [[toc Physics 5C]] Introduction to Thermodynamics and Quantum Mechanics [[toc Physics 89]] Introduction to Mathematical Physics toc Physics 137A Quantum Mechanics","title":"Table of Contents"},{"location":"Physics/Physics%20137A/1.%20Blackbody%20Radiation/","text":"1. Origins of Quantum Theory; UV Catastrophe \u00b6 This note explains the origins of Quantum theory, blackbody radiation and includes derivations of Rayleigh-Jeans and Maxwell-Planck laws. Origins of Quantum Theory \u00b6 There are a few successes of classical physics, namely Newtonian Mechanics Maxwellian Electromagnetism Boltzmann Statistical Mechanics But, there are 2 catastrophic breakdowns when applied to black body radiation and atomic spectra. Let's first discuss some historical events leading up to the origins of quantum theory 1792: Wedgward remarks that all objects heated to the same temperature grow the same color. 1800s: Improvements in spectroscopy show that solids emit continuous spectra; gases emit discrete lines 1859: Kirchoff proposes model of thermal radiation emission to be a function of wavelength and temperature \\[ R(\\lambda, T) \\qquad \\text{emissive power per unit area} \\] Blackbodies \u00b6 Blackbodies are objects that absorb all incident EM waves, regardless of frequencies and incident angles, and they also emit radiations with a spectrum determined by its temperature. They are called such because light will not be reflected directly. Instead, incident light has the change to reach thermal equilibrium with the blackbody. In other words, it is a cavity where light bounces many times off the walls. They are Perfect absorbers/Perfect emitters Equilibrium established between walls at temperature \\(T\\) and light field Classical Observations of Blackbodies include Stefan's Law (1879), which experimentally found that total radiation emitted from a glowing solid is proportional to \\(T^4\\) . \\[ R(T) = \\int_{0}^{\\infty} R(\\lambda, T)d\\lambda = \\sigma T^4, \\qquad \\text{where }\\sigma = 5.67\\times 10^{-8} \\frac{W}{m^2K^4} \\] Wien's Law: From spectroscopic data, found \\(\\lambda_{max}T = 2.898\\times10^{-3}mK\\) Rayleigh-Jeans Law \u00b6 This law attempts to fit a functional form to the end part of the spectrum graph of \\(R\\) vs. \\(\\lambda\\) . Derivation of Classical and Quantum Blackbody Radiation Formulae \u00b6 Cavity of Standing Waves \u00b6 Let's start with a simple object: a cube with sidelength \\(L\\) . The wave equation states \\[ \\nabla^2\\Psi(\\vec{r}, t) = \\frac{1}{c^2}\\frac{\\partial^2}{\\partial^2t}\\Psi(\\vec{r}, t) \\] where \\(\\Psi\\) is a function that describes wave amplitude. Since we have a PDE, we can specify a boundary condition, where \\(\\Psi = 0\\) at the cavity walls, i.e. \\[ \\Psi(x=0, y, z, t) = \\Psi(x = L, y, z, t) = \\cdots = 0 \\] The solution is known: \\[ \\Psi(\\vec{r}, t) = A(t) \\sin(k_xx) \\sin(k_yy)\\sin(k_zz) \\] and the boundary conditions require \\[ k_i = \\frac{n_i\\pi}{L}, \\qquad i = x, y, z; \\text{and n is an integer} \\] Notice the form of the solution. It is in a standing wave form, with a time varying amplitude \\[ A(t)B(x, y, z) \\] this is what we will substitute into the wave equation. Upon simiplification, I get \\[ -(n_1^2 + n_2^2 + n_3^3) \\frac{\\pi^2}{L^3} A(t) B(x, y, z) = \\frac{1}{c^2}B(x, y, z)\\frac{\\partial^2}{\\partial^2t}A(t) \\] We will guess the form for \\(A(t)\\) to be \\(A_0\\cos(\\omega t) + \\phi\\) , where \\(\\omega^2 = \\frac{c^2\\pi^2}{L}(n_1^2 + n_2^2 + n_3^2)\\) . This form makes sense because the function \\(A(t)\\) is related to the second derivative. Now, we need to count how many different ways (called modes) a given \\(\\omega\\) can be distributed over \\(n_i\\) . Let \\(g(\\omega) = \\frac{dN(\\omega)}{d\\omega}\\) , where \\(g\\) is the number of modes per unit frequency. Thus \\[ N(\\omega) = \\int_{0}^{\\omega}g(\\omega)d\\omega \\] For a given \\(\\omega\\) , the possible values of \\(n_i\\) are bound and must obey \\[ n_1^2 + n_2^2 + n_3^2 \\leq \\frac{\\omega^2L^2}{c^2\\pi^2} \\] Isn't this just a sphere of radius \\(\\frac{\\omega L}{c\\pi}\\) ? Therefore, let's just consider one quadrant of the whole sphere and count that much of it \\[ N(\\omega) = \\frac{1}{8}\\left(\\frac{4}{3}\\pi\\frac{\\omega^3L^3}{c^3\\pi^3}\\right) = \\frac{\\omega^3V}{6c^3\\pi^2} \\] where \\(V\\) is the volume. Now let's convert to linear frequency using \\(\\omega = 2\\pi f\\) . \\[ N(f) = \\frac{8\\pi^3f^3V}{6c^3 \\pi^2} \\] \\[ g(f) = \\frac{dN(f)}{df} = \\frac{4\\pi f^2 V}{c^3} \\] And since each mode has 2 polarization directions, we double it $$ g(f) = \\frac{8\\pi f 2}{c 3} V $$ This is true for both classical and quantum, since we just used a geometrical argument. Classical Calculation of The Result \u00b6 We are looking for energy density per volume. Where it will be \\[ \\rho(f) = \\frac{g(f)}{V} \\times Energy \\] In Classical physics, each mode has energy \\(k_BT\\) by the equipartition theorem. Thus, the energy density between \\(f\\) and \\(f + df\\) is \\[ g(f)k_BT df = \\frac{8\\pi f^2 V}{c^3} k_BTdf \\] And we get energy density by dividing by \\(V\\) . \\[ \\rho(f) = \\frac{8\\pi f^2}{c^3} k_BTdf \\] Now, let's convert to \\(\\lambda\\) . \\(f = c/\\lambda\\) , and \\(df = -cd\\lambda / \\lambda\\) , so we get \\[ \\rho(\\lambda) = \\frac{8\\pi k_BT}{\\lambda^4} \\] which is Rayleigh-Jeans. Let's analyze this result. The formula works for \\(k_BT >> \\omega\\) . But as \\(f\\rightarrow \\infty\\) , \\(\\rho\\rightarrow\\infty\\) , which makes no sense. This is the UV Catastrophe. Quantum Calculation of The Result \u00b6 Let's fix the UV Catastrophe using Quantum. Planck postulated that each oscillator cannot take on all modes of energy. He said that energy is gained/lost in discrete units of \\(hf\\) , or simply \\[ E_n = nhf \\] Now let's find the expectation value of the energy \\[ \\overline{E} = \\frac{\\sum_{n=0}^{\\infty} nhf e^{-\\frac{nhf}{k_BT}}}{\\sum_{n=0}^{\\infty}e^{-\\frac{-nhf}{k_BT}}} \\] We know this sum by looking it up on a table, and find \\[ \\overline{E} = \\frac{hfe^{-\\frac{hf}{k_BT}}}{1 - e^{-\\frac{hf}{k_BT}}} = \\frac{hf}{e^{\\frac{hf}{k_BT}} - 1} \\] This is the energy that we use, according to Planck, instead of the Equipartition Theorems (the Classical way). Now we can say the energy density per volume is \\[ \\rho(f, T) = \\frac{g(f)}{V} \\overline{E} = \\frac{8\\pi f^2}{c^3}\\frac{hf}{e^{\\frac{hf}{k_BT}} - 1} \\] And finally, converting to \\(\\lambda\\) , we get \\[ \\rho(\\lambda, T) = \\frac{8\\pi hc}{\\lambda^5} \\frac{hf}{e^{\\frac{hf}{k_BT}} - 1} \\] which actually matches the \\(R(\\lambda, T)\\) perfectly! The Classical result matches only the end part of it, while the Quantum result matches the whole curve.","title":"1. Origins of Quantum Theory; UV Catastrophe"},{"location":"Physics/Physics%20137A/1.%20Blackbody%20Radiation/#1-origins-of-quantum-theory-uv-catastrophe","text":"This note explains the origins of Quantum theory, blackbody radiation and includes derivations of Rayleigh-Jeans and Maxwell-Planck laws.","title":"1. Origins of Quantum Theory; UV Catastrophe"},{"location":"Physics/Physics%20137A/1.%20Blackbody%20Radiation/#origins-of-quantum-theory","text":"There are a few successes of classical physics, namely Newtonian Mechanics Maxwellian Electromagnetism Boltzmann Statistical Mechanics But, there are 2 catastrophic breakdowns when applied to black body radiation and atomic spectra. Let's first discuss some historical events leading up to the origins of quantum theory 1792: Wedgward remarks that all objects heated to the same temperature grow the same color. 1800s: Improvements in spectroscopy show that solids emit continuous spectra; gases emit discrete lines 1859: Kirchoff proposes model of thermal radiation emission to be a function of wavelength and temperature \\[ R(\\lambda, T) \\qquad \\text{emissive power per unit area} \\]","title":"Origins of Quantum Theory"},{"location":"Physics/Physics%20137A/1.%20Blackbody%20Radiation/#blackbodies","text":"Blackbodies are objects that absorb all incident EM waves, regardless of frequencies and incident angles, and they also emit radiations with a spectrum determined by its temperature. They are called such because light will not be reflected directly. Instead, incident light has the change to reach thermal equilibrium with the blackbody. In other words, it is a cavity where light bounces many times off the walls. They are Perfect absorbers/Perfect emitters Equilibrium established between walls at temperature \\(T\\) and light field Classical Observations of Blackbodies include Stefan's Law (1879), which experimentally found that total radiation emitted from a glowing solid is proportional to \\(T^4\\) . \\[ R(T) = \\int_{0}^{\\infty} R(\\lambda, T)d\\lambda = \\sigma T^4, \\qquad \\text{where }\\sigma = 5.67\\times 10^{-8} \\frac{W}{m^2K^4} \\] Wien's Law: From spectroscopic data, found \\(\\lambda_{max}T = 2.898\\times10^{-3}mK\\)","title":"Blackbodies"},{"location":"Physics/Physics%20137A/1.%20Blackbody%20Radiation/#rayleigh-jeans-law","text":"This law attempts to fit a functional form to the end part of the spectrum graph of \\(R\\) vs. \\(\\lambda\\) .","title":"Rayleigh-Jeans Law"},{"location":"Physics/Physics%20137A/1.%20Blackbody%20Radiation/#derivation-of-classical-and-quantum-blackbody-radiation-formulae","text":"","title":"Derivation of Classical and Quantum Blackbody Radiation Formulae"},{"location":"Physics/Physics%20137A/1.%20Blackbody%20Radiation/#cavity-of-standing-waves","text":"Let's start with a simple object: a cube with sidelength \\(L\\) . The wave equation states \\[ \\nabla^2\\Psi(\\vec{r}, t) = \\frac{1}{c^2}\\frac{\\partial^2}{\\partial^2t}\\Psi(\\vec{r}, t) \\] where \\(\\Psi\\) is a function that describes wave amplitude. Since we have a PDE, we can specify a boundary condition, where \\(\\Psi = 0\\) at the cavity walls, i.e. \\[ \\Psi(x=0, y, z, t) = \\Psi(x = L, y, z, t) = \\cdots = 0 \\] The solution is known: \\[ \\Psi(\\vec{r}, t) = A(t) \\sin(k_xx) \\sin(k_yy)\\sin(k_zz) \\] and the boundary conditions require \\[ k_i = \\frac{n_i\\pi}{L}, \\qquad i = x, y, z; \\text{and n is an integer} \\] Notice the form of the solution. It is in a standing wave form, with a time varying amplitude \\[ A(t)B(x, y, z) \\] this is what we will substitute into the wave equation. Upon simiplification, I get \\[ -(n_1^2 + n_2^2 + n_3^3) \\frac{\\pi^2}{L^3} A(t) B(x, y, z) = \\frac{1}{c^2}B(x, y, z)\\frac{\\partial^2}{\\partial^2t}A(t) \\] We will guess the form for \\(A(t)\\) to be \\(A_0\\cos(\\omega t) + \\phi\\) , where \\(\\omega^2 = \\frac{c^2\\pi^2}{L}(n_1^2 + n_2^2 + n_3^2)\\) . This form makes sense because the function \\(A(t)\\) is related to the second derivative. Now, we need to count how many different ways (called modes) a given \\(\\omega\\) can be distributed over \\(n_i\\) . Let \\(g(\\omega) = \\frac{dN(\\omega)}{d\\omega}\\) , where \\(g\\) is the number of modes per unit frequency. Thus \\[ N(\\omega) = \\int_{0}^{\\omega}g(\\omega)d\\omega \\] For a given \\(\\omega\\) , the possible values of \\(n_i\\) are bound and must obey \\[ n_1^2 + n_2^2 + n_3^2 \\leq \\frac{\\omega^2L^2}{c^2\\pi^2} \\] Isn't this just a sphere of radius \\(\\frac{\\omega L}{c\\pi}\\) ? Therefore, let's just consider one quadrant of the whole sphere and count that much of it \\[ N(\\omega) = \\frac{1}{8}\\left(\\frac{4}{3}\\pi\\frac{\\omega^3L^3}{c^3\\pi^3}\\right) = \\frac{\\omega^3V}{6c^3\\pi^2} \\] where \\(V\\) is the volume. Now let's convert to linear frequency using \\(\\omega = 2\\pi f\\) . \\[ N(f) = \\frac{8\\pi^3f^3V}{6c^3 \\pi^2} \\] \\[ g(f) = \\frac{dN(f)}{df} = \\frac{4\\pi f^2 V}{c^3} \\] And since each mode has 2 polarization directions, we double it $$ g(f) = \\frac{8\\pi f 2}{c 3} V $$ This is true for both classical and quantum, since we just used a geometrical argument.","title":"Cavity of Standing Waves"},{"location":"Physics/Physics%20137A/1.%20Blackbody%20Radiation/#classical-calculation-of-the-result","text":"We are looking for energy density per volume. Where it will be \\[ \\rho(f) = \\frac{g(f)}{V} \\times Energy \\] In Classical physics, each mode has energy \\(k_BT\\) by the equipartition theorem. Thus, the energy density between \\(f\\) and \\(f + df\\) is \\[ g(f)k_BT df = \\frac{8\\pi f^2 V}{c^3} k_BTdf \\] And we get energy density by dividing by \\(V\\) . \\[ \\rho(f) = \\frac{8\\pi f^2}{c^3} k_BTdf \\] Now, let's convert to \\(\\lambda\\) . \\(f = c/\\lambda\\) , and \\(df = -cd\\lambda / \\lambda\\) , so we get \\[ \\rho(\\lambda) = \\frac{8\\pi k_BT}{\\lambda^4} \\] which is Rayleigh-Jeans. Let's analyze this result. The formula works for \\(k_BT >> \\omega\\) . But as \\(f\\rightarrow \\infty\\) , \\(\\rho\\rightarrow\\infty\\) , which makes no sense. This is the UV Catastrophe.","title":"Classical Calculation of The Result"},{"location":"Physics/Physics%20137A/1.%20Blackbody%20Radiation/#quantum-calculation-of-the-result","text":"Let's fix the UV Catastrophe using Quantum. Planck postulated that each oscillator cannot take on all modes of energy. He said that energy is gained/lost in discrete units of \\(hf\\) , or simply \\[ E_n = nhf \\] Now let's find the expectation value of the energy \\[ \\overline{E} = \\frac{\\sum_{n=0}^{\\infty} nhf e^{-\\frac{nhf}{k_BT}}}{\\sum_{n=0}^{\\infty}e^{-\\frac{-nhf}{k_BT}}} \\] We know this sum by looking it up on a table, and find \\[ \\overline{E} = \\frac{hfe^{-\\frac{hf}{k_BT}}}{1 - e^{-\\frac{hf}{k_BT}}} = \\frac{hf}{e^{\\frac{hf}{k_BT}} - 1} \\] This is the energy that we use, according to Planck, instead of the Equipartition Theorems (the Classical way). Now we can say the energy density per volume is \\[ \\rho(f, T) = \\frac{g(f)}{V} \\overline{E} = \\frac{8\\pi f^2}{c^3}\\frac{hf}{e^{\\frac{hf}{k_BT}} - 1} \\] And finally, converting to \\(\\lambda\\) , we get \\[ \\rho(\\lambda, T) = \\frac{8\\pi hc}{\\lambda^5} \\frac{hf}{e^{\\frac{hf}{k_BT}} - 1} \\] which actually matches the \\(R(\\lambda, T)\\) perfectly! The Classical result matches only the end part of it, while the Quantum result matches the whole curve.","title":"Quantum Calculation of The Result"},{"location":"Physics/Physics%20137A/2.%20Bohr%20Model/","text":"2. Bohr Model \u00b6 This note explains another failure of classical physics, and derives the energy levels of electrons in the hydrogen atom. Brief History \u00b6 In classical radiation theory, Thomson and Rutherford found that electrons must revolve around the nucleus to avoid falling into it. Maxwell's EM theory supposed that if an electron revolves with frequency \\(f\\) , then it must emit radiation with frequency \\(f\\) . However! As energy is radiated, electrons should fall into a lighter orbit. In 1913, Bohr \"solves\" the mystery and publishes \"On the Constitution of Atoms and Molecules\". Bohr proposes two things: 1. Classical radiation theory does not apply to electrons 2. Only certain orbits are stable, and are separated by \\(hf = \\Delta E\\) . Derivation of Bohr Model \u00b6 In this derivation, we will discoverthe allowed radii that an electron can be in, as well as the energy at a specific level, and how to find the energy emitted upon a change in level. We start with three presumptions: 1. Circular orbit 2. Only certain orbits are stable 3. Jumping from one orbit to another absors or emits \\(hf\\) . Begin with circular motion: \\[ a_c = \\frac{v^2}{R} \\] We have an attractive electrostatic force with two charges of \\(e\\) . \\[ \\frac{F_c}{m} = \\frac{ke^2}{mR^2} \\] I want to get some form of angular momentum, so I multiply both sides by \\(m^2R^3\\) . \\[ \\frac{v^2}{R} = \\frac{ke^2}{mR^2} \\] \\[ m^2v^2R^2 = mke^2R \\] \\[ L^2 = mke^2R \\] Let's solve for \\(R\\) : \\[ R = \\frac{L^2}{mke^2} \\] Now we use the idea that angular momentum is quantized: \\[ mvr = n\\hbar \\] Which can be justified using the idea of de Broglie that all matter is a wave with \\[ \\lambda = \\frac{h}{p} \\] \\[ f = \\frac{E}{h} \\] Stable states are thus standing waves which satisfy periodic boundary conditions. Thus, \\[ 2\\pi R = n\\lambda = \\frac{nh}{mv} \\] And \\(mvR = n\\hbar = L\\) . Substitute this into our equation for \\(R\\) . \\[ R_n = \\frac{n^2\\hbar^2}{mke^2} \\] This shows that radii is quantized. Now we will look at the situation in terms of energy. \\[ U = qV = -\\frac{ke^2}{R} \\] \\[ K = \\frac{1}{2}mv^2 \\] Thus, the total energy is \\[ E = \\frac{1}{2}mv^2 - \\frac{ke^2}{R} \\] Note that we originally stated \\[ m^2v^2R^2 = mke^2R \\] Let's solve for \\(mv^2\\) : \\[ mv^2 = \\frac{ke^2}{R} \\] Substitute this into our energy equation $$ E = \\frac{1}{2}\\frac{ke^2}{R} - \\frac{ke^2}{R} = -\\frac{ke^2}{2R} $$ Let's substitute our quantized radius equation to the energy equation: \\[ E = -\\frac{ke^2}{2}\\frac{mke^2}{n^2\\hbar^2} \\] \\[ E_n = -\\frac{1}{n^2} \\left(\\frac{mk^2e^4}{2\\hbar^2}\\right) \\] Maybe it could be a bit better to separate the charges of the nucleus and the electron charge, then it would be \\[ E_n = -\\frac{1}{n^2}\\left(\\frac{mk^2q_N^2e^2}{2\\hbar^2}\\right) \\] Showing that energy is discrete as well. We can describe energy changes by finding the difference in energy orbits: \\[ \\Delta E = \\frac{mk^2q_N^2e^2}{2\\hbar^2}\\left(\\frac{1}{n_i^2} - \\frac{1}{n_f^2}\\right) \\] Emission will happen if the electron falls to a lower orbit, and absorption will happen if the elctron is excited to a higher orbit. What is Missing in Bohr's Model \u00b6 Several things: 1. Failed to predict intensity of spectral lines 2. Limited success for multi-electron atoms 3. Failed to produce time dynamics 4. Ignores wave nature/penomenon 5. No general quantization scheme Therefore, we need Quantum Mechanics as developed by Heisenberg, Schrodinger, Dirac, ...","title":"2. Bohr Model"},{"location":"Physics/Physics%20137A/2.%20Bohr%20Model/#2-bohr-model","text":"This note explains another failure of classical physics, and derives the energy levels of electrons in the hydrogen atom.","title":"2. Bohr Model"},{"location":"Physics/Physics%20137A/2.%20Bohr%20Model/#brief-history","text":"In classical radiation theory, Thomson and Rutherford found that electrons must revolve around the nucleus to avoid falling into it. Maxwell's EM theory supposed that if an electron revolves with frequency \\(f\\) , then it must emit radiation with frequency \\(f\\) . However! As energy is radiated, electrons should fall into a lighter orbit. In 1913, Bohr \"solves\" the mystery and publishes \"On the Constitution of Atoms and Molecules\". Bohr proposes two things: 1. Classical radiation theory does not apply to electrons 2. Only certain orbits are stable, and are separated by \\(hf = \\Delta E\\) .","title":"Brief History"},{"location":"Physics/Physics%20137A/2.%20Bohr%20Model/#derivation-of-bohr-model","text":"In this derivation, we will discoverthe allowed radii that an electron can be in, as well as the energy at a specific level, and how to find the energy emitted upon a change in level. We start with three presumptions: 1. Circular orbit 2. Only certain orbits are stable 3. Jumping from one orbit to another absors or emits \\(hf\\) . Begin with circular motion: \\[ a_c = \\frac{v^2}{R} \\] We have an attractive electrostatic force with two charges of \\(e\\) . \\[ \\frac{F_c}{m} = \\frac{ke^2}{mR^2} \\] I want to get some form of angular momentum, so I multiply both sides by \\(m^2R^3\\) . \\[ \\frac{v^2}{R} = \\frac{ke^2}{mR^2} \\] \\[ m^2v^2R^2 = mke^2R \\] \\[ L^2 = mke^2R \\] Let's solve for \\(R\\) : \\[ R = \\frac{L^2}{mke^2} \\] Now we use the idea that angular momentum is quantized: \\[ mvr = n\\hbar \\] Which can be justified using the idea of de Broglie that all matter is a wave with \\[ \\lambda = \\frac{h}{p} \\] \\[ f = \\frac{E}{h} \\] Stable states are thus standing waves which satisfy periodic boundary conditions. Thus, \\[ 2\\pi R = n\\lambda = \\frac{nh}{mv} \\] And \\(mvR = n\\hbar = L\\) . Substitute this into our equation for \\(R\\) . \\[ R_n = \\frac{n^2\\hbar^2}{mke^2} \\] This shows that radii is quantized. Now we will look at the situation in terms of energy. \\[ U = qV = -\\frac{ke^2}{R} \\] \\[ K = \\frac{1}{2}mv^2 \\] Thus, the total energy is \\[ E = \\frac{1}{2}mv^2 - \\frac{ke^2}{R} \\] Note that we originally stated \\[ m^2v^2R^2 = mke^2R \\] Let's solve for \\(mv^2\\) : \\[ mv^2 = \\frac{ke^2}{R} \\] Substitute this into our energy equation $$ E = \\frac{1}{2}\\frac{ke^2}{R} - \\frac{ke^2}{R} = -\\frac{ke^2}{2R} $$ Let's substitute our quantized radius equation to the energy equation: \\[ E = -\\frac{ke^2}{2}\\frac{mke^2}{n^2\\hbar^2} \\] \\[ E_n = -\\frac{1}{n^2} \\left(\\frac{mk^2e^4}{2\\hbar^2}\\right) \\] Maybe it could be a bit better to separate the charges of the nucleus and the electron charge, then it would be \\[ E_n = -\\frac{1}{n^2}\\left(\\frac{mk^2q_N^2e^2}{2\\hbar^2}\\right) \\] Showing that energy is discrete as well. We can describe energy changes by finding the difference in energy orbits: \\[ \\Delta E = \\frac{mk^2q_N^2e^2}{2\\hbar^2}\\left(\\frac{1}{n_i^2} - \\frac{1}{n_f^2}\\right) \\] Emission will happen if the electron falls to a lower orbit, and absorption will happen if the elctron is excited to a higher orbit.","title":"Derivation of Bohr Model"},{"location":"Physics/Physics%20137A/2.%20Bohr%20Model/#what-is-missing-in-bohrs-model","text":"Several things: 1. Failed to predict intensity of spectral lines 2. Limited success for multi-electron atoms 3. Failed to produce time dynamics 4. Ignores wave nature/penomenon 5. No general quantization scheme Therefore, we need Quantum Mechanics as developed by Heisenberg, Schrodinger, Dirac, ...","title":"What is Missing in Bohr's Model"},{"location":"Physics/Physics%20137A/3.%20Wavefunctions/","text":"3. Wavefunctions \u00b6 In this note describes the double-slit experiment, which directs us to the wavefunction. We will analyze consequences of the wavefunction framework. Double-Slit Experiment \u00b6 The physical world can be more accurately described using a wave description. Waves can interfere and be superposed. In Young's double-slit experiment, we can determine one plane wave can be represented by \\[ \\vec{E} = \\vec{E}_0e^{i(\\vec{k}\\cdot\\vec{r} - \\omega t + \\phi)} \\] and we can add two waves together by addition. \\[ \\vec{E}_{tot} = \\vec{E}_{o, 1}e^{i\\delta_1} \\vec{E}_{o, 2}e^{i\\delta_2} \\] We can also detect power or intensity by squaring the plane wave superposition. For two plane waves, the intensity is: \\[ \\left|E\\right|^2 = E_{o1}^2 + E_{o2}^2 + \\vec{E}_{o1} \\cdot \\vec{E}_{o2}\\left(e^{i(\\delta_2 - \\delta_1)} + e^{-i(\\delta_2 - \\delta_1)}\\right) \\] Note that we must add amplitudes not intensities. Also, notee observable pattern only depends on phase difference and not absolute phase. Quantum Wavefunction \u00b6 \\[ \\Psi \\] Represents a wave amplitude Not physical! Cannot picture it as something wiggling Cannot observe it Contains all the informatio nabout the system How to use it? \\(|\\Psi|^2\\) is the probability denbsity to find the system at \\(\\vec{r}, t\\) . Think of a large number of identical systems each with one particle Repeated measurements generates probability \\[ P(\\vec{r}, t) = |\\Psi(\\vec{r}, t)|^2 \\] To find the particle within a chunk \\(d\\vec{r}\\) , about \\(\\vec{r}\\) at time \\(t\\) is \\[ P(\\vec{r}, t)d\\vec{r} = |\\Psi(\\vec{r}, t)|^2d\\vec{r} \\] Wave Superposition \u00b6 If \\(\\Psi_1\\) and \\(\\Psi_2\\) are two allowed states, then any linear combination is also allowed. \\[ \\Psi = c_1\\Psi_1 + c_2\\Psi_2 \\] The scalars can be complex numbers. Wavefunction for a Particle with Definite Momentum \u00b6 We need to encode this information in waves. Just like a particle can be encoded with \\(m, \\vec{r}, \\vec{v}, E, \\vec{p}\\) , a wave should be characterized by some quantity. What we want to encode is a wave that extends outwards in out directions. It will be a function of position and time. We have two useful quantities \\[ \\begin{align*} E = hf = \\frac{h}{2\\pi}\\omega = \\hbar\\omega\\\\ p = \\frac{h}{\\lambda} = \\frac{hk}{2\\pi} = \\hbar k \\end{align*} \\] where \\(\\hbar = h/2\\pi\\) and \\(k = 2\\pi/\\lambda\\) . Let's look at a 1D particle in \\(\\hat{x}\\) . \\[ \\begin{align*} \\vec{P} & = p_x\\hat{x}\\\\ \\Psi &= A\\exp\\left[i(kx - \\omega k t)\\right]\\\\ & = A\\exp\\left[\\frac{i(p_xx - E(p_x)t)}{\\hbar}\\right] \\end{align*} \\] I wish to take out the \\(p_x\\) from this expression. Notice what happens if I take a position derivative of \\(\\Psi\\) . \\[ \\frac{\\partial\\Psi}{\\partial x} = \\frac{Ap_xi}{\\hbar}\\exp\\left[\\frac{i(p_xx - E(p_x)t)}{\\hbar}\\right] \\] Now rearranging the terms leads us to the following result: \\[ -i\\hbar \\frac{\\partial}{\\partial x}\\Psi = p_x\\Psi \\] which is known as th momentum operator. If, I wanted to extract An \\(E\\) , I would want to take a time derivative and will get to the following result: \\[ i\\hbar \\frac{\\partial}{\\partial t} \\Psi = E\\Psi \\] In 3D, we would get something very similar with the momentum and time operators. We find the wave function to be \\[ \\begin{align*} \\Psi(\\vec{r}, t) &= A\\exp(\\vec{k}\\cdot\\vec{r} - \\omega kt)\\\\ & = A\\exp\\left(\\frac{i(\\vec{p}\\cdot\\vec{r} - E(\\vec{p})t)}{\\hbar}\\right) \\end{align*} \\] And then the time and position derivatives would lead to \\[ i\\hbar \\frac{\\partial}{\\partial t} \\Psi = E\\Psi \\] \\[ -i\\hbar \\nabla\\Psi = \\vec{p}\\Psi \\] Probability and Normalization \u00b6 Another thing we need to note is that the wave function represents a density Recall, Max Born found that the probability density to find the system at \\(\\vec{r}, t\\) is \\[ |\\Psi(\\vec{r}, t)|^2 \\] Since this is a density, we should normalize it: \\[ \\int_{\\text{all space}} |\\Psi(\\vec{r}, t)|^2d\\vec{r} = 1 \\] However, for a plane wave, the integral would diverge. This is because a plane wave has amplitude everywhere in space. This tells us that a plane wave in not really a good thing to analyze in quantum mechanics. In other words, there must be something else that better accurately describes physics at this level. This is where the wavepacket comes in Which will be discussed in [[5. Wavepackets]]. However, in order to understand the physics with wavepackets, some math will need to be covered first in 4. Fourier Stuff","title":"3. Wavefunctions"},{"location":"Physics/Physics%20137A/3.%20Wavefunctions/#3-wavefunctions","text":"In this note describes the double-slit experiment, which directs us to the wavefunction. We will analyze consequences of the wavefunction framework.","title":"3. Wavefunctions"},{"location":"Physics/Physics%20137A/3.%20Wavefunctions/#double-slit-experiment","text":"The physical world can be more accurately described using a wave description. Waves can interfere and be superposed. In Young's double-slit experiment, we can determine one plane wave can be represented by \\[ \\vec{E} = \\vec{E}_0e^{i(\\vec{k}\\cdot\\vec{r} - \\omega t + \\phi)} \\] and we can add two waves together by addition. \\[ \\vec{E}_{tot} = \\vec{E}_{o, 1}e^{i\\delta_1} \\vec{E}_{o, 2}e^{i\\delta_2} \\] We can also detect power or intensity by squaring the plane wave superposition. For two plane waves, the intensity is: \\[ \\left|E\\right|^2 = E_{o1}^2 + E_{o2}^2 + \\vec{E}_{o1} \\cdot \\vec{E}_{o2}\\left(e^{i(\\delta_2 - \\delta_1)} + e^{-i(\\delta_2 - \\delta_1)}\\right) \\] Note that we must add amplitudes not intensities. Also, notee observable pattern only depends on phase difference and not absolute phase.","title":"Double-Slit Experiment"},{"location":"Physics/Physics%20137A/3.%20Wavefunctions/#quantum-wavefunction","text":"\\[ \\Psi \\] Represents a wave amplitude Not physical! Cannot picture it as something wiggling Cannot observe it Contains all the informatio nabout the system How to use it? \\(|\\Psi|^2\\) is the probability denbsity to find the system at \\(\\vec{r}, t\\) . Think of a large number of identical systems each with one particle Repeated measurements generates probability \\[ P(\\vec{r}, t) = |\\Psi(\\vec{r}, t)|^2 \\] To find the particle within a chunk \\(d\\vec{r}\\) , about \\(\\vec{r}\\) at time \\(t\\) is \\[ P(\\vec{r}, t)d\\vec{r} = |\\Psi(\\vec{r}, t)|^2d\\vec{r} \\]","title":"Quantum Wavefunction"},{"location":"Physics/Physics%20137A/3.%20Wavefunctions/#wave-superposition","text":"If \\(\\Psi_1\\) and \\(\\Psi_2\\) are two allowed states, then any linear combination is also allowed. \\[ \\Psi = c_1\\Psi_1 + c_2\\Psi_2 \\] The scalars can be complex numbers.","title":"Wave Superposition"},{"location":"Physics/Physics%20137A/3.%20Wavefunctions/#wavefunction-for-a-particle-with-definite-momentum","text":"We need to encode this information in waves. Just like a particle can be encoded with \\(m, \\vec{r}, \\vec{v}, E, \\vec{p}\\) , a wave should be characterized by some quantity. What we want to encode is a wave that extends outwards in out directions. It will be a function of position and time. We have two useful quantities \\[ \\begin{align*} E = hf = \\frac{h}{2\\pi}\\omega = \\hbar\\omega\\\\ p = \\frac{h}{\\lambda} = \\frac{hk}{2\\pi} = \\hbar k \\end{align*} \\] where \\(\\hbar = h/2\\pi\\) and \\(k = 2\\pi/\\lambda\\) . Let's look at a 1D particle in \\(\\hat{x}\\) . \\[ \\begin{align*} \\vec{P} & = p_x\\hat{x}\\\\ \\Psi &= A\\exp\\left[i(kx - \\omega k t)\\right]\\\\ & = A\\exp\\left[\\frac{i(p_xx - E(p_x)t)}{\\hbar}\\right] \\end{align*} \\] I wish to take out the \\(p_x\\) from this expression. Notice what happens if I take a position derivative of \\(\\Psi\\) . \\[ \\frac{\\partial\\Psi}{\\partial x} = \\frac{Ap_xi}{\\hbar}\\exp\\left[\\frac{i(p_xx - E(p_x)t)}{\\hbar}\\right] \\] Now rearranging the terms leads us to the following result: \\[ -i\\hbar \\frac{\\partial}{\\partial x}\\Psi = p_x\\Psi \\] which is known as th momentum operator. If, I wanted to extract An \\(E\\) , I would want to take a time derivative and will get to the following result: \\[ i\\hbar \\frac{\\partial}{\\partial t} \\Psi = E\\Psi \\] In 3D, we would get something very similar with the momentum and time operators. We find the wave function to be \\[ \\begin{align*} \\Psi(\\vec{r}, t) &= A\\exp(\\vec{k}\\cdot\\vec{r} - \\omega kt)\\\\ & = A\\exp\\left(\\frac{i(\\vec{p}\\cdot\\vec{r} - E(\\vec{p})t)}{\\hbar}\\right) \\end{align*} \\] And then the time and position derivatives would lead to \\[ i\\hbar \\frac{\\partial}{\\partial t} \\Psi = E\\Psi \\] \\[ -i\\hbar \\nabla\\Psi = \\vec{p}\\Psi \\]","title":"Wavefunction for a Particle with Definite Momentum"},{"location":"Physics/Physics%20137A/3.%20Wavefunctions/#probability-and-normalization","text":"Another thing we need to note is that the wave function represents a density Recall, Max Born found that the probability density to find the system at \\(\\vec{r}, t\\) is \\[ |\\Psi(\\vec{r}, t)|^2 \\] Since this is a density, we should normalize it: \\[ \\int_{\\text{all space}} |\\Psi(\\vec{r}, t)|^2d\\vec{r} = 1 \\] However, for a plane wave, the integral would diverge. This is because a plane wave has amplitude everywhere in space. This tells us that a plane wave in not really a good thing to analyze in quantum mechanics. In other words, there must be something else that better accurately describes physics at this level. This is where the wavepacket comes in Which will be discussed in [[5. Wavepackets]]. However, in order to understand the physics with wavepackets, some math will need to be covered first in 4. Fourier Stuff","title":"Probability and Normalization"},{"location":"Physics/Physics%20137A/4.%20Fourier%20Stuff/","text":"4. Fourier Stuff \u00b6 This note explains Fourier series and the Fourier transform in both discrete and continuous forms, and also explains why this is important in quantum mechanics. Review of Discrete and Continuous Fourier \\(\\Sigma\\) and \\(\\int\\) \u00b6 Discrete: consider \\(f(x)\\) in interval \\(x\\in[-\\pi, \\pi]\\) that is periodic $f(x +2\\pi) = f(x). Then \\[ f(x) = \\frac{1}{2}A_0 + \\sum_{n =1}^{\\infty}\\left[A_n\\cos(nx) + B_n\\sin(nx)\\right] \\] The series will converge if \\(f(x), f'(x)\\) are piecewise continuous on \\((-\\pi, \\pi)\\) . In addition, \\(A_n, B_n\\) are found by multiplying by basis \\(\\sin(mx)\\) \\[ A_m = \\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} f(x)\\cos(mx)dx \\] \\[ B_m = \\frac{1}{\\pi}\\int_{-\\pi}^{\\pi}f(x)\\sin(mx)dx \\] It can also be written in exponential form: \\[ f(x) = \\frac{1}{\\sqrt{2\\pi}}\\sum_{n=-\\infty}^{\\infty} c_ne^{inx} \\] where \\[ c_m = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\pi}^{\\pi} f(x) e^{-imx}dx \\] A useful quantity to know also is the Kronecker delta: \\[ \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}e^{i(n-m)}dx = \\delta_{mn} = \\begin{cases}1\\qquad m = n\\\\0\\qquad m\\neq n\\end{cases} \\] which just show the dot product of two basis vectors are orthonormal. In the continuous Forier transform, we find \\[ f(x) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty} g(k)e^{ikx}dk \\] \\[ g(k) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty} f(x)e^{-ikx}dx \\] Which is saying that you can transform \\(f(x)\\) and \\(g(k)\\) into each other, provided you have one. Plane Waves to Wave Packets \u00b6","title":"4. Fourier Stuff"},{"location":"Physics/Physics%20137A/4.%20Fourier%20Stuff/#4-fourier-stuff","text":"This note explains Fourier series and the Fourier transform in both discrete and continuous forms, and also explains why this is important in quantum mechanics.","title":"4. Fourier Stuff"},{"location":"Physics/Physics%20137A/4.%20Fourier%20Stuff/#review-of-discrete-and-continuous-fourier-sigma-and-int","text":"Discrete: consider \\(f(x)\\) in interval \\(x\\in[-\\pi, \\pi]\\) that is periodic $f(x +2\\pi) = f(x). Then \\[ f(x) = \\frac{1}{2}A_0 + \\sum_{n =1}^{\\infty}\\left[A_n\\cos(nx) + B_n\\sin(nx)\\right] \\] The series will converge if \\(f(x), f'(x)\\) are piecewise continuous on \\((-\\pi, \\pi)\\) . In addition, \\(A_n, B_n\\) are found by multiplying by basis \\(\\sin(mx)\\) \\[ A_m = \\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} f(x)\\cos(mx)dx \\] \\[ B_m = \\frac{1}{\\pi}\\int_{-\\pi}^{\\pi}f(x)\\sin(mx)dx \\] It can also be written in exponential form: \\[ f(x) = \\frac{1}{\\sqrt{2\\pi}}\\sum_{n=-\\infty}^{\\infty} c_ne^{inx} \\] where \\[ c_m = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\pi}^{\\pi} f(x) e^{-imx}dx \\] A useful quantity to know also is the Kronecker delta: \\[ \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}e^{i(n-m)}dx = \\delta_{mn} = \\begin{cases}1\\qquad m = n\\\\0\\qquad m\\neq n\\end{cases} \\] which just show the dot product of two basis vectors are orthonormal. In the continuous Forier transform, we find \\[ f(x) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty} g(k)e^{ikx}dk \\] \\[ g(k) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty} f(x)e^{-ikx}dx \\] Which is saying that you can transform \\(f(x)\\) and \\(g(k)\\) into each other, provided you have one.","title":"Review of Discrete and Continuous Fourier \\(\\Sigma\\) and \\(\\int\\)"},{"location":"Physics/Physics%20137A/4.%20Fourier%20Stuff/#plane-waves-to-wave-packets","text":"","title":"Plane Waves to Wave Packets"},{"location":"Physics/Physics%20137A/toc%20Physics%20137A/","text":"Table of Contents Physics 137A \u00b6 This note serves as a toc for Physics 137A notes Contents: 1. Blackbody Radiation 2. Bohr Model 3. Wavefunctions 4. Fourier Stuff [[5. Wavepackets]]","title":"Table of Contents Physics 137A"},{"location":"Physics/Physics%20137A/toc%20Physics%20137A/#table-of-contents-physics-137a","text":"This note serves as a toc for Physics 137A notes Contents: 1. Blackbody Radiation 2. Bohr Model 3. Wavefunctions 4. Fourier Stuff [[5. Wavepackets]]","title":"Table of Contents Physics 137A"}]}